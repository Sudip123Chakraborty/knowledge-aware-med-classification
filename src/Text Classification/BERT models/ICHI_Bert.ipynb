{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ICHI Ablation bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqx9cKKKkqBr",
        "outputId": "69278a43-5a5e-4fa1-b57e-405c3d888d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers/\n",
        "!git checkout 896a0eb1fd861bc37097a9b669ebf4cb8d523de7\n",
        "%cd ..\n",
        "\n",
        "!mkdir examples/ichi/\n",
        "!pip install -r requirements.txt\n",
        "!pip install .\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 47185 (delta 22), reused 28 (delta 10), pack-reused 47129\u001b[K\n",
            "Receiving objects: 100% (47185/47185), 33.76 MiB | 23.97 MiB/s, done.\n",
            "Resolving deltas: 100% (32800/32800), done.\n",
            "/content/transformers\n",
            "Note: checking out '896a0eb1fd861bc37097a9b669ebf4cb8d523de7'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 896a0eb1 Merge pull request #2459 from Perseus14/patch-4\n",
            "/content\n",
            "Cloning into 'ICHI-dataset'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 54 (delta 21), reused 42 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (54/54), done.\n",
            "/content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.18.5)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 4.6MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/b9/88fbe33f4f4862b06eed9e1fb05abb8883b0bf2683a87f21c45d597adc5a/boto3-1.15.17-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 39.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 41.6MB/s \n",
            "\u001b[?25hCollecting botocore<1.19.0,>=1.18.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/6e/73f5a0c1041090589531d346d9310030a135b04cb0570d357da699a56a52/botocore-1.18.17-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 33.3MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 5)) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->-r requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->-r requirements.txt (line 9)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->-r requirements.txt (line 9)) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.19.0,>=1.18.17->boto3->-r requirements.txt (line 3)) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=04738f99bbdd7df94fe3557659ceaebaeb53aeb805d19a9b81e34b9726545128\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, jmespath, botocore, s3transfer, boto3, sentencepiece, sacremoses\n",
            "Successfully installed boto3-1.15.17 botocore-1.18.17 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.0.11\n",
            "Processing /content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (0.0.11)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.15.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (0.0.43)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.19.0,>=1.18.17 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (1.18.17)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.19.0,>=1.18.17->boto3->transformers==2.3.0) (2.8.1)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.3.0-cp36-none-any.whl size=451157 sha256=79240e78d2f6d71892967e127aac28a4c8b134683bddde656c1e1409eaa084a6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5zgxmbxq/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-2.3.0\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D79M5NpS8vh",
        "outputId": "2e00ab97-abe8-4cb8-88e5-6d04161c8475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# ########### Uncomment it to download Glove Vectors\n",
        "\n",
        "# !curl -O -J -L http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "# !unzip glove.840B.300d.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0   315    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0   352    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 2075M  100 2075M    0     0  2091k      0  0:16:56  0:16:56 --:--:-- 2551k\n",
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-EzqBB_PvmT",
        "outputId": "c7289e00-2910-4e9c-f9c0-1dd424763f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# ########### Uncomment it to download BioASQ Embeddings\n",
        "\n",
        "# !curl -O -J -L http://bioasq.lip6.fr/tools/BioASQword2vec/\n",
        "# !tar -xvzf biomedicalWordVectors.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   345  100   345    0     0    435      0 --:--:-- --:--:-- --:--:--   435\n",
            "100 1279M  100 1279M    0     0  15.6M      0  0:01:21  0:01:21 --:--:-- 16.5M\n",
            "curl: Saved to filename 'biomedicalWordVectors.tar.gz'\n",
            "word2vecTools/toolkit.py\n",
            "word2vecTools/vectors.txt\n",
            "word2vecTools/\n",
            "word2vecTools/README_BioASQ_word_vectors.pdf\n",
            "word2vecTools/types.txt\n",
            "word2vecTools/train_vectors.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL0KtyeJkv6Z"
      },
      "source": [
        "# class ICHIDataset(Dataset):\n",
        "#     def __init__(self, fname, tokenizer):\n",
        "#         fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "#         lines = fin.readlines()\n",
        "#         fin.close()\n",
        "\n",
        "#         all_data = []\n",
        "#         for i in range(0, len(lines), 3):\n",
        "#             text_left, _, text_right = [s.lower().strip() for s in lines[i].partition(\"$T$\")]\n",
        "#             aspect = lines[i + 1].lower().strip()\n",
        "#             polarity = lines[i + 2].strip()\n",
        "\n",
        "#             text_raw_indices = tokenizer.text_to_sequence(text_left + \" \" + aspect + \" \" + text_right)\n",
        "#             text_raw_without_aspect_indices = tokenizer.text_to_sequence(text_left + \" \" + text_right)\n",
        "#             text_left_indices = tokenizer.text_to_sequence(text_left)\n",
        "#             text_left_with_aspect_indices = tokenizer.text_to_sequence(text_left + \" \" + aspect)\n",
        "#             text_right_indices = tokenizer.text_to_sequence(text_right, reverse=True)\n",
        "#             text_right_with_aspect_indices = tokenizer.text_to_sequence(\" \" + aspect + \" \" + text_right, reverse=True)\n",
        "#             aspect_indices = tokenizer.text_to_sequence(aspect)\n",
        "#             left_context_len = np.sum(text_left_indices != 0)\n",
        "#             aspect_len = np.sum(aspect_indices != 0)\n",
        "#             aspect_in_text = torch.tensor([left_context_len.item(), (left_context_len + aspect_len - 1).item()])\n",
        "#             polarity = int(polarity) + 1\n",
        "\n",
        "#             text_bert_indices = tokenizer.text_to_sequence('[CLS] ' + text_left + \" \" + aspect + \" \" + text_right + ' [SEP] ' + aspect + \" [SEP]\")\n",
        "#             bert_segments_ids = np.asarray([0] * (np.sum(text_raw_indices != 0) + 2) + [1] * (aspect_len + 1))\n",
        "#             bert_segments_ids = pad_and_truncate(bert_segments_ids, tokenizer.max_seq_len)\n",
        "\n",
        "#             text_raw_bert_indices = tokenizer.text_to_sequence(\"[CLS] \" + text_left + \" \" + aspect + \" \" + text_right + \" [SEP]\")\n",
        "#             aspect_bert_indices = tokenizer.text_to_sequence(\"[CLS] \" + aspect + \" [SEP]\")\n",
        "\n",
        "#             data = {\n",
        "#                 'text_bert_indices': text_bert_indices,\n",
        "#                 'bert_segments_ids': bert_segments_ids,\n",
        "#                 'text_raw_bert_indices': text_raw_bert_indices,\n",
        "#                 'aspect_bert_indices': aspect_bert_indices,\n",
        "#                 'text_raw_indices': text_raw_indices,\n",
        "#                 'text_raw_without_aspect_indices': text_raw_without_aspect_indices,\n",
        "#                 'text_left_indices': text_left_indices,\n",
        "#                 'text_left_with_aspect_indices': text_left_with_aspect_indices,\n",
        "#                 'text_right_indices': text_right_indices,\n",
        "#                 'text_right_with_aspect_indices': text_right_with_aspect_indices,\n",
        "#                 'aspect_indices': aspect_indices,\n",
        "#                 'aspect_in_text': aspect_in_text,\n",
        "#                 'polarity': polarity,\n",
        "#             }\n",
        "\n",
        "#             all_data.append(data)\n",
        "#         self.data = all_data\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         return self.data[index]\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG8YjUsTm2Eg",
        "outputId": "c2e3b3a4-442d-424a-e3f1-1c27a272bde4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGkNpSjDrXjh",
        "outputId": "332654bb-d232-4178-a3ae-ed776f2a8f1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile /content/transformers/examples/ichi/utils_ichi.py\n",
        "import logging\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import re\n",
        "import csv\n",
        "import pickle\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from sklearn.metrics import matthews_corrcoef, f1_score\n",
        "from transformers.file_utils import is_tf_available \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "if is_tf_available():\n",
        "    import tensorflow as tf\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def simple_accuracy(preds, labels):\n",
        "    return (preds == labels).mean()\n",
        "\n",
        "def acc_and_f1(preds, labels):\n",
        "    acc = simple_accuracy(preds, labels)\n",
        "    f1 = f1_score(y_true=labels, y_pred=preds, average='macro')\n",
        "    return {\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "def compute_metrics(preds, labels):\n",
        "    # return {\"acc\": simple_accuracy(preds, labels)}\n",
        "    return acc_and_f1(preds, labels)\n",
        "\n",
        "\n",
        "def pad_and_truncate(sequence, maxlen, dtype='int64', padding='pre', truncating='post', value=0):\n",
        "    x = (np.ones(maxlen) * value).astype(dtype)\n",
        "    if truncating == 'pre':\n",
        "        trunc = sequence[-maxlen:]\n",
        "    else:\n",
        "        trunc = sequence[:maxlen]\n",
        "    trunc = np.asarray(trunc, dtype=dtype)\n",
        "    if padding == 'post':\n",
        "        x[:len(trunc)] = trunc\n",
        "    else:\n",
        "        x[-len(trunc):] = trunc\n",
        "    return x\n",
        "\n",
        "class Tokenizer(object):\n",
        "    def __init__(self, max_seq_len, max_num_words=None,lower=True):\n",
        "        self.lower = lower\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.word2idx = {}\n",
        "        self.word_freq = {}\n",
        "        self.idx2word = {}\n",
        "        self.idx2word[0] = '<PAD>'\n",
        "        self.word2idx['<PAD>'] = 0\n",
        "        self.word_freq['<PAD>'] = 100000\n",
        "        self.idx = 1\n",
        "        self.max_num_words = max_num_words\n",
        "\n",
        "    def fit_on_text(self, text):\n",
        "        if self.lower:\n",
        "            text = text.lower()\n",
        "        words = text.split()\n",
        "        for word in words:\n",
        "            if word not in self.word2idx:\n",
        "                self.word2idx[word] = self.idx\n",
        "                self.word_freq[word] = 1\n",
        "                self.idx2word[self.idx] = word\n",
        "                self.idx += 1\n",
        "            else:\n",
        "                self.word_freq[word] = self.word_freq[word] + 1\n",
        "    \n",
        "    def update_tokenizer(self):\n",
        "        if self.max_num_words == None:\n",
        "            return\n",
        "        elif self.max_num_words >= self.idx:\n",
        "            return \n",
        "        else:\n",
        "            del self.word_freq['<PAD>']\n",
        "            self.word_freq = {k: v for k, v in sorted(self.word_freq.items(), key=lambda item: item[1], reverse=True)}\n",
        "            self.word2idx = {}\n",
        "            self.idx2word = {}\n",
        "            self.idx2word[0] = '<PAD>'\n",
        "            self.word2idx['<PAD>'] = 0\n",
        "            self.idx = 1\n",
        "            for i, key in enumerate(self.word_freq):\n",
        "                if i >= self.max_num_words:\n",
        "                    break\n",
        "                else:\n",
        "                    self.word2idx[key] = i+1\n",
        "                    self.idx2word[i+1] = key\n",
        "                    self.idx += 1\n",
        "            self.word_freq['<PAD>'] = 100000\n",
        "\n",
        "\n",
        "\n",
        "    def fit_on_examples(self, examples):\n",
        "        is_tf_dataset = False\n",
        "        if is_tf_available() and isinstance(examples, tf.data.Dataset):\n",
        "            is_tf_dataset = True\n",
        "        processor = ICHIProcessor()\n",
        "        for example in examples:\n",
        "            if is_tf_dataset:\n",
        "                example = processor.get_example_from_tensor_dict(example)\n",
        "                example = processor.tfds_map(example)\n",
        "            self.fit_on_text(example.clean_text)\n",
        "\n",
        "    def text_to_sequence(self, text, reverse=False, padding='pre', truncating='post'):\n",
        "        if self.lower:\n",
        "            text = text.lower()\n",
        "        words = text.split()\n",
        "        unknownidx = len(self.word2idx)+1\n",
        "        if (self.max_num_words == None) or (self.max_num_words >= self.idx):\n",
        "            sequence = [self.word2idx[w] if w in self.word2idx else unknownidx for w in words]\n",
        "        else:\n",
        "            sequence = []\n",
        "            for w in words:\n",
        "                if w in self.word2idx:\n",
        "                    if self.word2idx[w] > self.max_num_words:\n",
        "                        sequence.append(unknownidx)\n",
        "                    else:\n",
        "                        sequence.append(self.word2idx[w])\n",
        "                else:\n",
        "                    sequence.append(unknownidx)\n",
        "        if len(sequence) == 0:\n",
        "            sequence = [0]\n",
        "        if reverse:\n",
        "            sequence = sequence[::-1]\n",
        "        return pad_and_truncate(sequence, self.max_seq_len, padding=padding, truncating=truncating)\n",
        "\n",
        "def _load_word_vec_glove(path, word2idx=None):\n",
        "    fin = open(path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    word_vec = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split()\n",
        "        if word2idx is None or tokens[0] in word2idx.keys():\n",
        "            try:\n",
        "                word_vec[tokens[0]] = np.asarray(tokens[1:], dtype='float32')\n",
        "            except:\n",
        "                pass\n",
        "    return word_vec\n",
        "    \n",
        "def build_embedding_matrix_glove(word2idx, embed_dim, dat_fname, fname):\n",
        "    if os.path.exists(dat_fname):\n",
        "        print('loading embedding_matrix(glove): ', dat_fname)\n",
        "        embedding_matrix = pickle.load(open(dat_fname, 'rb'))\n",
        "    else:\n",
        "        print('loading word vectors...(glove)')\n",
        "        embedding_matrix = np.zeros((len(word2idx) + 2, embed_dim))  # idx 0 and len(word2idx)+1 are all-zeros\n",
        "        fname = fname + '/glove.twitter.27B/glove.twitter.27B.' + str(embed_dim) + 'd.txt' \\\n",
        "            if embed_dim != 300 else fname + '/glove.840B.300d.txt'\n",
        "        word_vec = _load_word_vec_glove(fname, word2idx=word2idx)\n",
        "        print('building embedding_matrix:', dat_fname)\n",
        "        for word, i in word2idx.items():\n",
        "            vec = word_vec.get(word)\n",
        "            if vec is not None:\n",
        "                # words not found in embedding index will be all-zeros.\n",
        "                embedding_matrix[i] = vec\n",
        "        pickle.dump(embedding_matrix, open(dat_fname, 'wb'))\n",
        "    return embedding_matrix\n",
        "\n",
        "def build_embedding_matrix_BioASQ(word2idx, embed_dim, dat_fname, fname):\n",
        "    if os.path.exists(dat_fname):\n",
        "        print('loading embedding_matrix(BioASQ):', dat_fname)\n",
        "        embedding_matrix = pickle.load(open(dat_fname, 'rb'))\n",
        "    else:\n",
        "        print('loading word vectors...(BioASQ)')\n",
        "        embedding_matrix = np.zeros((len(word2idx) + 2, embed_dim))  # idx 0 and len(word2idx)+1 are all-zeros\n",
        "        f = open(fname + \"/word2vecTools/types.txt\",\"r\")\n",
        "        i = 0\n",
        "        names = []\n",
        "        for line in f:\n",
        "            names.append(line.split('\\n')[0])\n",
        "            i = i + 1\n",
        "        vectors = np.loadtxt(fname + \"/word2vecTools/vectors.txt\")\n",
        "        word_vec = {}\n",
        "        for (index, name) in enumerate(names):\n",
        "            word_vec[name] = index\n",
        "\n",
        "        print('building embedding_matrix:', dat_fname)\n",
        "        for word, i in word2idx.items():\n",
        "            if word in word_vec.keys():\n",
        "                vec = vectors[word_vec[word]]\n",
        "            else:\n",
        "                vec = None\n",
        "            if vec is not None:\n",
        "                # words not found in embedding index will be all-zeros.\n",
        "                embedding_matrix[i] = vec\n",
        "        pickle.dump(embedding_matrix, open(dat_fname, 'wb'))\n",
        "    return embedding_matrix\n",
        "\n",
        "def convert_examples_to_features(\n",
        "    examples,\n",
        "    tokenizer,\n",
        "    tokenizer_cleantext,\n",
        "    max_length=512,\n",
        "    task=None,\n",
        "    label_list=None,\n",
        "    output_mode=None,\n",
        "    pad_on_left=False,\n",
        "    pad_token=0,\n",
        "    pad_token_segment_id=0,\n",
        "    mask_padding_with_zero=True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads a data file into a list of ``ICHI_InputFeatures``\n",
        "\n",
        "    Args:\n",
        "        examples: List of ``ICHI_InputExamples`` or ``tf.data.Dataset`` containing the examples.\n",
        "        tokenizer: Instance of a tokenizer that will tokenize the examples\n",
        "        tokenizer_cleantext: Instance of a tokenizer that will tokenize the examples clean text(used for our medical module) \n",
        "        max_length: Maximum example length\n",
        "        task: GLUE task\n",
        "        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n",
        "        output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n",
        "        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n",
        "        pad_token: Padding token\n",
        "        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n",
        "        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n",
        "            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n",
        "            actual values)\n",
        "\n",
        "    Returns:\n",
        "        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n",
        "        containing the task-specific features. If the input is a list of ``ICHI_InputExamples``, will return\n",
        "        a list of task-specific ``ICHI_InputFeatures`` which can be fed to the model.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    is_tf_dataset = False\n",
        "    if is_tf_available() and isinstance(examples, tf.data.Dataset):\n",
        "        is_tf_dataset = True\n",
        "\n",
        "    \"\"\"      Initialisation of Data Processor    \"\"\"\n",
        "    if task is not None:\n",
        "        processor = ICHIProcessor()  \n",
        "        if label_list is None:\n",
        "            label_list = processor.get_labels()\n",
        "            logger.info(\"Using label list %s for task %s\" % (label_list, task))\n",
        "        if output_mode is None:\n",
        "            output_mode = \"classification\"\n",
        "            logger.info(\"Using output mode %s for task %s\" % (output_mode, task))\n",
        "\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "    \"\"\"      Processing the examples    \"\"\"\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            logger.info(\"Writing example %d/%d\" % (ex_index, len(examples)))\n",
        "        if is_tf_dataset:\n",
        "            example = processor.get_example_from_tensor_dict(example)\n",
        "            example = processor.tfds_map(example)\n",
        "        \"\"\"      Assuming that each aspect consist of max 4 tokens hence making sure that aspects total tokens coming from aspects are not greater than max sequence length    \"\"\"\n",
        "        aspect_present = bool(example.aspects is not None)\n",
        "        if aspect_present:\n",
        "            if 4 * len(example.aspects) > max_length:\n",
        "                example.aspects = random.sample(example.aspects, k = int(max_length/4))\n",
        "                \n",
        "        \"\"\"      Using tokenizer.encode_plus_lcf the global features are encoded as [<special token> + text_tokens + <special token> + heading_tokens + <special token> + aspect1_token + <special token> + .... + aspectn_token + <special token>] \"\"\"\n",
        "        inputs_global = tokenizer.encode_plus_lcf(example.text, add_special_tokens=True, max_length=max_length,) ######## edittttttt\n",
        "        \"\"\"      Using tokenizer.encode_plus_lcf the local features(medical module) are encoded as [<special token> + text_tokens + <special token>] \"\"\"\n",
        "        inputs_local = tokenizer.encode_plus_lcf(example.text, add_special_tokens=True, max_length=max_length,)\n",
        "        \"\"\" Generating tokens for the clean_text i.e. tokenising text based on glove or BioASQ \"\"\"\n",
        "        text_clean_indices = tokenizer_cleantext.text_to_sequence(example.clean_text)\n",
        "        \n",
        "        \"\"\"      Using tokenizer.encode_plus_lcf the aspect_indices are encoded as [<special token> + aspect1_token + <special token> + .... + aspectn_token + <special token>] \"\"\"\n",
        "        if len(example.aspects) > 2:\n",
        "            aspect_indices = tokenizer.encode_plus_lcf(example.aspects[0], example.aspects[1], example.aspects[2:], add_special_tokens=False, max_length=max_length,)\n",
        "        elif len(example.aspects) == 2:\n",
        "            aspect_indices = tokenizer.encode_plus_lcf(example.aspects[0], example.aspects[1], add_special_tokens=False, max_length=max_length,)\n",
        "        else:\n",
        "            aspect_indices = tokenizer.encode_plus_lcf(example.aspects[0], add_special_tokens=False, max_length=max_length,)\n",
        "        \n",
        "        input_global_ids, token_global_type_ids = inputs_global[\"input_ids\"], inputs_global[\"token_type_ids\"]\n",
        "        input_local_ids, token_local_type_ids = inputs_local[\"input_ids\"], inputs_local[\"token_type_ids\"]\n",
        "        \n",
        "        aspect_indices = aspect_indices[\"input_ids\"]\n",
        "        padding_length_aspect = max_length - len(aspect_indices)\n",
        "        aspect_indices = aspect_indices + ([pad_token] * padding_length_aspect)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        attention_mask_global = [1 if mask_padding_with_zero else 0] * len(input_global_ids)\n",
        "        attention_mask_local = [1 if mask_padding_with_zero else 0] * len(input_local_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding_length_global = max_length - len(input_global_ids)\n",
        "        padding_length_local = max_length - len(input_local_ids)\n",
        "        if pad_on_left:\n",
        "            input_global_ids = ([pad_token] * padding_length_global) + input_global_ids\n",
        "            attention_mask_global = ([0 if mask_padding_with_zero else 1] * padding_length_global) + attention_mask_global\n",
        "            token_global_type_ids = ([pad_token_segment_id] * padding_length_global) + token_global_type_ids\n",
        "            input_local_ids = ([pad_token] * padding_length_local) + input_local_ids\n",
        "            attention_mask_local = ([0 if mask_padding_with_zero else 1] * padding_length_local) + attention_mask_local\n",
        "            token_local_type_ids = ([pad_token_segment_id] * padding_length_local) + token_local_type_ids\n",
        "        else:\n",
        "            input_global_ids = input_global_ids + ([pad_token] * padding_length_global)\n",
        "            attention_mask_global = attention_mask_global + ([0 if mask_padding_with_zero else 1] * padding_length_global)\n",
        "            token_global_type_ids = token_global_type_ids + ([pad_token_segment_id] * padding_length_global)\n",
        "            input_local_ids = input_local_ids + ([pad_token] * padding_length_local)\n",
        "            attention_mask_local = attention_mask_local + ([0 if mask_padding_with_zero else 1] * padding_length_local)\n",
        "            token_local_type_ids = token_local_type_ids + ([pad_token_segment_id] * padding_length_local)\n",
        "\n",
        "        assert len(input_global_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_global_ids), max_length)\n",
        "        assert len(input_local_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_local_ids), max_length)\n",
        "        assert len(attention_mask_global) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(attention_mask_global), max_length\n",
        "        )\n",
        "        assert len(attention_mask_local) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(attention_mask_local), max_length\n",
        "        )\n",
        "        assert len(token_global_type_ids) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(token_global_type_ids), max_length\n",
        "        )\n",
        "        assert len(token_local_type_ids) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(token_local_type_ids), max_length\n",
        "        )\n",
        "\n",
        "        if output_mode == \"classification\":\n",
        "            label = label_map[example.label]\n",
        "        elif output_mode == \"regression\":\n",
        "            label = float(example.label)\n",
        "        else:\n",
        "            raise KeyError(output_mode)\n",
        "\n",
        "        if ex_index < 5:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"input_global_ids: %s\" % \" \".join([str(x) for x in input_global_ids]))\n",
        "            logger.info(\"attention_mask_global: %s\" % \" \".join([str(x) for x in attention_mask_global]))\n",
        "            logger.info(\"token_global_type_ids: %s\" % \" \".join([str(x) for x in token_global_type_ids]))\n",
        "            logger.info(\"input_local_ids: %s\" % \" \".join([str(x) for x in input_local_ids]))\n",
        "            logger.info(\"attention_mask_local: %s\" % \" \".join([str(x) for x in attention_mask_local]))\n",
        "            logger.info(\"token_local_type_ids: %s\" % \" \".join([str(x) for x in token_local_type_ids]))\n",
        "            logger.info(\"text_clean_indices: %s\" % \" \".join([str(x) for x in text_clean_indices]))\n",
        "            logger.info(\"aspect_indices: %s\" % \" \".join([str(x) for x in aspect_indices]))\n",
        "            logger.info(\"label: %s (id = %d)\" % (example.label, label))\n",
        "\n",
        "        features.append(\n",
        "            ICHI_InputFeatures(\n",
        "                input_global_ids=input_global_ids, input_local_ids=input_local_ids, attention_mask_global=attention_mask_global, attention_mask_local=attention_mask_local,\n",
        "                token_global_type_ids=token_global_type_ids, token_local_type_ids=token_local_type_ids, text_clean_indices=text_clean_indices, aspect_indices=aspect_indices, label=label\n",
        "            )\n",
        "        )\n",
        "\n",
        "    if is_tf_available() and is_tf_dataset:\n",
        "\n",
        "        def gen():\n",
        "            for ex in features:\n",
        "                yield (\n",
        "                    {\n",
        "                        \"input_global_ids\": ex.input_global_ids,\n",
        "                        \"input_local_ids\": ex.input_local_ids,\n",
        "                        \"attention_mask_global\": ex.attention_mask_global,\n",
        "                        \"attention_mask_local\": ex.attention_mask_local,\n",
        "                        \"token_global_type_ids\": ex.token_global_type_ids,\n",
        "                        \"token_local_type_ids\": ex.token_local_type_ids,\n",
        "                        \"text_clean_indices\": ex.text_clean_indices,\n",
        "                        \"aspect_indices\": ex.aspect_indices,\n",
        "                    },\n",
        "                    ex.label,\n",
        "                )\n",
        "\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            gen,\n",
        "            ({\"input_global_ids\": tf.int32, \"input_local_ids\": tf.int32, \"attention_mask_global\": tf.int32, \"attention_mask_local\": tf.int32, \"token_global_type_ids\": tf.int32, \"token_local_type_ids\": tf.int32, \"text_clean_indices\": tf.int32, \"aspect_indices\": tf.int32}, tf.int64),\n",
        "            (\n",
        "                {\n",
        "                    \"input_global_ids\": tf.TensorShape([None]),\n",
        "                    \"input_local_ids\": tf.TensorShape([None]),\n",
        "                    \"attention_mask_global\": tf.TensorShape([None]),\n",
        "                    \"attention_mask_local\": tf.TensorShape([None]),\n",
        "                    \"token_global_type_ids\": tf.TensorShape([None]),\n",
        "                    \"token_local_type_ids\": tf.TensorShape([None]),\n",
        "                    \"text_clean_indices\": tf.TensorShape([None]),\n",
        "                    \"aspect_indices\": tf.TensorShape([None]),\n",
        "                },\n",
        "                tf.TensorShape([]),\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    return features\n",
        "\n",
        "class ICHIProcessor(object):\n",
        "    \"\"\"Processor for the ICHI data set (GLUE version).\"\"\"\n",
        "\n",
        "    def get_example_from_tensor_dict(self, tensor_dict):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return ICHI_InputExample(tensor_dict['idx'].numpy(),\n",
        "                            tensor_dict['heading'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['text'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['clean_text'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['aspects'].numpy().decode('utf-8'),\n",
        "                            str(tensor_dict['label'].numpy()))\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"dev.tsv\")),\n",
        "            \"dev\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"DEMO\", \"DISE\", \"TRMT\", \"GOAL\", \"PREG\", \"FAML\", \"SOCL\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        for (i, line) in enumerate(lines):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            label = line[0]\n",
        "            heading = None\n",
        "            text = line[1] + ' ' + line[2]\n",
        "            try:\n",
        "                aspects = [' ' + x for x in line[3].split('|')]\n",
        "                temp_clean_text = \" \".join(line[3].split('|'))\n",
        "            except:\n",
        "                aspects = None\n",
        "                temp_clean_text = \"\"\n",
        "                print(\"Sed\")\n",
        "            \n",
        "            # print(aspects)\n",
        "            \"\"\"    IMPORTANT    IMPORTANT    IMPORTANT    IMPORTANT    IMPORTANT   \"\"\"\n",
        "            clean_text = self.clean_str( text, lemmatizer) ######## for using glove embeddings over sentence\n",
        "            # clean_text = self.clean_str( temp_clean_text, lemmatizer) ##### for using BioASQ embeddings in aspects\n",
        "            examples.append(\n",
        "                ICHI_InputExample(guid=guid, heading=heading, text=text, clean_text=clean_text, aspects=aspects, label=label))\n",
        "        return examples\n",
        "\n",
        "    def tfds_map(self, example):\n",
        "        \"\"\"Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are.\n",
        "        This method converts examples to the correct format.\"\"\"\n",
        "        if len(self.get_labels()) > 1:\n",
        "            example.label = self.get_labels()[int(example.label)]\n",
        "        return example\n",
        "\n",
        "    def clean_str(self, string1, lemmatizer):\n",
        "        \"\"\"\n",
        "        Tokenization/string cleaning for dataset\n",
        "        Every dataset is lower cased except\n",
        "        \"\"\"\n",
        "        str_stop = \"\"\n",
        "        string1 = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '',string1)\n",
        "        string1 = re.sub(r\"\\\\\", \" \", string1)    \n",
        "        string1 = re.sub(r\"\\'\", \" \", string1)    \n",
        "        string1 = re.sub(r\"\\\"\", \" \", string1)   \n",
        "        string1 = re.sub(r'(\\W)\\1+', r'\\1', string1)\n",
        "        word_list=string1.split(\" \")\n",
        "        filtered_words = [word for word in word_list if word not in stopwords.words('english')]\n",
        "        for kj in filtered_words:\n",
        "            new=lemmatizer.lemmatize(str(kj)) \n",
        "            str_stop=str_stop +\" \"+new\n",
        "            str_stop.encode('utf-8')\n",
        "        return str_stop.strip().lower()\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "            return list(csv.reader(f, delimiter=\"\\t\", quotechar=quotechar))\n",
        "\n",
        "class ICHI_InputExample(object):\n",
        "    \"\"\"\n",
        "    A single training/test example for simple sequence classification.\n",
        "\n",
        "    Args:\n",
        "        guid: Unique id for the example.\n",
        "        heading: string. The untokenized heading of the sequence\n",
        "        text: string. The untokenized text part of the sequence.\n",
        "        clean_text: string. The untokenized text part of the sequence used for medical module(as tokenization will be different for glove and BioASQ than BERT).\n",
        "        aspects: list of string. The untokenized aspects for the sequence as a list of strings\n",
        "        Only must be specified for sequence pair tasks.\n",
        "        label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, guid, heading, text, clean_text, aspects, label=None):\n",
        "        self.guid = guid\n",
        "        self.heading = heading\n",
        "        self.text = text\n",
        "        self.clean_text = clean_text\n",
        "        self.aspects = aspects\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "class ICHI_InputFeatures(object):\n",
        "    \"\"\"\n",
        "    A single set of features of data.\n",
        "\n",
        "    Args:\n",
        "        input_ids: Indices of input sequence tokens in the vocabulary.\n",
        "        attention_mask: Mask to avoid performing attention on padding token indices.\n",
        "            Mask values selected in ``[0, 1]``:\n",
        "            Usually  ``1`` for tokens that are NOT MASKED, ``0`` for MASKED (padded) tokens.\n",
        "        token_type_ids: Segment token indices to indicate first and second portions of the inputs.\n",
        "        label: Label corresponding to the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_global_ids, input_local_ids, attention_mask_global=None, attention_mask_local=None, token_global_type_ids=None, token_local_type_ids=None, text_clean_indices=None, aspect_indices=None, label=None):\n",
        "        self.input_global_ids = input_global_ids\n",
        "        self.attention_mask_global = attention_mask_global\n",
        "        self.token_global_type_ids = token_global_type_ids\n",
        "        self.input_local_ids = input_local_ids\n",
        "        self.attention_mask_local = attention_mask_local\n",
        "        self.token_local_type_ids = token_local_type_ids\n",
        "        self.text_clean_indices = text_clean_indices\n",
        "        self.aspect_indices = aspect_indices\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "def load_and_cache_examples(args, task, tokenizer, tokenizer_cleantext, evaluate=False):\n",
        "    if args.local_rank not in [-1, 0] and not evaluate:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "    processor = ICHIProcessor()  \n",
        "    output_mode = \"classification\"\n",
        "    # Load data features from cache or dataset file\n",
        "    cached_features_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cached_{}_{}_{}_{}\".format(\n",
        "            \"dev\" if evaluate else \"train\",\n",
        "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "            str(args.max_seq_length),\n",
        "            str(task),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    \"\"\" Load saved tokenizer for the clean_text\"\"\"\n",
        "    cached_tokenizer_cleantext_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cachedtokenizer_{}_{}_{}\".format(\n",
        "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "            str(args.embedding_type),\n",
        "            str(task),\n",
        "        ),\n",
        "    )\n",
        "    \"\"\" if overwrite cache is disabled and saved feature and tokenizer file exists then load from the saved file else process them \"\"\"\n",
        "    if os.path.exists(cached_features_file) and os.path.exists(cached_tokenizer_cleantext_file) and not args.overwrite_cache:\n",
        "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        features = torch.load(cached_features_file)\n",
        "        print('loading tokenizer from cache:', cached_tokenizer_cleantext_file)\n",
        "        tokenizer_cleantext = pickle.load(open(cached_tokenizer_cleantext_file, 'rb'))\n",
        "    else:\n",
        "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
        "        label_list = processor.get_labels()\n",
        "        if task in [\"mnli\", \"mnli-mm\"] and args.model_type in [\"roberta\", \"xlmroberta\"]:\n",
        "            # HACK(label indices are swapped in RoBERTa pretrained model)\n",
        "            label_list[1], label_list[2] = label_list[2], label_list[1]\n",
        "        examples = (\n",
        "            processor.get_dev_examples(args.data_dir) if evaluate else processor.get_train_examples(args.data_dir)\n",
        "        )\n",
        "        if (not evaluate):\n",
        "            tokenizer_cleantext.fit_on_examples(examples)\n",
        "            tokenizer_cleantext.update_tokenizer()\n",
        "        \"\"\" features are created using this function which is defined above\"\"\"\n",
        "        features = convert_examples_to_features(\n",
        "            examples,\n",
        "            tokenizer,\n",
        "            tokenizer_cleantext,\n",
        "            label_list=label_list,\n",
        "            max_length=args.max_seq_length,\n",
        "            output_mode=output_mode,\n",
        "            pad_on_left=bool(args.model_type in [\"xlnet\"]),  # pad on the left for xlnet\n",
        "            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
        "            pad_token_segment_id=4 if args.model_type in [\"xlnet\"] else 0,\n",
        "        )\n",
        "        if args.local_rank in [-1, 0]:\n",
        "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "            torch.save(features, cached_features_file)\n",
        "            pickle.dump(tokenizer_cleantext, open(cached_tokenizer_cleantext_file, 'wb'))\n",
        "\n",
        "    if args.local_rank == 0 and not evaluate:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "    # Convert to Tensors and build dataset\n",
        "    all_input_global_ids = torch.tensor([f.input_global_ids for f in features], dtype=torch.long)\n",
        "    all_input_local_ids = torch.tensor([f.input_local_ids for f in features], dtype=torch.long)\n",
        "    all_attention_mask_global = torch.tensor([f.attention_mask_global for f in features], dtype=torch.long)\n",
        "    all_attention_mask_local = torch.tensor([f.attention_mask_local for f in features], dtype=torch.long)\n",
        "    all_token_global_type_ids = torch.tensor([f.token_global_type_ids for f in features], dtype=torch.long)\n",
        "    all_token_local_type_ids = torch.tensor([f.token_local_type_ids for f in features], dtype=torch.long)\n",
        "    all_text_clean_indices = torch.tensor([f.text_clean_indices for f in features], dtype=torch.long)\n",
        "    all_aspect_indices = torch.tensor([f.aspect_indices for f in features], dtype=torch.long)\n",
        "    all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
        "    \n",
        "    dataset = TensorDataset(all_input_global_ids, all_input_local_ids, all_attention_mask_global, all_attention_mask_local, all_token_global_type_ids, all_token_local_type_ids, all_text_clean_indices, all_aspect_indices, all_labels)\n",
        "    \n",
        "    return dataset, tokenizer_cleantext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/transformers/examples/ichi/utils_ichi.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyy-AEpoS8Lx",
        "outputId": "060ead3e-55d8-4f9b-86ef-c8d992dc3eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile /content/transformers/examples/ichi/lcf_ichi.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "import numpy as np\n",
        "from transformers.modeling_bert import BertPooler, BertSelfAttention, BertPreTrainedModel, BertModel\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "\n",
        "def compute_average_with_padding(tensor, padding):\n",
        "    \"\"\"\n",
        "    :param tensor: dimension batch_size, seq_length, hidden_size\n",
        "    :param padding: dimension batch_size, seq_length\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    batch_size, seq_length, emb_size = tensor.shape\n",
        "    entry_sizes = torch.sum(padding, axis=1)\n",
        "    return torch.sum(tensor, axis=1) / entry_sizes\n",
        "\n",
        "\n",
        "class BertMaxPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states, mask):\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        first_token_tensor = compute_average_with_padding(hidden_states, mask)\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, config, args):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.args = args\n",
        "        self.SA = BertSelfAttention(config)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        zero_tensor = torch.tensor(np.zeros((inputs.size(0), 1, 1, self.args.max_seq_length),\n",
        "                                            dtype=np.float32), dtype=torch.float32).to(self.args.device)\n",
        "        SA_out = self.SA(inputs, zero_tensor)\n",
        "        return self.tanh(SA_out[0])\n",
        "\n",
        "\n",
        "class lcf_BERT(BertPreTrainedModel):\n",
        "    def __init__(self, config, args):\n",
        "        super(lcf_BERT, self).__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.args = args\n",
        "        self.config =config\n",
        "        self.bert = BertModel(config)\n",
        "        # self.bert_global_focus = self.bert\n",
        "        # self.bert_local_focus = copy.deepcopy(self.bert_global_focus) if args.use_single_bert else self.bert_global_focus\n",
        "        # self.embedder = nn.Embedding.from_pretrained(torch.from_numpy(args.word2vec).float(), freeze=True, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        # self.lstm = nn.LSTM(args.emb_size, 100, 1, batch_first=True, bidirectional=True)\n",
        "        # Co = 100\n",
        "        # self.conv13 = nn.Conv2d(1, Co, (3, 2*args.emb_size))\n",
        "        # self.conv14 = nn.Conv2d(1, Co, (4, 2*args.emb_size))\n",
        "        # self.conv15 = nn.Conv2d(1, Co, (5, 2*args.emb_size))\n",
        "        # self.dropout_1 = nn.Dropout(0.4)\n",
        "        # self.fc1 = nn.Linear(3*Co, config.num_labels)\n",
        "        # self.fc = nn.Linear(200, config.num_labels)\n",
        "        self.bert_SA = SelfAttention(config, args) ### change\n",
        "        self.linear_double_cdm_or_cdw = nn.Linear(config.hidden_size * 2,config.hidden_size)\n",
        "        self.linear_triple_lcf_global = nn.Linear(config.hidden_size * 3, config.hidden_size)\n",
        "        self.bert_pooler_org = BertPooler(config)\n",
        "        self.bert_pooler = BertMaxPooler(config) ### change\n",
        "        self.dense = nn.Linear(config.hidden_size, config.num_labels)\n",
        "        self.init_weights()\n",
        "\n",
        "    def conv_and_pool(self, x, conv):\n",
        "        x = F.gelu(conv(x)).squeeze(3) # (n, Co, W)\n",
        "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "        return x\n",
        "\n",
        "    def feature_dynamic_mask(self, text_local_indices, aspect_indices):\n",
        "        texts = text_local_indices\n",
        "        # mask_len = self.args.SRD\n",
        "        masked_text_raw_indices = torch.zeros((text_local_indices.size(0), self.args.max_seq_length, self.config.hidden_size),\n",
        "                                          dtype=torch.float)\n",
        "        \n",
        "        masked_text_raw_indices[:, 0, :] = torch.ones((text_local_indices.size(0), self.config.hidden_size), dtype=torch.float) \n",
        "        zero_tensor = torch.tensor(0).to(self.args.device)\n",
        "        for i in range(aspect_indices.shape[0]):\n",
        "            for j in range(aspect_indices[i].shape[0]):\n",
        "                if aspect_indices[i][j] == zero_tensor:\n",
        "                    break\n",
        "                else:\n",
        "                    indices = (text_local_indices[i] == aspect_indices[i][j]).nonzero()\n",
        "                    for k in indices:\n",
        "                        masked_text_raw_indices[i][k] = torch.ones(self.config.hidden_size, dtype=torch.float)\n",
        "        return masked_text_raw_indices.to(self.args.device)\n",
        "\n",
        "    # # create the weights tensor for local context features\n",
        "    # def feature_dynamic_weighted(self, text_local_indices, aspect_indices):\n",
        "    #     texts = text_local_indices\n",
        "    #     asps = aspect_indices\n",
        "    #     # mask_len = self.args.SRD\n",
        "    #     masked_text_raw_indices = torch.zeros((text_local_indices.size(0), self.args.max_seq_length, self.config.hidden_size),\n",
        "    #                                       dtype=torch.float)\n",
        "    #     for text_i, asp_i in zip(range(len(texts)), range(len(asps))):\n",
        "    #         asp_len = np.count_nonzero(asps[asp_i]) - 2\n",
        "    #         try:\n",
        "    #             asp_begin = np.argwhere(texts[text_i] == asps[asp_i][1])[0][0]\n",
        "    #             asp_avg_index = (asp_begin * 2 + asp_len) / 2\n",
        "    #         except:\n",
        "    #             continue\n",
        "    #         distances = np.zeros(np.count_nonzero(texts[text_i]), dtype=np.float32)\n",
        "    #         for i in range(1, np.count_nonzero(texts[text_i])-1):\n",
        "    #             if abs(i - asp_avg_index) + asp_len / 2 > self.args.SRD:\n",
        "    #                 distances[i] = 1 - (abs(i - asp_avg_index)+asp_len/2\n",
        "    #                                     - self.args.SRD)/np.count_nonzero(texts[text_i])\n",
        "    #             else:\n",
        "    #                 distances[i] = 1\n",
        "    #         for i in range(len(distances)):\n",
        "    #             masked_text_raw_indices[text_i][i] = masked_text_raw_indices[text_i][i] * distances[i]\n",
        "    #     # masked_text_raw_indices = torch.from_numpy(masked_text_raw_indices)\n",
        "    #     return masked_text_raw_indices.to(self.args.device)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_global_ids=None,\n",
        "        attention_mask_global=None,\n",
        "        token_global_type_ids=None,\n",
        "        input_local_ids=None,\n",
        "        attention_mask_local=None,\n",
        "        token_local_type_ids=None,\n",
        "        text_clean_indices=None,\n",
        "        aspect_indices=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "\n",
        "        # word_vectors = self.embedder(text_clean_indices)\n",
        "        # self.lstm.flatten_parameters()\n",
        "        # out, _ = self.lstm(word_vectors)\n",
        "        # # out = out.unsqueeze(1)   #### for using CNN\n",
        "        # # print(out.size())\n",
        "        # # print(out)\n",
        "        # logits = self.fc(out[:, -1, :])\n",
        "        # # print(logits.size())\n",
        "        # # print(logits)\n",
        "        # # raise ValueError\n",
        "        # # logits = self.fc(torch.div(word_vectors.sum(axis=1), word_vectors.shape[1]))\n",
        "\n",
        "        # global_outputs, _ = self.bert(\n",
        "        #     input_global_ids,\n",
        "        #     attention_mask=attention_mask_global,\n",
        "        #     token_type_ids=token_global_type_ids,\n",
        "        #     position_ids=position_ids,\n",
        "        #     head_mask=head_mask,\n",
        "        #     inputs_embeds=inputs_embeds,\n",
        "        # )\n",
        "\n",
        "        local_outputs, _ = self.bert(\n",
        "            input_local_ids,\n",
        "            attention_mask=attention_mask_local,\n",
        "            token_type_ids=token_local_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        # out_cat = torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "        # out_cat = self.linear_double_cdm_or_cdw(out_cat)\n",
        "        \n",
        "        # if self.args.local_context_focus == 'cdm':\n",
        "        #     masked_local_text_vec = self.feature_dynamic_mask(input_local_ids, aspect_indices)\n",
        "        #     local_outputs = torch.mul(local_outputs, masked_local_text_vec)\n",
        "        #     # out_cat = torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "        #     # out_cat = self.linear_double_cdm_or_cdw(out_cat)\n",
        "\n",
        "        # elif self.args.local_context_focus == 'cdw':\n",
        "        #     weighted_text_local_features = self.feature_dynamic_weighted(input_local_ids, aspect_indices)\n",
        "        #     local_outputs = torch.mul(local_outputs, weighted_text_local_features)\n",
        "        #     out_cat = torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "        #     out_cat = self.linear_double_cdm_or_cdw(out_cat)\n",
        "\n",
        "        # elif self.args.local_context_focus == 'lcf_fusion':\n",
        "        #     masked_local_text_vec = self.feature_dynamic_mask(text_local_indices, aspect_indices)\n",
        "        #     masked_local_out = torch.mul(local_outputs, masked_local_text_vec)\n",
        "        #     weighted_text_local_features = self.feature_dynamic_weighted(text_local_indices, aspect_indices)\n",
        "        #     weighted_local_out = torch.mul(local_outputs, weighted_text_local_features)\n",
        "        #     out_cat = torch.cat((masked_local_out, global_outputs, weighted_local_out), dim=-1)\n",
        "        #     out_cat = self.linear_triple_lcf_global(out_cat)\n",
        "\n",
        "        # self_attention_out = self.bert_SA(local_outputs)\n",
        "        self_attention_out = self.dropout(local_outputs)\n",
        "        local_pooled_out = self.bert_pooler_org(self_attention_out)\n",
        "        # self_attention_out = self.dropout(global_outputs)\n",
        "        # global_pooled_out = self.bert_pooler_org(self_attention_out)\n",
        "        # pooled_out = torch.cat((local_pooled_out, global_pooled_out), dim=-1)\n",
        "        logits = self.dense(local_pooled_out)\n",
        "        outputs = (logits,)\n",
        "\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "            else:\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/transformers/examples/ichi/lcf_ichi.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWhlcZgHS8a9",
        "outputId": "7c2ca1eb-72ac-4184-fc46-8c71967419d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile /content/transformers/examples/ichi/run_ichi.py\n",
        "import argparse\n",
        "import glob\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AlbertConfig,\n",
        "    AlbertForSequenceClassification,\n",
        "    AlbertTokenizer,\n",
        "    BertConfig,\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    DistilBertConfig,\n",
        "    DistilBertForSequenceClassification,\n",
        "    DistilBertTokenizer,\n",
        "    RobertaConfig,\n",
        "    RobertaForSequenceClassification,\n",
        "    RobertaTokenizer,\n",
        "    XLMConfig,\n",
        "    XLMForSequenceClassification,\n",
        "    XLMRobertaConfig,\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaTokenizer,\n",
        "    XLMTokenizer,\n",
        "    XLNetConfig,\n",
        "    XLNetForSequenceClassification,\n",
        "    XLNetTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "from lcf_ichi import lcf_BERT#, lcf_XLNET, lcf_XLM, lcf_Roberta, lcf_DistilBert, lcf_Albert, lcf_XLMRoberta\n",
        "from utils_ichi import convert_examples_to_features, ICHIProcessor, compute_metrics, load_and_cache_examples, Tokenizer, pad_and_truncate, build_embedding_matrix_glove, build_embedding_matrix_BioASQ\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "ALL_MODELS = sum(\n",
        "    (\n",
        "        tuple(conf.pretrained_config_archive_map.keys())\n",
        "        for conf in (\n",
        "            BertConfig,\n",
        "            XLNetConfig,\n",
        "            XLMConfig,\n",
        "            RobertaConfig,\n",
        "            DistilBertConfig,\n",
        "            AlbertConfig,\n",
        "            XLMRobertaConfig,\n",
        "        )\n",
        "    ),\n",
        "    (),\n",
        ")\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    \"bert\": (BertConfig, BertForSequenceClassification, BertTokenizer, lcf_BERT),\n",
        "}\n",
        "#     \"xlnet\": (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer, lcf_XLNET),\n",
        "#     \"xlm\": (XLMConfig, XLMForSequenceClassification, XLMTokenizer, lcf_XLM),\n",
        "#     \"roberta\": (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer, lcf_Roberta),\n",
        "#     \"distilbert\": (DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer, lcf_DistilBert),\n",
        "#     \"albert\": (AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer, lcf_Albert),\n",
        "#     \"xlmroberta\": (XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer, lcf_XLMRoberta),\n",
        "# }\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "\n",
        "def train(args, train_dataset, model, tokenizer, tokenizer_cleantext):\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer = SummaryWriter()\n",
        "\n",
        "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
        "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
        "\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "\n",
        "    # Check if saved optimizer or scheduler states exist\n",
        "    if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
        "        os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
        "    ):\n",
        "        # Load in optimizer and scheduler states\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
        "\n",
        "    if args.fp16:\n",
        "        try:\n",
        "            from apex import amp\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
        "\n",
        "    # multi-gpu training (should be after apex fp16 initialization)\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Distributed training (should be after apex fp16 initialization)\n",
        "    if args.local_rank != -1:\n",
        "        model = torch.nn.parallel.DistributedDataParallel(\n",
        "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True,\n",
        "        )\n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
        "    logger.info(\n",
        "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "        args.train_batch_size\n",
        "        * args.gradient_accumulation_steps\n",
        "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
        "    )\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    epochs_trained = 0\n",
        "    steps_trained_in_current_epoch = 0\n",
        "    # Check if continuing training from a checkpoint\n",
        "    if os.path.exists(args.model_name_or_path):\n",
        "        # set global_step to gobal_step of last saved checkpoint from model path\n",
        "        global_step = int(args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0])\n",
        "        epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "        steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "\n",
        "        logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "        logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
        "        logger.info(\"  Continuing training from global step %d\", global_step)\n",
        "        logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
        "\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.zero_grad()\n",
        "    train_iterator = trange(\n",
        "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0],\n",
        "    )\n",
        "    set_seed(args)  # Added here for reproductibility\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "\n",
        "            # Skip past any already trained steps if resuming training\n",
        "            if steps_trained_in_current_epoch > 0:\n",
        "                steps_trained_in_current_epoch -= 1\n",
        "                continue\n",
        "\n",
        "            model.train()\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "            inputs = {\"input_global_ids\": batch[0], \"attention_mask_global\": batch[2], \"input_local_ids\": batch[1], \"attention_mask_local\": batch[3], \"text_clean_indices\": batch[6], \"aspect_indices\": batch[7], \"labels\": batch[8]}\n",
        "            if args.model_type != \"distilbert\":\n",
        "                inputs[\"token_global_type_ids\"] = (\n",
        "                    batch[4] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                )\n",
        "                inputs[\"token_local_type_ids\"] = (\n",
        "                    batch[5] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                )\n",
        "            # inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[3]}\n",
        "            # if args.model_type != \"distilbert\":\n",
        "            #     inputs[\"token_type_ids\"] = (\n",
        "            #         batch[2] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "            #     )  # XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            if args.fp16:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                if args.fp16:\n",
        "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "\n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    logs = {}\n",
        "                    if (\n",
        "                        args.local_rank == -1 and args.evaluate_during_training\n",
        "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(args, model, tokenizer, tokenizer_cleantext)\n",
        "                        for key, value in results.items():\n",
        "                            eval_key = \"eval_{}\".format(key)\n",
        "                            logs[eval_key] = value\n",
        "\n",
        "                    loss_scalar = (tr_loss - logging_loss) / args.logging_steps\n",
        "                    learning_rate_scalar = scheduler.get_lr()[0]\n",
        "                    logs[\"learning_rate\"] = learning_rate_scalar\n",
        "                    logs[\"loss\"] = loss_scalar\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                    for key, value in logs.items():\n",
        "                        tb_writer.add_scalar(key, value, global_step)\n",
        "                    print(json.dumps({**logs, **{\"step\": global_step}}))\n",
        "\n",
        "                # if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                #     # Save model checkpoint\n",
        "                #     output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n",
        "                #     if not os.path.exists(output_dir):\n",
        "                #         os.makedirs(output_dir)\n",
        "                #     # model_to_save = (\n",
        "                #     #     model.module if hasattr(model, \"module\") else model\n",
        "                #     # )  # Take care of distributed/parallel training\n",
        "                #     # model_to_save.save_pretrained(output_dir)\n",
        "                #     torch.save(model.state_dict(), args.output_dir)\n",
        "                #     tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "                #     torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                #     logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "                #     torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "                #     torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "                #     logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                epoch_iterator.close()\n",
        "                break\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step\n",
        "\n",
        "\n",
        "def evaluate(args, model, tokenizer, tokenizer_cleantext, prefix=\"\"):\n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    eval_task_names = (\"ichi\",)\n",
        "    eval_outputs_dirs = (args.output_dir,)\n",
        "\n",
        "    results = {}\n",
        "    for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n",
        "        eval_dataset, tokenizer_cleantext = load_and_cache_examples(args, eval_task, tokenizer, tokenizer_cleantext, evaluate=True)\n",
        "\n",
        "        if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(eval_output_dir)\n",
        "\n",
        "        args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "        # Note that DistributedSampler samples randomly\n",
        "        eval_sampler = SequentialSampler(eval_dataset)\n",
        "        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
        "\n",
        "        # multi-gpu eval\n",
        "        if args.n_gpu > 1:\n",
        "            model = torch.nn.DataParallel(model)\n",
        "\n",
        "        # Eval!\n",
        "        logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "        logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "        logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "        eval_loss = 0.0\n",
        "        nb_eval_steps = 0\n",
        "        preds = None\n",
        "        preds_original = None\n",
        "        out_label_ids = None\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "            model.eval()\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                inputs = {\"input_global_ids\": batch[0], \"attention_mask_global\": batch[2], \"input_local_ids\": batch[1], \"attention_mask_local\": batch[3], \"text_clean_indices\": batch[6], \"aspect_indices\": batch[7], \"labels\": batch[8]}\n",
        "                if args.model_type != \"distilbert\":\n",
        "                    inputs[\"token_global_type_ids\"] = (\n",
        "                        batch[4] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                    )\n",
        "                    inputs[\"token_local_type_ids\"] = (\n",
        "                        batch[5] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                    )  # XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids\n",
        "                outputs = model(**inputs)\n",
        "                tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "                eval_loss += tmp_eval_loss.mean().item()\n",
        "            nb_eval_steps += 1\n",
        "            if preds is None:\n",
        "                preds = logits.detach().cpu().numpy()\n",
        "                preds_original = logits.detach().cpu().numpy()\n",
        "                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
        "            else:\n",
        "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "                preds_original = np.append(preds_original, logits.detach().cpu().numpy(), axis=0)\n",
        "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "        eval_loss = eval_loss / nb_eval_steps\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "        result = compute_metrics(preds, out_label_ids) ######################update kar !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "        results.update(result)\n",
        "\n",
        "        output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
        "        with open(output_eval_file, \"w\") as writer:\n",
        "            logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "            for key in sorted(result.keys()):\n",
        "                logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "            # for a in preds:\n",
        "            #     writer.write(str(a)+'\\n')\n",
        "            writer.write('[')\n",
        "            for a in preds_original:\n",
        "                writer.write('[')\n",
        "                for c in range(len(a)):\n",
        "                    b = a[c]\n",
        "                    if c!=6:\n",
        "                        writer.write(str(b)+',')\n",
        "                    else:\n",
        "                        writer.write(str(b))\n",
        "                writer.write(']')\n",
        "                writer.write('\\n')\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Required parameters\n",
        "    parser.add_argument(\n",
        "        \"--data_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_type\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_name_or_path\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Path to pre-trained model or shortcut name selected in the list: \" + \", \".join(ALL_MODELS),\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
        "    )\n",
        "\n",
        "    # Other parameters\n",
        "    parser.add_argument(\n",
        "        \"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--tokenizer_name\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--cache_dir\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Where do you want to store the pre-trained models downloaded from s3\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_seq_length\",\n",
        "        default=128,\n",
        "        type=int,\n",
        "        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "        \"than this will be truncated, sequences shorter will be padded.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--embedding_dim_word2vec\",\n",
        "        default=300,\n",
        "        type=int,\n",
        "        help=\"embedding dimension for the word vectors in the medical module\",\n",
        "    )\n",
        "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
        "    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n",
        "    parser.add_argument(\n",
        "        \"--evaluate_during_training\", action=\"store_true\", help=\"Rul evaluation during training at each logging step.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--do_lower_case\", action=\"store_true\", help=\"Set this flag if you are using an uncased model.\",\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--per_gpu_train_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for training.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--per_gpu_eval_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for evaluation.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--gradient_accumulation_steps\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
        "    )\n",
        "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
        "    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
        "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
        "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
        "    parser.add_argument(\n",
        "        \"--num_train_epochs\", default=3.0, type=float, help=\"Total number of training epochs to perform.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_steps\",\n",
        "        default=-1,\n",
        "        type=int,\n",
        "        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
        "    )\n",
        "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
        "\n",
        "    parser.add_argument(\"--logging_steps\", type=int, default=50, help=\"Log every X updates steps.\")\n",
        "    parser.add_argument(\"--save_steps\", type=int, default=10000, help=\"Save checkpoint every X updates steps.\")\n",
        "    parser.add_argument(\n",
        "        \"--eval_all_checkpoints\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
        "    )\n",
        "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_output_dir\", action=\"store_true\", help=\"Overwrite the content of the output directory\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_cache\", action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\",\n",
        "    )\n",
        "    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--fp16\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--fp16_opt_level\",\n",
        "        type=str,\n",
        "        default=\"O1\",\n",
        "        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
        "        \"See details at https://nvidia.github.io/apex/amp.html\",\n",
        "    )\n",
        "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n",
        "    parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if (\n",
        "        os.path.exists(args.output_dir)\n",
        "        and os.listdir(args.output_dir)\n",
        "        and args.do_train\n",
        "        and not args.overwrite_output_dir\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
        "                args.output_dir\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Setup distant debugging if needed\n",
        "    if args.server_ip and args.server_port:\n",
        "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
        "        import ptvsd\n",
        "\n",
        "        print(\"Waiting for debugger attach\")\n",
        "        ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n",
        "        ptvsd.wait_for_attach()\n",
        "\n",
        "    # Setup CUDA, GPU & distributed training\n",
        "    if args.local_rank == -1 or args.no_cuda:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
        "        args.n_gpu = torch.cuda.device_count()\n",
        "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "        torch.cuda.set_device(args.local_rank)\n",
        "        device = torch.device(\"cuda\", args.local_rank)\n",
        "        torch.distributed.init_process_group(backend=\"nccl\")\n",
        "        args.n_gpu = 1\n",
        "    args.device = device\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
        "    )\n",
        "    logger.warning(\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        args.local_rank,\n",
        "        device,\n",
        "        args.n_gpu,\n",
        "        bool(args.local_rank != -1),\n",
        "        args.fp16,\n",
        "    )\n",
        "\n",
        "    # Set seed\n",
        "    set_seed(args)\n",
        "\n",
        "    # Prepare GLUE task\n",
        "    args.task_name = 'ichi'\n",
        "    processor = ICHIProcessor()\n",
        "    args.output_mode = \"classification\"\n",
        "    label_list = processor.get_labels()\n",
        "    num_labels = len(label_list)\n",
        "\n",
        "    # Load pretrained model and tokenizer\n",
        "    if args.local_rank not in [-1, 0]:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
        "\n",
        "    args.model_type = args.model_type.lower()\n",
        "    config_class, model_class, tokenizer_class, lcf_model = MODEL_CLASSES[args.model_type]\n",
        "    config = config_class.from_pretrained(\n",
        "        args.config_name if args.config_name else args.model_name_or_path,\n",
        "        num_labels=num_labels,\n",
        "        finetuning_task=args.task_name,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    tokenizer = tokenizer_class.from_pretrained(\n",
        "        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
        "        do_lower_case=args.do_lower_case,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    tokenizer_cleantext = Tokenizer(max_seq_len = 1600, max_num_words=20000,lower=True)\n",
        "    # model = model_class.from_pretrained(\n",
        "    #     args.model_name_or_path,\n",
        "    #     from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "    #     config=config,\n",
        "    #     cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    #     force_download=True,\n",
        "    # )\n",
        "\n",
        "    args.use_single_bert = False\n",
        "    args.local_context_focus = 'cdm'\n",
        "    args.embedding_type = 'glove'\n",
        "\n",
        "    cached_embeddingmatrix_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cachedword2vec_{}_{}\".format(\n",
        "            str(args.task_name),\n",
        "            str(\"glove\"),\n",
        "        ),\n",
        "    )\n",
        "    cached_embeddingmatrix_path = \".\"\n",
        "    \n",
        "    train_dataset, tokenizer_cleantext = load_and_cache_examples(args, args.task_name, tokenizer, tokenizer_cleantext, evaluate=False)\n",
        "    # embedding_matrix = build_embedding_matrix_glove(tokenizer_cleantext.word2idx, args.embedding_dim_word2vec, cached_embeddingmatrix_file, cached_embeddingmatrix_path)\n",
        "    # print(embedding_matrix.shape)\n",
        "    # print(tokenizer_cleantext.word2idx)\n",
        "    \n",
        "    # args.word2vec = embedding_matrix\n",
        "    # args.emb_size = embedding_matrix.shape[1]\n",
        "    model = lcf_model.from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "        config=config,\n",
        "        args=args,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    # model = lcf_Roberta.from_pretrained(\n",
        "    #     \"/home/bt1/17CS10037/new_transformers/transformers/roberta-large-pytorch_model.bin\",\n",
        "    #     from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "    #     config=config,\n",
        "    #     args=args,\n",
        "    #     cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    #     force_download=True,\n",
        "    # )\n",
        "\n",
        "    if args.local_rank == 0:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
        "\n",
        "    model.to(args.device)\n",
        "\n",
        "    logger.info(\"Training/evaluation parameters %s\", args)\n",
        "    \n",
        "    # Training\n",
        "    if args.do_train:\n",
        "        # train_dataset, tokenizer_cleantext = load_and_cache_examples(args, args.task_name, tokenizer, tokenizer_cleantext, evaluate=False)\n",
        "        # matrix = build_embedding_matrix_glove(tokenizer_cleantext.word2idx, args.embedding_dim_word2vec, cached_glove_embeddingmatrix_file, cached_glove_embeddingmatrix_path)\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer, tokenizer_cleantext)\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "    result = evaluate(args, model, tokenizer, tokenizer_cleantext)\n",
        "    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
        "        # Create output directory if needed\n",
        "        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(args.output_dir)\n",
        "\n",
        "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        # model_to_save = (\n",
        "        #     model.module if hasattr(model, \"module\") else model\n",
        "        # )  # Take care of distributed/parallel training\n",
        "        # model_to_save.save_pretrained(args.output_dir)\n",
        "        model_name = \"{}.pt\".format(args.model_type)\n",
        "        torch.save(model.state_dict(), os.path.join(args.output_dir,model_name))\n",
        "        tokenizer.save_pretrained(args.output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
        "\n",
        "        # Load a trained model and vocabulary that you have fine-tuned\n",
        "        # model = model_class.from_pretrained(args.output_dir)\n",
        "        model = lcf_model(config, args)\n",
        "        model.load_state_dict(torch.load(os.path.join(args.output_dir,model_name)))\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.output_dir)\n",
        "        model.to(args.device)\n",
        "\n",
        "    # Evaluation\n",
        "    results = {}\n",
        "    if args.do_eval and args.local_rank in [-1, 0]:\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
        "        cached_tokenizer_cleantext_file = os.path.join(\n",
        "            args.data_dir,\n",
        "            \"cachedtokenizer_{}_{}_{}\".format(\n",
        "                list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "                str(args.embedding_type),\n",
        "                str(args.task_name),\n",
        "            ),\n",
        "        )\n",
        "        if os.path.exists(cached_tokenizer_cleantext_file):\n",
        "            print('loading tokenizer from cache:', cached_tokenizer_cleantext_file)\n",
        "            tokenizer_cleantext = pickle.load(open(cached_tokenizer_cleantext_file, 'rb'))\n",
        "        checkpoints = [args.output_dir]\n",
        "        if args.eval_all_checkpoints:\n",
        "            checkpoints = list(\n",
        "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
        "            )\n",
        "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
        "            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
        "\n",
        "            # model = model_class.from_pretrained(checkpoint)\n",
        "            # model = lcf_model.from_pretrained(\n",
        "            #     args.model_name_or_path,\n",
        "            #     from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "            #     config=config,\n",
        "            #     args=args,\n",
        "            #     cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "            # )\n",
        "\n",
        "            model = lcf_model(config, args)\n",
        "            model_name = \"{}.pt\".format(args.model_type)\n",
        "            model.load_state_dict(torch.load(os.path.join(args.output_dir,model_name)))\n",
        "            model.to(args.device)\n",
        "            result = evaluate(args, model, tokenizer, tokenizer_cleantext, prefix=prefix)\n",
        "            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
        "            results.update(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/transformers/examples/ichi/run_ichi.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmpFdc6sbALY",
        "outputId": "5a82083f-307b-4fc4-f4c8-8f4018b56f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python ./examples/ichi/run_ichi.py --model_type bert --model_name_or_path bert-base-uncased --do_lower_case --do_train --do_eval --data_dir ./data/ichi --max_seq_length 256 --per_gpu_eval_batch_size=16 --per_gpu_train_batch_size=16 --learning_rate 5e-5 --num_train_epochs 2 --output_dir ./tmp/ichi_bert_base_new --overwrite_output_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-16 16:00:34.494705: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "10/16/2020 16:00:36 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "10/16/2020 16:00:36 - INFO - filelock -   Lock 139953782287272 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "10/16/2020 16:00:36 - INFO - filelock -   Lock 139953782287272 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "10/16/2020 16:00:36 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "10/16/2020 16:00:36 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"ichi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 7,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "10/16/2020 16:00:37 - INFO - filelock -   Lock 139953782599464 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "10/16/2020 16:00:37 - INFO - filelock -   Lock 139953782599464 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "10/16/2020 16:00:37 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "10/16/2020 16:00:37 - INFO - utils_ichi -   Loading features from cached file ./data/ichi/cached_train_bert-base-uncased_256_ichi\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_ichi\n",
            "10/16/2020 16:00:42 - INFO - filelock -   Lock 139953375400792 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "10/16/2020 16:00:42 - INFO - filelock -   Lock 139953375400792 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "10/16/2020 16:00:42 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "10/16/2020 16:00:46 - INFO - transformers.modeling_utils -   Weights of lcf_BERT not initialized from pretrained model: ['bert_SA.SA.query.weight', 'bert_SA.SA.query.bias', 'bert_SA.SA.key.weight', 'bert_SA.SA.key.bias', 'bert_SA.SA.value.weight', 'bert_SA.SA.value.bias', 'linear_double_cdm_or_cdw.weight', 'linear_double_cdm_or_cdw.bias', 'linear_triple_lcf_global.weight', 'linear_triple_lcf_global.bias', 'bert_pooler_org.dense.weight', 'bert_pooler_org.dense.bias', 'bert_pooler.dense.weight', 'bert_pooler.dense.bias', 'dense.weight', 'dense.bias']\n",
            "10/16/2020 16:00:46 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in lcf_BERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "10/16/2020 16:00:51 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='./data/ichi', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, embedding_dim_word2vec=300, embedding_type='glove', eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_context_focus='cdm', local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=256, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=2.0, output_dir='./tmp/ichi_bert_base_new', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=16, save_steps=10000, seed=42, server_ip='', server_port='', task_name='ichi', tokenizer_name='', use_single_bert=False, warmup_steps=0, weight_decay=0.0)\n",
            "10/16/2020 16:00:51 - INFO - __main__ -   ***** Running training *****\n",
            "10/16/2020 16:00:51 - INFO - __main__ -     Num examples = 8000\n",
            "10/16/2020 16:00:51 - INFO - __main__ -     Num Epochs = 2\n",
            "10/16/2020 16:00:51 - INFO - __main__ -     Instantaneous batch size per GPU = 16\n",
            "10/16/2020 16:00:51 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "10/16/2020 16:00:51 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "10/16/2020 16:00:51 - INFO - __main__ -     Total optimization steps = 1000\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/500 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   0% 1/500 [00:00<04:00,  2.08it/s]\u001b[A\n",
            "Iteration:   0% 2/500 [00:00<03:56,  2.11it/s]\u001b[A\n",
            "Iteration:   1% 3/500 [00:01<03:53,  2.13it/s]\u001b[A\n",
            "Iteration:   1% 4/500 [00:01<03:51,  2.14it/s]\u001b[A\n",
            "Iteration:   1% 5/500 [00:02<03:51,  2.14it/s]\u001b[A\n",
            "Iteration:   1% 6/500 [00:02<03:49,  2.15it/s]\u001b[A\n",
            "Iteration:   1% 7/500 [00:03<03:48,  2.16it/s]\u001b[A\n",
            "Iteration:   2% 8/500 [00:03<03:47,  2.16it/s]\u001b[A\n",
            "Iteration:   2% 9/500 [00:04<03:46,  2.16it/s]\u001b[A\n",
            "Iteration:   2% 10/500 [00:04<03:46,  2.17it/s]\u001b[A\n",
            "Iteration:   2% 11/500 [00:05<03:45,  2.17it/s]\u001b[A\n",
            "Iteration:   2% 12/500 [00:05<03:44,  2.17it/s]\u001b[A\n",
            "Iteration:   3% 13/500 [00:06<03:43,  2.18it/s]\u001b[A\n",
            "Iteration:   3% 14/500 [00:06<03:43,  2.17it/s]\u001b[A\n",
            "Iteration:   3% 15/500 [00:06<03:42,  2.18it/s]\u001b[A\n",
            "Iteration:   3% 16/500 [00:07<03:43,  2.17it/s]\u001b[A\n",
            "Iteration:   3% 17/500 [00:07<03:42,  2.17it/s]\u001b[A\n",
            "Iteration:   4% 18/500 [00:08<03:42,  2.17it/s]\u001b[A\n",
            "Iteration:   4% 19/500 [00:08<03:41,  2.17it/s]\u001b[A\n",
            "Iteration:   4% 20/500 [00:09<03:41,  2.17it/s]\u001b[A\n",
            "Iteration:   4% 21/500 [00:09<03:40,  2.17it/s]\u001b[A\n",
            "Iteration:   4% 22/500 [00:10<03:39,  2.17it/s]\u001b[A\n",
            "Iteration:   5% 23/500 [00:10<03:39,  2.17it/s]\u001b[A\n",
            "Iteration:   5% 24/500 [00:11<03:40,  2.16it/s]\u001b[A\n",
            "Iteration:   5% 25/500 [00:11<03:39,  2.16it/s]\u001b[A\n",
            "Iteration:   5% 26/500 [00:12<03:38,  2.17it/s]\u001b[A\n",
            "Iteration:   5% 27/500 [00:12<03:37,  2.17it/s]\u001b[A\n",
            "Iteration:   6% 28/500 [00:12<03:37,  2.17it/s]\u001b[A\n",
            "Iteration:   6% 29/500 [00:13<03:37,  2.17it/s]\u001b[A\n",
            "Iteration:   6% 30/500 [00:13<03:36,  2.17it/s]\u001b[A\n",
            "Iteration:   6% 31/500 [00:14<03:35,  2.17it/s]\u001b[A\n",
            "Iteration:   6% 32/500 [00:14<03:35,  2.17it/s]\u001b[A\n",
            "Iteration:   7% 33/500 [00:15<03:34,  2.17it/s]\u001b[A\n",
            "Iteration:   7% 34/500 [00:15<03:35,  2.17it/s]\u001b[A\n",
            "Iteration:   7% 35/500 [00:16<03:35,  2.16it/s]\u001b[A\n",
            "Iteration:   7% 36/500 [00:16<03:35,  2.15it/s]\u001b[A\n",
            "Iteration:   7% 37/500 [00:17<03:37,  2.13it/s]\u001b[A\n",
            "Iteration:   8% 38/500 [00:17<03:35,  2.14it/s]\u001b[A\n",
            "Iteration:   8% 39/500 [00:18<03:34,  2.15it/s]\u001b[A\n",
            "Iteration:   8% 40/500 [00:18<03:32,  2.16it/s]\u001b[A\n",
            "Iteration:   8% 41/500 [00:18<03:31,  2.17it/s]\u001b[A\n",
            "Iteration:   8% 42/500 [00:19<03:32,  2.16it/s]\u001b[A\n",
            "Iteration:   9% 43/500 [00:19<03:31,  2.16it/s]\u001b[A\n",
            "Iteration:   9% 44/500 [00:20<03:30,  2.17it/s]\u001b[A\n",
            "Iteration:   9% 45/500 [00:20<03:29,  2.17it/s]\u001b[A\n",
            "Iteration:   9% 46/500 [00:21<03:28,  2.17it/s]\u001b[A\n",
            "Iteration:   9% 47/500 [00:21<03:29,  2.17it/s]\u001b[A\n",
            "Iteration:  10% 48/500 [00:22<03:28,  2.17it/s]\u001b[A\n",
            "Iteration:  10% 49/500 [00:22<03:28,  2.17it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"learning_rate\": 4.75e-05, \"loss\": 1.7327789878845214, \"step\": 50}\n",
            "\n",
            "Iteration:  10% 50/500 [00:23<03:27,  2.17it/s]\u001b[A\n",
            "Iteration:  10% 51/500 [00:23<03:26,  2.17it/s]\u001b[A\n",
            "Iteration:  10% 52/500 [00:24<03:26,  2.17it/s]\u001b[A\n",
            "Iteration:  11% 53/500 [00:24<03:26,  2.17it/s]\u001b[A\n",
            "Iteration:  11% 54/500 [00:24<03:25,  2.17it/s]\u001b[A\n",
            "Iteration:  11% 55/500 [00:25<03:24,  2.17it/s]\u001b[A\n",
            "Iteration:  11% 56/500 [00:25<03:24,  2.17it/s]\u001b[A\n",
            "Iteration:  11% 57/500 [00:26<03:24,  2.17it/s]\u001b[A\n",
            "Iteration:  12% 58/500 [00:26<03:23,  2.17it/s]\u001b[A\n",
            "Iteration:  12% 59/500 [00:27<03:23,  2.17it/s]\u001b[A\n",
            "Iteration:  12% 60/500 [00:27<03:22,  2.17it/s]\u001b[A\n",
            "Iteration:  12% 61/500 [00:28<03:22,  2.17it/s]\u001b[A\n",
            "Iteration:  12% 62/500 [00:28<03:21,  2.17it/s]\u001b[A\n",
            "Iteration:  13% 63/500 [00:29<03:21,  2.17it/s]\u001b[A\n",
            "Iteration:  13% 64/500 [00:29<03:21,  2.16it/s]\u001b[A\n",
            "Iteration:  13% 65/500 [00:30<03:21,  2.16it/s]\u001b[A\n",
            "Iteration:  13% 66/500 [00:30<03:20,  2.16it/s]\u001b[A\n",
            "Iteration:  13% 67/500 [00:30<03:21,  2.15it/s]\u001b[A\n",
            "Iteration:  14% 68/500 [00:31<03:20,  2.16it/s]\u001b[A\n",
            "Iteration:  14% 69/500 [00:31<03:19,  2.16it/s]\u001b[A\n",
            "Iteration:  14% 70/500 [00:32<03:18,  2.16it/s]\u001b[A\n",
            "Iteration:  14% 71/500 [00:32<03:18,  2.16it/s]\u001b[A\n",
            "Iteration:  14% 72/500 [00:33<03:17,  2.17it/s]\u001b[A\n",
            "Iteration:  15% 73/500 [00:33<03:16,  2.17it/s]\u001b[A\n",
            "Iteration:  15% 74/500 [00:34<03:16,  2.17it/s]\u001b[A\n",
            "Iteration:  15% 75/500 [00:34<03:16,  2.16it/s]\u001b[A\n",
            "Iteration:  15% 76/500 [00:35<03:15,  2.17it/s]\u001b[A\n",
            "Iteration:  15% 77/500 [00:35<03:15,  2.17it/s]\u001b[A\n",
            "Iteration:  16% 78/500 [00:36<03:15,  2.16it/s]\u001b[A\n",
            "Iteration:  16% 79/500 [00:36<03:14,  2.17it/s]\u001b[A\n",
            "Iteration:  16% 80/500 [00:36<03:13,  2.17it/s]\u001b[A\n",
            "Iteration:  16% 81/500 [00:37<03:12,  2.17it/s]\u001b[A\n",
            "Iteration:  16% 82/500 [00:37<03:12,  2.17it/s]\u001b[A\n",
            "Iteration:  17% 83/500 [00:38<03:11,  2.18it/s]\u001b[A\n",
            "Iteration:  17% 84/500 [00:38<03:11,  2.18it/s]\u001b[A\n",
            "Iteration:  17% 85/500 [00:39<03:10,  2.18it/s]\u001b[A\n",
            "Iteration:  17% 86/500 [00:39<03:11,  2.16it/s]\u001b[A\n",
            "Iteration:  17% 87/500 [00:40<03:11,  2.15it/s]\u001b[A\n",
            "Iteration:  18% 88/500 [00:40<03:10,  2.16it/s]\u001b[A\n",
            "Iteration:  18% 89/500 [00:41<03:09,  2.16it/s]\u001b[A\n",
            "Iteration:  18% 90/500 [00:41<03:09,  2.17it/s]\u001b[A\n",
            "Iteration:  18% 91/500 [00:42<03:08,  2.17it/s]\u001b[A\n",
            "Iteration:  18% 92/500 [00:42<03:08,  2.16it/s]\u001b[A\n",
            "Iteration:  19% 93/500 [00:42<03:09,  2.14it/s]\u001b[A\n",
            "Iteration:  19% 94/500 [00:43<03:08,  2.15it/s]\u001b[A\n",
            "Iteration:  19% 95/500 [00:43<03:07,  2.16it/s]\u001b[A\n",
            "Iteration:  19% 96/500 [00:44<03:06,  2.16it/s]\u001b[A\n",
            "Iteration:  19% 97/500 [00:44<03:06,  2.17it/s]\u001b[A\n",
            "Iteration:  20% 98/500 [00:45<03:06,  2.16it/s]\u001b[A\n",
            "Iteration:  20% 99/500 [00:45<03:05,  2.16it/s]\u001b[A{\"learning_rate\": 4.5e-05, \"loss\": 1.2450772190093995, \"step\": 100}\n",
            "\n",
            "Iteration:  20% 100/500 [00:46<03:04,  2.16it/s]\u001b[A\n",
            "Iteration:  20% 101/500 [00:46<03:04,  2.17it/s]\u001b[A\n",
            "Iteration:  20% 102/500 [00:47<03:03,  2.17it/s]\u001b[A\n",
            "Iteration:  21% 103/500 [00:47<03:03,  2.17it/s]\u001b[A\n",
            "Iteration:  21% 104/500 [00:48<03:02,  2.17it/s]\u001b[A\n",
            "Iteration:  21% 105/500 [00:48<03:01,  2.17it/s]\u001b[A\n",
            "Iteration:  21% 106/500 [00:48<03:01,  2.17it/s]\u001b[A\n",
            "Iteration:  21% 107/500 [00:49<03:00,  2.18it/s]\u001b[A\n",
            "Iteration:  22% 108/500 [00:49<03:00,  2.18it/s]\u001b[A\n",
            "Iteration:  22% 109/500 [00:50<02:59,  2.18it/s]\u001b[A\n",
            "Iteration:  22% 110/500 [00:50<02:59,  2.17it/s]\u001b[A\n",
            "Iteration:  22% 111/500 [00:51<02:59,  2.17it/s]\u001b[A\n",
            "Iteration:  22% 112/500 [00:51<02:59,  2.17it/s]\u001b[A\n",
            "Iteration:  23% 113/500 [00:52<02:58,  2.17it/s]\u001b[A\n",
            "Iteration:  23% 114/500 [00:52<02:57,  2.17it/s]\u001b[A\n",
            "Iteration:  23% 115/500 [00:53<02:57,  2.17it/s]\u001b[A\n",
            "Iteration:  23% 116/500 [00:53<02:57,  2.17it/s]\u001b[A\n",
            "Iteration:  23% 117/500 [00:54<02:56,  2.17it/s]\u001b[A\n",
            "Iteration:  24% 118/500 [00:54<02:57,  2.15it/s]\u001b[A\n",
            "Iteration:  24% 119/500 [00:54<02:57,  2.15it/s]\u001b[A\n",
            "Iteration:  24% 120/500 [00:55<02:55,  2.16it/s]\u001b[A\n",
            "Iteration:  24% 121/500 [00:55<02:56,  2.15it/s]\u001b[A\n",
            "Iteration:  24% 122/500 [00:56<02:55,  2.16it/s]\u001b[A\n",
            "Iteration:  25% 123/500 [00:56<02:54,  2.16it/s]\u001b[A\n",
            "Iteration:  25% 124/500 [00:57<02:53,  2.17it/s]\u001b[A\n",
            "Iteration:  25% 125/500 [00:57<02:53,  2.17it/s]\u001b[A\n",
            "Iteration:  25% 126/500 [00:58<02:52,  2.17it/s]\u001b[A\n",
            "Iteration:  25% 127/500 [00:58<02:51,  2.17it/s]\u001b[A\n",
            "Iteration:  26% 128/500 [00:59<02:51,  2.17it/s]\u001b[A\n",
            "Iteration:  26% 129/500 [00:59<02:53,  2.14it/s]\u001b[A\n",
            "Iteration:  26% 130/500 [01:00<02:52,  2.15it/s]\u001b[A\n",
            "Iteration:  26% 131/500 [01:00<02:51,  2.16it/s]\u001b[A\n",
            "Iteration:  26% 132/500 [01:00<02:50,  2.15it/s]\u001b[A\n",
            "Iteration:  27% 133/500 [01:01<02:49,  2.16it/s]\u001b[A\n",
            "Iteration:  27% 134/500 [01:01<02:49,  2.16it/s]\u001b[A\n",
            "Iteration:  27% 135/500 [01:02<02:48,  2.17it/s]\u001b[A\n",
            "Iteration:  27% 136/500 [01:02<02:48,  2.17it/s]\u001b[A\n",
            "Iteration:  27% 137/500 [01:03<02:47,  2.17it/s]\u001b[A\n",
            "Iteration:  28% 138/500 [01:03<02:46,  2.17it/s]\u001b[A\n",
            "Iteration:  28% 139/500 [01:04<02:46,  2.17it/s]\u001b[A\n",
            "Iteration:  28% 140/500 [01:04<02:45,  2.17it/s]\u001b[A\n",
            "Iteration:  28% 141/500 [01:05<02:45,  2.17it/s]\u001b[A\n",
            "Iteration:  28% 142/500 [01:05<02:44,  2.17it/s]\u001b[A\n",
            "Iteration:  29% 143/500 [01:06<02:44,  2.16it/s]\u001b[A\n",
            "Iteration:  29% 144/500 [01:06<02:44,  2.17it/s]\u001b[A\n",
            "Iteration:  29% 145/500 [01:06<02:43,  2.17it/s]\u001b[A\n",
            "Iteration:  29% 146/500 [01:07<02:42,  2.17it/s]\u001b[A\n",
            "Iteration:  29% 147/500 [01:07<02:42,  2.18it/s]\u001b[A\n",
            "Iteration:  30% 148/500 [01:08<02:41,  2.18it/s]\u001b[A\n",
            "Iteration:  30% 149/500 [01:08<02:42,  2.16it/s]\u001b[A{\"learning_rate\": 4.25e-05, \"loss\": 1.1088671684265137, \"step\": 150}\n",
            "\n",
            "Iteration:  30% 150/500 [01:09<02:41,  2.16it/s]\u001b[A\n",
            "Iteration:  30% 151/500 [01:09<02:41,  2.17it/s]\u001b[A\n",
            "Iteration:  30% 152/500 [01:10<02:40,  2.17it/s]\u001b[A\n",
            "Iteration:  31% 153/500 [01:10<02:39,  2.17it/s]\u001b[A\n",
            "Iteration:  31% 154/500 [01:11<02:40,  2.16it/s]\u001b[A\n",
            "Iteration:  31% 155/500 [01:11<02:39,  2.16it/s]\u001b[A\n",
            "Iteration:  31% 156/500 [01:12<02:38,  2.17it/s]\u001b[A\n",
            "Iteration:  31% 157/500 [01:12<02:37,  2.17it/s]\u001b[A\n",
            "Iteration:  32% 158/500 [01:12<02:38,  2.16it/s]\u001b[A\n",
            "Iteration:  32% 159/500 [01:13<02:37,  2.17it/s]\u001b[A\n",
            "Iteration:  32% 160/500 [01:13<02:37,  2.16it/s]\u001b[A\n",
            "Iteration:  32% 161/500 [01:14<02:36,  2.16it/s]\u001b[A\n",
            "Iteration:  32% 162/500 [01:14<02:36,  2.16it/s]\u001b[A\n",
            "Iteration:  33% 163/500 [01:15<02:35,  2.17it/s]\u001b[A\n",
            "Iteration:  33% 164/500 [01:15<02:35,  2.17it/s]\u001b[A\n",
            "Iteration:  33% 165/500 [01:16<02:35,  2.16it/s]\u001b[A\n",
            "Iteration:  33% 166/500 [01:16<02:34,  2.16it/s]\u001b[A\n",
            "Iteration:  33% 167/500 [01:17<02:33,  2.17it/s]\u001b[A\n",
            "Iteration:  34% 168/500 [01:17<02:33,  2.17it/s]\u001b[A\n",
            "Iteration:  34% 169/500 [01:18<02:33,  2.16it/s]\u001b[A\n",
            "Iteration:  34% 170/500 [01:18<02:32,  2.16it/s]\u001b[A\n",
            "Iteration:  34% 171/500 [01:18<02:31,  2.17it/s]\u001b[A\n",
            "Iteration:  34% 172/500 [01:19<02:31,  2.17it/s]\u001b[A\n",
            "Iteration:  35% 173/500 [01:19<02:31,  2.17it/s]\u001b[A\n",
            "Iteration:  35% 174/500 [01:20<02:30,  2.17it/s]\u001b[A\n",
            "Iteration:  35% 175/500 [01:20<02:29,  2.17it/s]\u001b[A\n",
            "Iteration:  35% 176/500 [01:21<02:30,  2.16it/s]\u001b[A\n",
            "Iteration:  35% 177/500 [01:21<02:29,  2.16it/s]\u001b[A\n",
            "Iteration:  36% 178/500 [01:22<02:29,  2.16it/s]\u001b[A\n",
            "Iteration:  36% 179/500 [01:22<02:28,  2.17it/s]\u001b[A\n",
            "Iteration:  36% 180/500 [01:23<02:29,  2.14it/s]\u001b[A\n",
            "Iteration:  36% 181/500 [01:23<02:28,  2.15it/s]\u001b[A\n",
            "Iteration:  36% 182/500 [01:24<02:27,  2.16it/s]\u001b[A\n",
            "Iteration:  37% 183/500 [01:24<02:26,  2.16it/s]\u001b[A\n",
            "Iteration:  37% 184/500 [01:24<02:25,  2.17it/s]\u001b[A\n",
            "Iteration:  37% 185/500 [01:25<02:25,  2.17it/s]\u001b[A\n",
            "Iteration:  37% 186/500 [01:25<02:24,  2.17it/s]\u001b[A\n",
            "Iteration:  37% 187/500 [01:26<02:24,  2.17it/s]\u001b[A\n",
            "Iteration:  38% 188/500 [01:26<02:23,  2.17it/s]\u001b[A\n",
            "Iteration:  38% 189/500 [01:27<02:23,  2.17it/s]\u001b[A\n",
            "Iteration:  38% 190/500 [01:27<02:22,  2.17it/s]\u001b[A\n",
            "Iteration:  38% 191/500 [01:28<02:22,  2.16it/s]\u001b[A\n",
            "Iteration:  38% 192/500 [01:28<02:22,  2.16it/s]\u001b[A\n",
            "Iteration:  39% 193/500 [01:29<02:21,  2.17it/s]\u001b[A\n",
            "Iteration:  39% 194/500 [01:29<02:20,  2.17it/s]\u001b[A\n",
            "Iteration:  39% 195/500 [01:30<02:20,  2.17it/s]\u001b[A\n",
            "Iteration:  39% 196/500 [01:30<02:19,  2.17it/s]\u001b[A\n",
            "Iteration:  39% 197/500 [01:30<02:19,  2.17it/s]\u001b[A\n",
            "Iteration:  40% 198/500 [01:31<02:19,  2.17it/s]\u001b[A\n",
            "Iteration:  40% 199/500 [01:31<02:18,  2.17it/s]\u001b[A{\"learning_rate\": 4e-05, \"loss\": 1.0468602919578551, \"step\": 200}\n",
            "\n",
            "Iteration:  40% 200/500 [01:32<02:18,  2.17it/s]\u001b[A\n",
            "Iteration:  40% 201/500 [01:32<02:17,  2.17it/s]\u001b[A\n",
            "Iteration:  40% 202/500 [01:33<02:16,  2.18it/s]\u001b[A\n",
            "Iteration:  41% 203/500 [01:33<02:16,  2.18it/s]\u001b[A\n",
            "Iteration:  41% 204/500 [01:34<02:16,  2.18it/s]\u001b[A\n",
            "Iteration:  41% 205/500 [01:34<02:15,  2.18it/s]\u001b[A\n",
            "Iteration:  41% 206/500 [01:35<02:14,  2.18it/s]\u001b[A\n",
            "Iteration:  41% 207/500 [01:35<02:14,  2.18it/s]\u001b[A\n",
            "Iteration:  42% 208/500 [01:36<02:13,  2.18it/s]\u001b[A\n",
            "Iteration:  42% 209/500 [01:36<02:14,  2.17it/s]\u001b[A\n",
            "Iteration:  42% 210/500 [01:36<02:13,  2.17it/s]\u001b[A\n",
            "Iteration:  42% 211/500 [01:37<02:13,  2.16it/s]\u001b[A\n",
            "Iteration:  42% 212/500 [01:37<02:12,  2.17it/s]\u001b[A\n",
            "Iteration:  43% 213/500 [01:38<02:11,  2.18it/s]\u001b[A\n",
            "Iteration:  43% 214/500 [01:38<02:11,  2.18it/s]\u001b[A\n",
            "Iteration:  43% 215/500 [01:39<02:11,  2.17it/s]\u001b[A\n",
            "Iteration:  43% 216/500 [01:39<02:10,  2.17it/s]\u001b[A\n",
            "Iteration:  43% 217/500 [01:40<02:10,  2.18it/s]\u001b[A\n",
            "Iteration:  44% 218/500 [01:40<02:09,  2.18it/s]\u001b[A\n",
            "Iteration:  44% 219/500 [01:41<02:09,  2.17it/s]\u001b[A\n",
            "Iteration:  44% 220/500 [01:41<02:09,  2.15it/s]\u001b[A\n",
            "Iteration:  44% 221/500 [01:42<02:09,  2.16it/s]\u001b[A\n",
            "Iteration:  44% 222/500 [01:42<02:08,  2.17it/s]\u001b[A\n",
            "Iteration:  45% 223/500 [01:42<02:07,  2.17it/s]\u001b[A\n",
            "Iteration:  45% 224/500 [01:43<02:07,  2.17it/s]\u001b[A\n",
            "Iteration:  45% 225/500 [01:43<02:06,  2.17it/s]\u001b[A\n",
            "Iteration:  45% 226/500 [01:44<02:06,  2.17it/s]\u001b[A\n",
            "Iteration:  45% 227/500 [01:44<02:05,  2.17it/s]\u001b[A\n",
            "Iteration:  46% 228/500 [01:45<02:05,  2.17it/s]\u001b[A\n",
            "Iteration:  46% 229/500 [01:45<02:04,  2.17it/s]\u001b[A\n",
            "Iteration:  46% 230/500 [01:46<02:04,  2.17it/s]\u001b[A\n",
            "Iteration:  46% 231/500 [01:46<02:04,  2.15it/s]\u001b[A\n",
            "Iteration:  46% 232/500 [01:47<02:04,  2.16it/s]\u001b[A\n",
            "Iteration:  47% 233/500 [01:47<02:03,  2.15it/s]\u001b[A\n",
            "Iteration:  47% 234/500 [01:48<02:02,  2.16it/s]\u001b[A\n",
            "Iteration:  47% 235/500 [01:48<02:02,  2.16it/s]\u001b[A\n",
            "Iteration:  47% 236/500 [01:48<02:02,  2.15it/s]\u001b[A\n",
            "Iteration:  47% 237/500 [01:49<02:01,  2.16it/s]\u001b[A\n",
            "Iteration:  48% 238/500 [01:49<02:01,  2.15it/s]\u001b[A\n",
            "Iteration:  48% 239/500 [01:50<02:00,  2.16it/s]\u001b[A\n",
            "Iteration:  48% 240/500 [01:50<02:00,  2.16it/s]\u001b[A\n",
            "Iteration:  48% 241/500 [01:51<01:59,  2.17it/s]\u001b[A\n",
            "Iteration:  48% 242/500 [01:51<01:59,  2.16it/s]\u001b[A\n",
            "Iteration:  49% 243/500 [01:52<01:58,  2.16it/s]\u001b[A\n",
            "Iteration:  49% 244/500 [01:52<01:58,  2.16it/s]\u001b[A\n",
            "Iteration:  49% 245/500 [01:53<01:57,  2.17it/s]\u001b[A\n",
            "Iteration:  49% 246/500 [01:53<01:57,  2.17it/s]\u001b[A\n",
            "Iteration:  49% 247/500 [01:54<01:56,  2.17it/s]\u001b[A\n",
            "Iteration:  50% 248/500 [01:54<01:55,  2.18it/s]\u001b[A\n",
            "Iteration:  50% 249/500 [01:54<01:55,  2.18it/s]\u001b[A{\"learning_rate\": 3.7500000000000003e-05, \"loss\": 1.0267996180057526, \"step\": 250}\n",
            "\n",
            "Iteration:  50% 250/500 [01:55<01:54,  2.18it/s]\u001b[A\n",
            "Iteration:  50% 251/500 [01:55<01:55,  2.16it/s]\u001b[A\n",
            "Iteration:  50% 252/500 [01:56<01:54,  2.17it/s]\u001b[A\n",
            "Iteration:  51% 253/500 [01:56<01:54,  2.16it/s]\u001b[A\n",
            "Iteration:  51% 254/500 [01:57<01:53,  2.16it/s]\u001b[A\n",
            "Iteration:  51% 255/500 [01:57<01:53,  2.16it/s]\u001b[A\n",
            "Iteration:  51% 256/500 [01:58<01:52,  2.16it/s]\u001b[A\n",
            "Iteration:  51% 257/500 [01:58<01:52,  2.16it/s]\u001b[A\n",
            "Iteration:  52% 258/500 [01:59<01:51,  2.17it/s]\u001b[A\n",
            "Iteration:  52% 259/500 [01:59<01:51,  2.17it/s]\u001b[A\n",
            "Iteration:  52% 260/500 [02:00<01:50,  2.17it/s]\u001b[A\n",
            "Iteration:  52% 261/500 [02:00<01:49,  2.18it/s]\u001b[A\n",
            "Iteration:  52% 262/500 [02:00<01:49,  2.17it/s]\u001b[A\n",
            "Iteration:  53% 263/500 [02:01<01:49,  2.17it/s]\u001b[A\n",
            "Iteration:  53% 264/500 [02:01<01:49,  2.16it/s]\u001b[A\n",
            "Iteration:  53% 265/500 [02:02<01:48,  2.17it/s]\u001b[A\n",
            "Iteration:  53% 266/500 [02:02<01:47,  2.17it/s]\u001b[A\n",
            "Iteration:  53% 267/500 [02:03<01:47,  2.17it/s]\u001b[A\n",
            "Iteration:  54% 268/500 [02:03<01:46,  2.17it/s]\u001b[A\n",
            "Iteration:  54% 269/500 [02:04<01:46,  2.17it/s]\u001b[A\n",
            "Iteration:  54% 270/500 [02:04<01:45,  2.17it/s]\u001b[A\n",
            "Iteration:  54% 271/500 [02:05<01:45,  2.17it/s]\u001b[A\n",
            "Iteration:  54% 272/500 [02:05<01:45,  2.17it/s]\u001b[A\n",
            "Iteration:  55% 273/500 [02:06<01:44,  2.17it/s]\u001b[A\n",
            "Iteration:  55% 274/500 [02:06<01:44,  2.17it/s]\u001b[A\n",
            "Iteration:  55% 275/500 [02:06<01:44,  2.16it/s]\u001b[A\n",
            "Iteration:  55% 276/500 [02:07<01:43,  2.17it/s]\u001b[A\n",
            "Iteration:  55% 277/500 [02:07<01:42,  2.17it/s]\u001b[A\n",
            "Iteration:  56% 278/500 [02:08<01:42,  2.17it/s]\u001b[A\n",
            "Iteration:  56% 279/500 [02:08<01:41,  2.17it/s]\u001b[A\n",
            "Iteration:  56% 280/500 [02:09<01:41,  2.17it/s]\u001b[A\n",
            "Iteration:  56% 281/500 [02:09<01:40,  2.17it/s]\u001b[A\n",
            "Iteration:  56% 282/500 [02:10<01:40,  2.16it/s]\u001b[A\n",
            "Iteration:  57% 283/500 [02:10<01:40,  2.17it/s]\u001b[A\n",
            "Iteration:  57% 284/500 [02:11<01:39,  2.17it/s]\u001b[A\n",
            "Iteration:  57% 285/500 [02:11<01:39,  2.17it/s]\u001b[A\n",
            "Iteration:  57% 286/500 [02:12<01:38,  2.16it/s]\u001b[A\n",
            "Iteration:  57% 287/500 [02:12<01:38,  2.17it/s]\u001b[A\n",
            "Iteration:  58% 288/500 [02:12<01:37,  2.17it/s]\u001b[A\n",
            "Iteration:  58% 289/500 [02:13<01:37,  2.17it/s]\u001b[A\n",
            "Iteration:  58% 290/500 [02:13<01:36,  2.17it/s]\u001b[A\n",
            "Iteration:  58% 291/500 [02:14<01:36,  2.17it/s]\u001b[A\n",
            "Iteration:  58% 292/500 [02:14<01:35,  2.17it/s]\u001b[A\n",
            "Iteration:  59% 293/500 [02:15<01:35,  2.17it/s]\u001b[A\n",
            "Iteration:  59% 294/500 [02:15<01:34,  2.17it/s]\u001b[A\n",
            "Iteration:  59% 295/500 [02:16<01:34,  2.18it/s]\u001b[A\n",
            "Iteration:  59% 296/500 [02:16<01:33,  2.18it/s]\u001b[A\n",
            "Iteration:  59% 297/500 [02:17<01:33,  2.17it/s]\u001b[A\n",
            "Iteration:  60% 298/500 [02:17<01:33,  2.17it/s]\u001b[A\n",
            "Iteration:  60% 299/500 [02:17<01:32,  2.17it/s]\u001b[A{\"learning_rate\": 3.5e-05, \"loss\": 1.0153700667619705, \"step\": 300}\n",
            "\n",
            "Iteration:  60% 300/500 [02:18<01:32,  2.17it/s]\u001b[A\n",
            "Iteration:  60% 301/500 [02:18<01:31,  2.17it/s]\u001b[A\n",
            "Iteration:  60% 302/500 [02:19<01:31,  2.16it/s]\u001b[A\n",
            "Iteration:  61% 303/500 [02:19<01:30,  2.16it/s]\u001b[A\n",
            "Iteration:  61% 304/500 [02:20<01:30,  2.17it/s]\u001b[A\n",
            "Iteration:  61% 305/500 [02:20<01:29,  2.17it/s]\u001b[A\n",
            "Iteration:  61% 306/500 [02:21<01:29,  2.17it/s]\u001b[A\n",
            "Iteration:  61% 307/500 [02:21<01:28,  2.17it/s]\u001b[A\n",
            "Iteration:  62% 308/500 [02:22<01:28,  2.16it/s]\u001b[A\n",
            "Iteration:  62% 309/500 [02:22<01:28,  2.17it/s]\u001b[A\n",
            "Iteration:  62% 310/500 [02:23<01:27,  2.17it/s]\u001b[A\n",
            "Iteration:  62% 311/500 [02:23<01:27,  2.17it/s]\u001b[A\n",
            "Iteration:  62% 312/500 [02:23<01:26,  2.18it/s]\u001b[A\n",
            "Iteration:  63% 313/500 [02:24<01:25,  2.18it/s]\u001b[A\n",
            "Iteration:  63% 314/500 [02:24<01:25,  2.18it/s]\u001b[A\n",
            "Iteration:  63% 315/500 [02:25<01:25,  2.18it/s]\u001b[A\n",
            "Iteration:  63% 316/500 [02:25<01:24,  2.18it/s]\u001b[A\n",
            "Iteration:  63% 317/500 [02:26<01:24,  2.18it/s]\u001b[A\n",
            "Iteration:  64% 318/500 [02:26<01:23,  2.18it/s]\u001b[A\n",
            "Iteration:  64% 319/500 [02:27<01:23,  2.17it/s]\u001b[A\n",
            "Iteration:  64% 320/500 [02:27<01:23,  2.17it/s]\u001b[A\n",
            "Iteration:  64% 321/500 [02:28<01:22,  2.17it/s]\u001b[A\n",
            "Iteration:  64% 322/500 [02:28<01:22,  2.16it/s]\u001b[A\n",
            "Iteration:  65% 323/500 [02:29<01:21,  2.16it/s]\u001b[A\n",
            "Iteration:  65% 324/500 [02:29<01:21,  2.17it/s]\u001b[A\n",
            "Iteration:  65% 325/500 [02:29<01:20,  2.17it/s]\u001b[A\n",
            "Iteration:  65% 326/500 [02:30<01:20,  2.17it/s]\u001b[A\n",
            "Iteration:  65% 327/500 [02:30<01:19,  2.17it/s]\u001b[A\n",
            "Iteration:  66% 328/500 [02:31<01:19,  2.18it/s]\u001b[A\n",
            "Iteration:  66% 329/500 [02:31<01:18,  2.18it/s]\u001b[A\n",
            "Iteration:  66% 330/500 [02:32<01:18,  2.17it/s]\u001b[A\n",
            "Iteration:  66% 331/500 [02:32<01:17,  2.17it/s]\u001b[A\n",
            "Iteration:  66% 332/500 [02:33<01:17,  2.17it/s]\u001b[A\n",
            "Iteration:  67% 333/500 [02:33<01:16,  2.17it/s]\u001b[A\n",
            "Iteration:  67% 334/500 [02:34<01:16,  2.17it/s]\u001b[A\n",
            "Iteration:  67% 335/500 [02:34<01:15,  2.17it/s]\u001b[A\n",
            "Iteration:  67% 336/500 [02:35<01:15,  2.17it/s]\u001b[A\n",
            "Iteration:  67% 337/500 [02:35<01:15,  2.17it/s]\u001b[A\n",
            "Iteration:  68% 338/500 [02:35<01:14,  2.17it/s]\u001b[A\n",
            "Iteration:  68% 339/500 [02:36<01:14,  2.17it/s]\u001b[A\n",
            "Iteration:  68% 340/500 [02:36<01:13,  2.17it/s]\u001b[A\n",
            "Iteration:  68% 341/500 [02:37<01:13,  2.16it/s]\u001b[A\n",
            "Iteration:  68% 342/500 [02:37<01:13,  2.15it/s]\u001b[A\n",
            "Iteration:  69% 343/500 [02:38<01:12,  2.16it/s]\u001b[A\n",
            "Iteration:  69% 344/500 [02:38<01:12,  2.16it/s]\u001b[A\n",
            "Iteration:  69% 345/500 [02:39<01:11,  2.17it/s]\u001b[A\n",
            "Iteration:  69% 346/500 [02:39<01:11,  2.17it/s]\u001b[A\n",
            "Iteration:  69% 347/500 [02:40<01:10,  2.17it/s]\u001b[A\n",
            "Iteration:  70% 348/500 [02:40<01:10,  2.16it/s]\u001b[A\n",
            "Iteration:  70% 349/500 [02:41<01:09,  2.16it/s]\u001b[A{\"learning_rate\": 3.2500000000000004e-05, \"loss\": 0.9132737773656845, \"step\": 350}\n",
            "\n",
            "Iteration:  70% 350/500 [02:41<01:09,  2.17it/s]\u001b[A\n",
            "Iteration:  70% 351/500 [02:41<01:08,  2.16it/s]\u001b[A\n",
            "Iteration:  70% 352/500 [02:42<01:08,  2.16it/s]\u001b[A\n",
            "Iteration:  71% 353/500 [02:42<01:08,  2.15it/s]\u001b[A\n",
            "Iteration:  71% 354/500 [02:43<01:07,  2.16it/s]\u001b[A\n",
            "Iteration:  71% 355/500 [02:43<01:06,  2.17it/s]\u001b[A\n",
            "Iteration:  71% 356/500 [02:44<01:06,  2.17it/s]\u001b[A\n",
            "Iteration:  71% 357/500 [02:44<01:05,  2.17it/s]\u001b[A\n",
            "Iteration:  72% 358/500 [02:45<01:05,  2.17it/s]\u001b[A\n",
            "Iteration:  72% 359/500 [02:45<01:04,  2.17it/s]\u001b[A\n",
            "Iteration:  72% 360/500 [02:46<01:04,  2.17it/s]\u001b[A\n",
            "Iteration:  72% 361/500 [02:46<01:03,  2.17it/s]\u001b[A\n",
            "Iteration:  72% 362/500 [02:47<01:03,  2.18it/s]\u001b[A\n",
            "Iteration:  73% 363/500 [02:47<01:03,  2.17it/s]\u001b[A\n",
            "Iteration:  73% 364/500 [02:47<01:02,  2.17it/s]\u001b[A\n",
            "Iteration:  73% 365/500 [02:48<01:02,  2.17it/s]\u001b[A\n",
            "Iteration:  73% 366/500 [02:48<01:01,  2.17it/s]\u001b[A\n",
            "Iteration:  73% 367/500 [02:49<01:01,  2.17it/s]\u001b[A\n",
            "Iteration:  74% 368/500 [02:49<01:00,  2.17it/s]\u001b[A\n",
            "Iteration:  74% 369/500 [02:50<01:00,  2.15it/s]\u001b[A\n",
            "Iteration:  74% 370/500 [02:50<01:00,  2.16it/s]\u001b[A\n",
            "Iteration:  74% 371/500 [02:51<00:59,  2.16it/s]\u001b[A\n",
            "Iteration:  74% 372/500 [02:51<00:59,  2.16it/s]\u001b[A\n",
            "Iteration:  75% 373/500 [02:52<00:58,  2.16it/s]\u001b[A\n",
            "Iteration:  75% 374/500 [02:52<00:58,  2.17it/s]\u001b[A\n",
            "Iteration:  75% 375/500 [02:53<00:57,  2.17it/s]\u001b[A\n",
            "Iteration:  75% 376/500 [02:53<00:57,  2.17it/s]\u001b[A\n",
            "Iteration:  75% 377/500 [02:53<00:56,  2.18it/s]\u001b[A\n",
            "Iteration:  76% 378/500 [02:54<00:56,  2.18it/s]\u001b[A\n",
            "Iteration:  76% 379/500 [02:54<00:55,  2.17it/s]\u001b[A\n",
            "Iteration:  76% 380/500 [02:55<00:55,  2.18it/s]\u001b[A\n",
            "Iteration:  76% 381/500 [02:55<00:54,  2.18it/s]\u001b[A\n",
            "Iteration:  76% 382/500 [02:56<00:54,  2.18it/s]\u001b[A\n",
            "Iteration:  77% 383/500 [02:56<00:53,  2.17it/s]\u001b[A\n",
            "Iteration:  77% 384/500 [02:57<00:53,  2.18it/s]\u001b[A\n",
            "Iteration:  77% 385/500 [02:57<00:53,  2.17it/s]\u001b[A\n",
            "Iteration:  77% 386/500 [02:58<00:52,  2.17it/s]\u001b[A\n",
            "Iteration:  77% 387/500 [02:58<00:51,  2.17it/s]\u001b[A\n",
            "Iteration:  78% 388/500 [02:59<00:51,  2.17it/s]\u001b[A\n",
            "Iteration:  78% 389/500 [02:59<00:51,  2.17it/s]\u001b[A\n",
            "Iteration:  78% 390/500 [02:59<00:50,  2.17it/s]\u001b[A\n",
            "Iteration:  78% 391/500 [03:00<00:50,  2.16it/s]\u001b[A\n",
            "Iteration:  78% 392/500 [03:00<00:49,  2.17it/s]\u001b[A\n",
            "Iteration:  79% 393/500 [03:01<00:49,  2.16it/s]\u001b[A\n",
            "Iteration:  79% 394/500 [03:01<00:48,  2.17it/s]\u001b[A\n",
            "Iteration:  79% 395/500 [03:02<00:48,  2.17it/s]\u001b[A\n",
            "Iteration:  79% 396/500 [03:02<00:47,  2.17it/s]\u001b[A\n",
            "Iteration:  79% 397/500 [03:03<00:47,  2.16it/s]\u001b[A\n",
            "Iteration:  80% 398/500 [03:03<00:47,  2.16it/s]\u001b[A\n",
            "Iteration:  80% 399/500 [03:04<00:46,  2.17it/s]\u001b[A{\"learning_rate\": 3e-05, \"loss\": 0.9186457639932633, \"step\": 400}\n",
            "\n",
            "Iteration:  80% 400/500 [03:04<00:46,  2.17it/s]\u001b[A\n",
            "Iteration:  80% 401/500 [03:05<00:45,  2.17it/s]\u001b[A\n",
            "Iteration:  80% 402/500 [03:05<00:45,  2.17it/s]\u001b[A\n",
            "Iteration:  81% 403/500 [03:05<00:44,  2.17it/s]\u001b[A\n",
            "Iteration:  81% 404/500 [03:06<00:44,  2.16it/s]\u001b[A\n",
            "Iteration:  81% 405/500 [03:06<00:43,  2.17it/s]\u001b[A\n",
            "Iteration:  81% 406/500 [03:07<00:43,  2.17it/s]\u001b[A\n",
            "Iteration:  81% 407/500 [03:07<00:42,  2.17it/s]\u001b[A\n",
            "Iteration:  82% 408/500 [03:08<00:42,  2.17it/s]\u001b[A\n",
            "Iteration:  82% 409/500 [03:08<00:41,  2.17it/s]\u001b[A\n",
            "Iteration:  82% 410/500 [03:09<00:41,  2.17it/s]\u001b[A\n",
            "Iteration:  82% 411/500 [03:09<00:40,  2.18it/s]\u001b[A\n",
            "Iteration:  82% 412/500 [03:10<00:40,  2.17it/s]\u001b[A\n",
            "Iteration:  83% 413/500 [03:10<00:39,  2.18it/s]\u001b[A\n",
            "Iteration:  83% 414/500 [03:11<00:39,  2.18it/s]\u001b[A\n",
            "Iteration:  83% 415/500 [03:11<00:39,  2.17it/s]\u001b[A\n",
            "Iteration:  83% 416/500 [03:11<00:38,  2.17it/s]\u001b[A\n",
            "Iteration:  83% 417/500 [03:12<00:38,  2.18it/s]\u001b[A\n",
            "Iteration:  84% 418/500 [03:12<00:37,  2.17it/s]\u001b[A\n",
            "Iteration:  84% 419/500 [03:13<00:37,  2.17it/s]\u001b[A\n",
            "Iteration:  84% 420/500 [03:13<00:36,  2.17it/s]\u001b[A\n",
            "Iteration:  84% 421/500 [03:14<00:36,  2.17it/s]\u001b[A\n",
            "Iteration:  84% 422/500 [03:14<00:35,  2.17it/s]\u001b[A\n",
            "Iteration:  85% 423/500 [03:15<00:35,  2.17it/s]\u001b[A\n",
            "Iteration:  85% 424/500 [03:15<00:35,  2.16it/s]\u001b[A\n",
            "Iteration:  85% 425/500 [03:16<00:34,  2.16it/s]\u001b[A\n",
            "Iteration:  85% 426/500 [03:16<00:34,  2.17it/s]\u001b[A\n",
            "Iteration:  85% 427/500 [03:17<00:33,  2.17it/s]\u001b[A\n",
            "Iteration:  86% 428/500 [03:17<00:33,  2.17it/s]\u001b[A\n",
            "Iteration:  86% 429/500 [03:17<00:32,  2.17it/s]\u001b[A\n",
            "Iteration:  86% 430/500 [03:18<00:32,  2.17it/s]\u001b[A\n",
            "Iteration:  86% 431/500 [03:18<00:31,  2.17it/s]\u001b[A\n",
            "Iteration:  86% 432/500 [03:19<00:31,  2.18it/s]\u001b[A\n",
            "Iteration:  87% 433/500 [03:19<00:30,  2.17it/s]\u001b[A\n",
            "Iteration:  87% 434/500 [03:20<00:30,  2.18it/s]\u001b[A\n",
            "Iteration:  87% 435/500 [03:20<00:29,  2.17it/s]\u001b[A\n",
            "Iteration:  87% 436/500 [03:21<00:29,  2.17it/s]\u001b[A\n",
            "Iteration:  87% 437/500 [03:21<00:28,  2.17it/s]\u001b[A\n",
            "Iteration:  88% 438/500 [03:22<00:28,  2.17it/s]\u001b[A\n",
            "Iteration:  88% 439/500 [03:22<00:28,  2.17it/s]\u001b[A\n",
            "Iteration:  88% 440/500 [03:22<00:27,  2.17it/s]\u001b[A\n",
            "Iteration:  88% 441/500 [03:23<00:27,  2.17it/s]\u001b[A\n",
            "Iteration:  88% 442/500 [03:23<00:26,  2.17it/s]\u001b[A\n",
            "Iteration:  89% 443/500 [03:24<00:26,  2.17it/s]\u001b[A\n",
            "Iteration:  89% 444/500 [03:24<00:25,  2.16it/s]\u001b[A\n",
            "Iteration:  89% 445/500 [03:25<00:25,  2.17it/s]\u001b[A\n",
            "Iteration:  89% 446/500 [03:25<00:24,  2.17it/s]\u001b[A\n",
            "Iteration:  89% 447/500 [03:26<00:24,  2.17it/s]\u001b[A\n",
            "Iteration:  90% 448/500 [03:26<00:23,  2.17it/s]\u001b[A\n",
            "Iteration:  90% 449/500 [03:27<00:23,  2.16it/s]\u001b[A{\"learning_rate\": 2.7500000000000004e-05, \"loss\": 0.9750370335578918, \"step\": 450}\n",
            "\n",
            "Iteration:  90% 450/500 [03:27<00:23,  2.17it/s]\u001b[A\n",
            "Iteration:  90% 451/500 [03:28<00:22,  2.16it/s]\u001b[A\n",
            "Iteration:  90% 452/500 [03:28<00:22,  2.15it/s]\u001b[A\n",
            "Iteration:  91% 453/500 [03:28<00:21,  2.16it/s]\u001b[A\n",
            "Iteration:  91% 454/500 [03:29<00:21,  2.16it/s]\u001b[A\n",
            "Iteration:  91% 455/500 [03:29<00:20,  2.17it/s]\u001b[A\n",
            "Iteration:  91% 456/500 [03:30<00:20,  2.17it/s]\u001b[A\n",
            "Iteration:  91% 457/500 [03:30<00:19,  2.17it/s]\u001b[A\n",
            "Iteration:  92% 458/500 [03:31<00:19,  2.17it/s]\u001b[A\n",
            "Iteration:  92% 459/500 [03:31<00:18,  2.17it/s]\u001b[A\n",
            "Iteration:  92% 460/500 [03:32<00:18,  2.16it/s]\u001b[A\n",
            "Iteration:  92% 461/500 [03:32<00:18,  2.16it/s]\u001b[A\n",
            "Iteration:  92% 462/500 [03:33<00:17,  2.17it/s]\u001b[A\n",
            "Iteration:  93% 463/500 [03:33<00:17,  2.17it/s]\u001b[A\n",
            "Iteration:  93% 464/500 [03:34<00:16,  2.16it/s]\u001b[A\n",
            "Iteration:  93% 465/500 [03:34<00:16,  2.16it/s]\u001b[A\n",
            "Iteration:  93% 466/500 [03:34<00:15,  2.16it/s]\u001b[A\n",
            "Iteration:  93% 467/500 [03:35<00:15,  2.16it/s]\u001b[A\n",
            "Iteration:  94% 468/500 [03:35<00:14,  2.17it/s]\u001b[A\n",
            "Iteration:  94% 469/500 [03:36<00:14,  2.17it/s]\u001b[A\n",
            "Iteration:  94% 470/500 [03:36<00:13,  2.17it/s]\u001b[A\n",
            "Iteration:  94% 471/500 [03:37<00:13,  2.17it/s]\u001b[A\n",
            "Iteration:  94% 472/500 [03:37<00:12,  2.17it/s]\u001b[A\n",
            "Iteration:  95% 473/500 [03:38<00:12,  2.17it/s]\u001b[A\n",
            "Iteration:  95% 474/500 [03:38<00:11,  2.17it/s]\u001b[A\n",
            "Iteration:  95% 475/500 [03:39<00:11,  2.16it/s]\u001b[A\n",
            "Iteration:  95% 476/500 [03:39<00:11,  2.16it/s]\u001b[A\n",
            "Iteration:  95% 477/500 [03:40<00:10,  2.16it/s]\u001b[A\n",
            "Iteration:  96% 478/500 [03:40<00:10,  2.17it/s]\u001b[A\n",
            "Iteration:  96% 479/500 [03:40<00:09,  2.17it/s]\u001b[A\n",
            "Iteration:  96% 480/500 [03:41<00:09,  2.16it/s]\u001b[A\n",
            "Iteration:  96% 481/500 [03:41<00:08,  2.16it/s]\u001b[A\n",
            "Iteration:  96% 482/500 [03:42<00:08,  2.16it/s]\u001b[A\n",
            "Iteration:  97% 483/500 [03:42<00:07,  2.17it/s]\u001b[A\n",
            "Iteration:  97% 484/500 [03:43<00:07,  2.17it/s]\u001b[A\n",
            "Iteration:  97% 485/500 [03:43<00:06,  2.16it/s]\u001b[A\n",
            "Iteration:  97% 486/500 [03:44<00:06,  2.17it/s]\u001b[A\n",
            "Iteration:  97% 487/500 [03:44<00:06,  2.16it/s]\u001b[A\n",
            "Iteration:  98% 488/500 [03:45<00:05,  2.17it/s]\u001b[A\n",
            "Iteration:  98% 489/500 [03:45<00:05,  2.17it/s]\u001b[A\n",
            "Iteration:  98% 490/500 [03:46<00:04,  2.17it/s]\u001b[A\n",
            "Iteration:  98% 491/500 [03:46<00:04,  2.17it/s]\u001b[A\n",
            "Iteration:  98% 492/500 [03:46<00:03,  2.17it/s]\u001b[A\n",
            "Iteration:  99% 493/500 [03:47<00:03,  2.17it/s]\u001b[A\n",
            "Iteration:  99% 494/500 [03:47<00:02,  2.18it/s]\u001b[A\n",
            "Iteration:  99% 495/500 [03:48<00:02,  2.15it/s]\u001b[A\n",
            "Iteration:  99% 496/500 [03:48<00:01,  2.16it/s]\u001b[A\n",
            "Iteration:  99% 497/500 [03:49<00:01,  2.17it/s]\u001b[A\n",
            "Iteration: 100% 498/500 [03:49<00:00,  2.17it/s]\u001b[A\n",
            "Iteration: 100% 499/500 [03:50<00:00,  2.17it/s]\u001b[A{\"learning_rate\": 2.5e-05, \"loss\": 0.9409276562929153, \"step\": 500}\n",
            "\n",
            "Iteration: 100% 500/500 [03:50<00:00,  2.17it/s]\n",
            "Epoch:  50% 1/2 [03:50<03:50, 230.68s/it]\n",
            "Iteration:   0% 0/500 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 1/500 [00:00<03:48,  2.18it/s]\u001b[A\n",
            "Iteration:   0% 2/500 [00:00<03:48,  2.18it/s]\u001b[A\n",
            "Iteration:   1% 3/500 [00:01<03:47,  2.18it/s]\u001b[A\n",
            "Iteration:   1% 4/500 [00:01<03:47,  2.18it/s]\u001b[A\n",
            "Iteration:   1% 5/500 [00:02<03:47,  2.18it/s]\u001b[A\n",
            "Iteration:   1% 6/500 [00:02<03:48,  2.16it/s]\u001b[A\n",
            "Iteration:   1% 7/500 [00:03<03:48,  2.16it/s]\u001b[A\n",
            "Iteration:   2% 8/500 [00:03<03:47,  2.17it/s]\u001b[A\n",
            "Iteration:   2% 9/500 [00:04<03:46,  2.17it/s]\u001b[A\n",
            "Iteration:   2% 10/500 [00:04<03:45,  2.17it/s]\u001b[A\n",
            "Iteration:   2% 11/500 [00:05<03:45,  2.17it/s]\u001b[A\n",
            "Iteration:   2% 12/500 [00:05<03:44,  2.17it/s]\u001b[A\n",
            "Iteration:   3% 13/500 [00:05<03:44,  2.17it/s]\u001b[A\n",
            "Iteration:   3% 14/500 [00:06<03:44,  2.17it/s]\u001b[A\n",
            "Iteration:   3% 15/500 [00:06<03:44,  2.16it/s]\u001b[A\n",
            "Iteration:   3% 16/500 [00:07<03:43,  2.17it/s]\u001b[A\n",
            "Iteration:   3% 17/500 [00:07<03:43,  2.16it/s]\u001b[A\n",
            "Iteration:   4% 18/500 [00:08<03:42,  2.16it/s]\u001b[A\n",
            "Iteration:   4% 19/500 [00:08<03:41,  2.17it/s]\u001b[A\n",
            "Iteration:   4% 20/500 [00:09<03:41,  2.17it/s]\u001b[A\n",
            "Iteration:   4% 21/500 [00:09<03:41,  2.16it/s]\u001b[A\n",
            "Iteration:   4% 22/500 [00:10<03:40,  2.17it/s]\u001b[A\n",
            "Iteration:   5% 23/500 [00:10<03:39,  2.17it/s]\u001b[A\n",
            "Iteration:   5% 24/500 [00:11<03:39,  2.17it/s]\u001b[A\n",
            "Iteration:   5% 25/500 [00:11<03:38,  2.17it/s]\u001b[A\n",
            "Iteration:   5% 26/500 [00:11<03:38,  2.17it/s]\u001b[A\n",
            "Iteration:   5% 27/500 [00:12<03:37,  2.17it/s]\u001b[A\n",
            "Iteration:   6% 28/500 [00:12<03:40,  2.14it/s]\u001b[A\n",
            "Iteration:   6% 29/500 [00:13<03:39,  2.15it/s]\u001b[A\n",
            "Iteration:   6% 30/500 [00:13<03:37,  2.16it/s]\u001b[A\n",
            "Iteration:   6% 31/500 [00:14<03:36,  2.16it/s]\u001b[A\n",
            "Iteration:   6% 32/500 [00:14<03:35,  2.17it/s]\u001b[A\n",
            "Iteration:   7% 33/500 [00:15<03:35,  2.17it/s]\u001b[A\n",
            "Iteration:   7% 34/500 [00:15<03:34,  2.17it/s]\u001b[A\n",
            "Iteration:   7% 35/500 [00:16<03:33,  2.18it/s]\u001b[A\n",
            "Iteration:   7% 36/500 [00:16<03:32,  2.18it/s]\u001b[A\n",
            "Iteration:   7% 37/500 [00:17<03:32,  2.18it/s]\u001b[A\n",
            "Iteration:   8% 38/500 [00:17<03:32,  2.18it/s]\u001b[A\n",
            "Iteration:   8% 39/500 [00:17<03:33,  2.16it/s]\u001b[A\n",
            "Iteration:   8% 40/500 [00:18<03:32,  2.17it/s]\u001b[A\n",
            "Iteration:   8% 41/500 [00:18<03:31,  2.17it/s]\u001b[A\n",
            "Iteration:   8% 42/500 [00:19<03:30,  2.17it/s]\u001b[A\n",
            "Iteration:   9% 43/500 [00:19<03:29,  2.18it/s]\u001b[A\n",
            "Iteration:   9% 44/500 [00:20<03:29,  2.17it/s]\u001b[A\n",
            "Iteration:   9% 45/500 [00:20<03:29,  2.18it/s]\u001b[A\n",
            "Iteration:   9% 46/500 [00:21<03:29,  2.17it/s]\u001b[A\n",
            "Iteration:   9% 47/500 [00:21<03:29,  2.17it/s]\u001b[A\n",
            "Iteration:  10% 48/500 [00:22<03:28,  2.17it/s]\u001b[A\n",
            "Iteration:  10% 49/500 [00:22<03:28,  2.17it/s]\u001b[A{\"learning_rate\": 2.25e-05, \"loss\": 0.7628151470422745, \"step\": 550}\n",
            "\n",
            "Iteration:  10% 50/500 [00:23<03:29,  2.14it/s]\u001b[A\n",
            "Iteration:  10% 51/500 [00:23<03:28,  2.15it/s]\u001b[A\n",
            "Iteration:  10% 52/500 [00:24<03:27,  2.16it/s]\u001b[A\n",
            "Iteration:  11% 53/500 [00:24<03:27,  2.16it/s]\u001b[A\n",
            "Iteration:  11% 54/500 [00:24<03:26,  2.16it/s]\u001b[A\n",
            "Iteration:  11% 55/500 [00:25<03:25,  2.17it/s]\u001b[A\n",
            "Iteration:  11% 56/500 [00:25<03:24,  2.17it/s]\u001b[A\n",
            "Iteration:  11% 57/500 [00:26<03:24,  2.17it/s]\u001b[A\n",
            "Iteration:  12% 58/500 [00:26<03:23,  2.17it/s]\u001b[A\n",
            "Iteration:  12% 59/500 [00:27<03:22,  2.17it/s]\u001b[A\n",
            "Iteration:  12% 60/500 [00:27<03:22,  2.18it/s]\u001b[A\n",
            "Iteration:  12% 61/500 [00:28<03:22,  2.17it/s]\u001b[A\n",
            "Iteration:  12% 62/500 [00:28<03:21,  2.18it/s]\u001b[A\n",
            "Iteration:  13% 63/500 [00:29<03:20,  2.18it/s]\u001b[A\n",
            "Iteration:  13% 64/500 [00:29<03:20,  2.17it/s]\u001b[A\n",
            "Iteration:  13% 65/500 [00:29<03:20,  2.17it/s]\u001b[A\n",
            "Iteration:  13% 66/500 [00:30<03:20,  2.16it/s]\u001b[A\n",
            "Iteration:  13% 67/500 [00:30<03:19,  2.17it/s]\u001b[A\n",
            "Iteration:  14% 68/500 [00:31<03:19,  2.16it/s]\u001b[A\n",
            "Iteration:  14% 69/500 [00:31<03:19,  2.16it/s]\u001b[A\n",
            "Iteration:  14% 70/500 [00:32<03:18,  2.17it/s]\u001b[A\n",
            "Iteration:  14% 71/500 [00:32<03:17,  2.17it/s]\u001b[A\n",
            "Iteration:  14% 72/500 [00:33<03:17,  2.17it/s]\u001b[A\n",
            "Iteration:  15% 73/500 [00:33<03:16,  2.17it/s]\u001b[A\n",
            "Iteration:  15% 74/500 [00:34<03:16,  2.17it/s]\u001b[A\n",
            "Iteration:  15% 75/500 [00:34<03:15,  2.17it/s]\u001b[A\n",
            "Iteration:  15% 76/500 [00:35<03:14,  2.17it/s]\u001b[A\n",
            "Iteration:  15% 77/500 [00:35<03:14,  2.17it/s]\u001b[A\n",
            "Iteration:  16% 78/500 [00:35<03:14,  2.16it/s]\u001b[A\n",
            "Iteration:  16% 79/500 [00:36<03:14,  2.17it/s]\u001b[A\n",
            "Iteration:  16% 80/500 [00:36<03:13,  2.17it/s]\u001b[A\n",
            "Iteration:  16% 81/500 [00:37<03:12,  2.17it/s]\u001b[A\n",
            "Iteration:  16% 82/500 [00:37<03:12,  2.17it/s]\u001b[A\n",
            "Iteration:  17% 83/500 [00:38<03:12,  2.17it/s]\u001b[A\n",
            "Iteration:  17% 84/500 [00:38<03:12,  2.17it/s]\u001b[A\n",
            "Iteration:  17% 85/500 [00:39<03:11,  2.17it/s]\u001b[A\n",
            "Iteration:  17% 86/500 [00:39<03:11,  2.16it/s]\u001b[A\n",
            "Iteration:  17% 87/500 [00:40<03:10,  2.16it/s]\u001b[A\n",
            "Iteration:  18% 88/500 [00:40<03:10,  2.17it/s]\u001b[A\n",
            "Iteration:  18% 89/500 [00:41<03:09,  2.17it/s]\u001b[A\n",
            "Iteration:  18% 90/500 [00:41<03:08,  2.17it/s]\u001b[A\n",
            "Iteration:  18% 91/500 [00:41<03:08,  2.18it/s]\u001b[A\n",
            "Iteration:  18% 92/500 [00:42<03:07,  2.18it/s]\u001b[A\n",
            "Iteration:  19% 93/500 [00:42<03:07,  2.17it/s]\u001b[A\n",
            "Iteration:  19% 94/500 [00:43<03:07,  2.17it/s]\u001b[A\n",
            "Iteration:  19% 95/500 [00:43<03:07,  2.16it/s]\u001b[A\n",
            "Iteration:  19% 96/500 [00:44<03:06,  2.17it/s]\u001b[A\n",
            "Iteration:  19% 97/500 [00:44<03:05,  2.17it/s]\u001b[A\n",
            "Iteration:  20% 98/500 [00:45<03:05,  2.17it/s]\u001b[A\n",
            "Iteration:  20% 99/500 [00:45<03:04,  2.17it/s]\u001b[A{\"learning_rate\": 2e-05, \"loss\": 0.7326333510875702, \"step\": 600}\n",
            "\n",
            "Iteration:  20% 100/500 [00:46<03:03,  2.17it/s]\u001b[A\n",
            "Iteration:  20% 101/500 [00:46<03:03,  2.18it/s]\u001b[A\n",
            "Iteration:  20% 102/500 [00:47<03:02,  2.18it/s]\u001b[A\n",
            "Iteration:  21% 103/500 [00:47<03:03,  2.16it/s]\u001b[A\n",
            "Iteration:  21% 104/500 [00:47<03:02,  2.16it/s]\u001b[A\n",
            "Iteration:  21% 105/500 [00:48<03:02,  2.16it/s]\u001b[A\n",
            "Iteration:  21% 106/500 [00:48<03:02,  2.16it/s]\u001b[A\n",
            "Iteration:  21% 107/500 [00:49<03:01,  2.17it/s]\u001b[A\n",
            "Iteration:  22% 108/500 [00:49<03:00,  2.17it/s]\u001b[A\n",
            "Iteration:  22% 109/500 [00:50<03:00,  2.17it/s]\u001b[A\n",
            "Iteration:  22% 110/500 [00:50<02:59,  2.17it/s]\u001b[A\n",
            "Iteration:  22% 111/500 [00:51<02:59,  2.17it/s]\u001b[A\n",
            "Iteration:  22% 112/500 [00:51<02:58,  2.17it/s]\u001b[A\n",
            "Iteration:  23% 113/500 [00:52<02:58,  2.17it/s]\u001b[A\n",
            "Iteration:  23% 114/500 [00:52<02:58,  2.17it/s]\u001b[A\n",
            "Iteration:  23% 115/500 [00:53<02:57,  2.17it/s]\u001b[A\n",
            "Iteration:  23% 116/500 [00:53<02:57,  2.17it/s]\u001b[A\n",
            "Iteration:  23% 117/500 [00:53<02:57,  2.16it/s]\u001b[A\n",
            "Iteration:  24% 118/500 [00:54<02:56,  2.16it/s]\u001b[A\n",
            "Iteration:  24% 119/500 [00:54<02:56,  2.15it/s]\u001b[A\n",
            "Iteration:  24% 120/500 [00:55<02:55,  2.16it/s]\u001b[A\n",
            "Iteration:  24% 121/500 [00:55<02:54,  2.17it/s]\u001b[A\n",
            "Iteration:  24% 122/500 [00:56<02:54,  2.17it/s]\u001b[A\n",
            "Iteration:  25% 123/500 [00:56<02:53,  2.17it/s]\u001b[A\n",
            "Iteration:  25% 124/500 [00:57<02:53,  2.17it/s]\u001b[A\n",
            "Iteration:  25% 125/500 [00:57<02:52,  2.18it/s]\u001b[A\n",
            "Iteration:  25% 126/500 [00:58<02:51,  2.18it/s]\u001b[A\n",
            "Iteration:  25% 127/500 [00:58<02:51,  2.17it/s]\u001b[A\n",
            "Iteration:  26% 128/500 [00:59<02:51,  2.17it/s]\u001b[A\n",
            "Iteration:  26% 129/500 [00:59<02:50,  2.17it/s]\u001b[A\n",
            "Iteration:  26% 130/500 [00:59<02:50,  2.17it/s]\u001b[A\n",
            "Iteration:  26% 131/500 [01:00<02:50,  2.16it/s]\u001b[A\n",
            "Iteration:  26% 132/500 [01:00<02:50,  2.16it/s]\u001b[A\n",
            "Iteration:  27% 133/500 [01:01<02:49,  2.17it/s]\u001b[A\n",
            "Iteration:  27% 134/500 [01:01<02:48,  2.17it/s]\u001b[A\n",
            "Iteration:  27% 135/500 [01:02<02:47,  2.18it/s]\u001b[A\n",
            "Iteration:  27% 136/500 [01:02<02:47,  2.18it/s]\u001b[A\n",
            "Iteration:  27% 137/500 [01:03<02:47,  2.16it/s]\u001b[A\n",
            "Iteration:  28% 138/500 [01:03<02:47,  2.16it/s]\u001b[A\n",
            "Iteration:  28% 139/500 [01:04<02:46,  2.16it/s]\u001b[A\n",
            "Iteration:  28% 140/500 [01:04<02:46,  2.17it/s]\u001b[A\n",
            "Iteration:  28% 141/500 [01:05<02:45,  2.17it/s]\u001b[A\n",
            "Iteration:  28% 142/500 [01:05<02:44,  2.17it/s]\u001b[A\n",
            "Iteration:  29% 143/500 [01:05<02:44,  2.17it/s]\u001b[A\n",
            "Iteration:  29% 144/500 [01:06<02:43,  2.17it/s]\u001b[A\n",
            "Iteration:  29% 145/500 [01:06<02:43,  2.18it/s]\u001b[A\n",
            "Iteration:  29% 146/500 [01:07<02:42,  2.18it/s]\u001b[A\n",
            "Iteration:  29% 147/500 [01:07<02:42,  2.18it/s]\u001b[A\n",
            "Iteration:  30% 148/500 [01:08<02:41,  2.18it/s]\u001b[A\n",
            "Iteration:  30% 149/500 [01:08<02:41,  2.18it/s]\u001b[A{\"learning_rate\": 1.75e-05, \"loss\": 0.6355807614326477, \"step\": 650}\n",
            "\n",
            "Iteration:  30% 150/500 [01:09<02:40,  2.18it/s]\u001b[A\n",
            "Iteration:  30% 151/500 [01:09<02:40,  2.18it/s]\u001b[A\n",
            "Iteration:  30% 152/500 [01:10<02:39,  2.18it/s]\u001b[A\n",
            "Iteration:  31% 153/500 [01:10<02:39,  2.18it/s]\u001b[A\n",
            "Iteration:  31% 154/500 [01:11<02:39,  2.17it/s]\u001b[A\n",
            "Iteration:  31% 155/500 [01:11<02:38,  2.17it/s]\u001b[A\n",
            "Iteration:  31% 156/500 [01:11<02:38,  2.18it/s]\u001b[A\n",
            "Iteration:  31% 157/500 [01:12<02:39,  2.15it/s]\u001b[A\n",
            "Iteration:  32% 158/500 [01:12<02:38,  2.16it/s]\u001b[A\n",
            "Iteration:  32% 159/500 [01:13<02:37,  2.17it/s]\u001b[A\n",
            "Iteration:  32% 160/500 [01:13<02:36,  2.17it/s]\u001b[A\n",
            "Iteration:  32% 161/500 [01:14<02:36,  2.17it/s]\u001b[A\n",
            "Iteration:  32% 162/500 [01:14<02:35,  2.17it/s]\u001b[A\n",
            "Iteration:  33% 163/500 [01:15<02:34,  2.17it/s]\u001b[A\n",
            "Iteration:  33% 164/500 [01:15<02:34,  2.18it/s]\u001b[A\n",
            "Iteration:  33% 165/500 [01:16<02:33,  2.18it/s]\u001b[A\n",
            "Iteration:  33% 166/500 [01:16<02:33,  2.17it/s]\u001b[A\n",
            "Iteration:  33% 167/500 [01:16<02:33,  2.17it/s]\u001b[A\n",
            "Iteration:  34% 168/500 [01:17<02:32,  2.17it/s]\u001b[A\n",
            "Iteration:  34% 169/500 [01:17<02:32,  2.17it/s]\u001b[A\n",
            "Iteration:  34% 170/500 [01:18<02:32,  2.17it/s]\u001b[A\n",
            "Iteration:  34% 171/500 [01:18<02:32,  2.16it/s]\u001b[A\n",
            "Iteration:  34% 172/500 [01:19<02:31,  2.17it/s]\u001b[A\n",
            "Iteration:  35% 173/500 [01:19<02:31,  2.16it/s]\u001b[A\n",
            "Iteration:  35% 174/500 [01:20<02:30,  2.17it/s]\u001b[A\n",
            "Iteration:  35% 175/500 [01:20<02:29,  2.17it/s]\u001b[A\n",
            "Iteration:  35% 176/500 [01:21<02:29,  2.17it/s]\u001b[A\n",
            "Iteration:  35% 177/500 [01:21<02:29,  2.17it/s]\u001b[A\n",
            "Iteration:  36% 178/500 [01:22<02:28,  2.17it/s]\u001b[A\n",
            "Iteration:  36% 179/500 [01:22<02:27,  2.17it/s]\u001b[A\n",
            "Iteration:  36% 180/500 [01:22<02:27,  2.16it/s]\u001b[A\n",
            "Iteration:  36% 181/500 [01:23<02:27,  2.16it/s]\u001b[A\n",
            "Iteration:  36% 182/500 [01:23<02:27,  2.16it/s]\u001b[A\n",
            "Iteration:  37% 183/500 [01:24<02:27,  2.15it/s]\u001b[A\n",
            "Iteration:  37% 184/500 [01:24<02:26,  2.16it/s]\u001b[A\n",
            "Iteration:  37% 185/500 [01:25<02:25,  2.17it/s]\u001b[A\n",
            "Iteration:  37% 186/500 [01:25<02:24,  2.17it/s]\u001b[A\n",
            "Iteration:  37% 187/500 [01:26<02:24,  2.17it/s]\u001b[A\n",
            "Iteration:  38% 188/500 [01:26<02:24,  2.16it/s]\u001b[A\n",
            "Iteration:  38% 189/500 [01:27<02:23,  2.17it/s]\u001b[A\n",
            "Iteration:  38% 190/500 [01:27<02:22,  2.17it/s]\u001b[A\n",
            "Iteration:  38% 191/500 [01:28<02:22,  2.17it/s]\u001b[A\n",
            "Iteration:  38% 192/500 [01:28<02:21,  2.17it/s]\u001b[A\n",
            "Iteration:  39% 193/500 [01:28<02:21,  2.17it/s]\u001b[A\n",
            "Iteration:  39% 194/500 [01:29<02:21,  2.17it/s]\u001b[A\n",
            "Iteration:  39% 195/500 [01:29<02:20,  2.17it/s]\u001b[A\n",
            "Iteration:  39% 196/500 [01:30<02:19,  2.18it/s]\u001b[A\n",
            "Iteration:  39% 197/500 [01:30<02:19,  2.18it/s]\u001b[A\n",
            "Iteration:  40% 198/500 [01:31<02:18,  2.18it/s]\u001b[A\n",
            "Iteration:  40% 199/500 [01:31<02:18,  2.18it/s]\u001b[A{\"learning_rate\": 1.5e-05, \"loss\": 0.69057293176651, \"step\": 700}\n",
            "\n",
            "Iteration:  40% 200/500 [01:32<02:17,  2.18it/s]\u001b[A\n",
            "Iteration:  40% 201/500 [01:32<02:17,  2.18it/s]\u001b[A\n",
            "Iteration:  40% 202/500 [01:33<02:16,  2.18it/s]\u001b[A\n",
            "Iteration:  41% 203/500 [01:33<02:16,  2.18it/s]\u001b[A\n",
            "Iteration:  41% 204/500 [01:34<02:16,  2.17it/s]\u001b[A\n",
            "Iteration:  41% 205/500 [01:34<02:16,  2.16it/s]\u001b[A\n",
            "Iteration:  41% 206/500 [01:34<02:15,  2.16it/s]\u001b[A\n",
            "Iteration:  41% 207/500 [01:35<02:15,  2.17it/s]\u001b[A\n",
            "Iteration:  42% 208/500 [01:35<02:15,  2.16it/s]\u001b[A\n",
            "Iteration:  42% 209/500 [01:36<02:14,  2.17it/s]\u001b[A\n",
            "Iteration:  42% 210/500 [01:36<02:13,  2.17it/s]\u001b[A\n",
            "Iteration:  42% 211/500 [01:37<02:12,  2.17it/s]\u001b[A\n",
            "Iteration:  42% 212/500 [01:37<02:12,  2.18it/s]\u001b[A\n",
            "Iteration:  43% 213/500 [01:38<02:11,  2.18it/s]\u001b[A\n",
            "Iteration:  43% 214/500 [01:38<02:11,  2.18it/s]\u001b[A\n",
            "Iteration:  43% 215/500 [01:39<02:11,  2.17it/s]\u001b[A\n",
            "Iteration:  43% 216/500 [01:39<02:10,  2.17it/s]\u001b[A\n",
            "Iteration:  43% 217/500 [01:40<02:10,  2.17it/s]\u001b[A\n",
            "Iteration:  44% 218/500 [01:40<02:09,  2.17it/s]\u001b[A\n",
            "Iteration:  44% 219/500 [01:40<02:09,  2.17it/s]\u001b[A\n",
            "Iteration:  44% 220/500 [01:41<02:08,  2.17it/s]\u001b[A\n",
            "Iteration:  44% 221/500 [01:41<02:08,  2.17it/s]\u001b[A\n",
            "Iteration:  44% 222/500 [01:42<02:07,  2.18it/s]\u001b[A\n",
            "Iteration:  45% 223/500 [01:42<02:07,  2.18it/s]\u001b[A\n",
            "Iteration:  45% 224/500 [01:43<02:06,  2.18it/s]\u001b[A\n",
            "Iteration:  45% 225/500 [01:43<02:06,  2.17it/s]\u001b[A\n",
            "Iteration:  45% 226/500 [01:44<02:06,  2.16it/s]\u001b[A\n",
            "Iteration:  45% 227/500 [01:44<02:05,  2.17it/s]\u001b[A\n",
            "Iteration:  46% 228/500 [01:45<02:06,  2.16it/s]\u001b[A\n",
            "Iteration:  46% 229/500 [01:45<02:05,  2.16it/s]\u001b[A\n",
            "Iteration:  46% 230/500 [01:46<02:04,  2.16it/s]\u001b[A\n",
            "Iteration:  46% 231/500 [01:46<02:04,  2.16it/s]\u001b[A\n",
            "Iteration:  46% 232/500 [01:46<02:03,  2.17it/s]\u001b[A\n",
            "Iteration:  47% 233/500 [01:47<02:03,  2.17it/s]\u001b[A\n",
            "Iteration:  47% 234/500 [01:47<02:02,  2.17it/s]\u001b[A\n",
            "Iteration:  47% 235/500 [01:48<02:01,  2.17it/s]\u001b[A\n",
            "Iteration:  47% 236/500 [01:48<02:01,  2.17it/s]\u001b[A\n",
            "Iteration:  47% 237/500 [01:49<02:01,  2.16it/s]\u001b[A\n",
            "Iteration:  48% 238/500 [01:49<02:00,  2.17it/s]\u001b[A\n",
            "Iteration:  48% 239/500 [01:50<02:00,  2.16it/s]\u001b[A\n",
            "Iteration:  48% 240/500 [01:50<01:59,  2.17it/s]\u001b[A\n",
            "Iteration:  48% 241/500 [01:51<01:59,  2.17it/s]\u001b[A\n",
            "Iteration:  48% 242/500 [01:51<01:59,  2.17it/s]\u001b[A\n",
            "Iteration:  49% 243/500 [01:52<01:58,  2.17it/s]\u001b[A\n",
            "Iteration:  49% 244/500 [01:52<01:57,  2.17it/s]\u001b[A\n",
            "Iteration:  49% 245/500 [01:52<01:57,  2.17it/s]\u001b[A\n",
            "Iteration:  49% 246/500 [01:53<01:57,  2.17it/s]\u001b[A\n",
            "Iteration:  49% 247/500 [01:53<01:56,  2.17it/s]\u001b[A\n",
            "Iteration:  50% 248/500 [01:54<01:57,  2.15it/s]\u001b[A\n",
            "Iteration:  50% 249/500 [01:54<01:56,  2.16it/s]\u001b[A{\"learning_rate\": 1.25e-05, \"loss\": 0.6913404780626297, \"step\": 750}\n",
            "\n",
            "Iteration:  50% 250/500 [01:55<01:55,  2.16it/s]\u001b[A\n",
            "Iteration:  50% 251/500 [01:55<01:55,  2.17it/s]\u001b[A\n",
            "Iteration:  50% 252/500 [01:56<01:54,  2.16it/s]\u001b[A\n",
            "Iteration:  51% 253/500 [01:56<01:53,  2.17it/s]\u001b[A\n",
            "Iteration:  51% 254/500 [01:57<01:53,  2.17it/s]\u001b[A\n",
            "Iteration:  51% 255/500 [01:57<01:52,  2.17it/s]\u001b[A\n",
            "Iteration:  51% 256/500 [01:58<01:52,  2.18it/s]\u001b[A\n",
            "Iteration:  51% 257/500 [01:58<01:51,  2.17it/s]\u001b[A\n",
            "Iteration:  52% 258/500 [01:58<01:51,  2.17it/s]\u001b[A\n",
            "Iteration:  52% 259/500 [01:59<01:51,  2.16it/s]\u001b[A\n",
            "Iteration:  52% 260/500 [01:59<01:51,  2.16it/s]\u001b[A\n",
            "Iteration:  52% 261/500 [02:00<01:50,  2.16it/s]\u001b[A\n",
            "Iteration:  52% 262/500 [02:00<01:49,  2.17it/s]\u001b[A\n",
            "Iteration:  53% 263/500 [02:01<01:49,  2.17it/s]\u001b[A\n",
            "Iteration:  53% 264/500 [02:01<01:48,  2.17it/s]\u001b[A\n",
            "Iteration:  53% 265/500 [02:02<01:48,  2.18it/s]\u001b[A\n",
            "Iteration:  53% 266/500 [02:02<01:47,  2.18it/s]\u001b[A\n",
            "Iteration:  53% 267/500 [02:03<01:47,  2.18it/s]\u001b[A\n",
            "Iteration:  54% 268/500 [02:03<01:47,  2.16it/s]\u001b[A\n",
            "Iteration:  54% 269/500 [02:04<01:46,  2.17it/s]\u001b[A\n",
            "Iteration:  54% 270/500 [02:04<01:46,  2.16it/s]\u001b[A\n",
            "Iteration:  54% 271/500 [02:04<01:45,  2.17it/s]\u001b[A\n",
            "Iteration:  54% 272/500 [02:05<01:44,  2.17it/s]\u001b[A\n",
            "Iteration:  55% 273/500 [02:05<01:44,  2.18it/s]\u001b[A\n",
            "Iteration:  55% 274/500 [02:06<01:43,  2.18it/s]\u001b[A\n",
            "Iteration:  55% 275/500 [02:06<01:43,  2.18it/s]\u001b[A\n",
            "Iteration:  55% 276/500 [02:07<01:43,  2.17it/s]\u001b[A\n",
            "Iteration:  55% 277/500 [02:07<01:42,  2.17it/s]\u001b[A\n",
            "Iteration:  56% 278/500 [02:08<01:42,  2.17it/s]\u001b[A\n",
            "Iteration:  56% 279/500 [02:08<01:41,  2.17it/s]\u001b[A\n",
            "Iteration:  56% 280/500 [02:09<01:41,  2.17it/s]\u001b[A\n",
            "Iteration:  56% 281/500 [02:09<01:41,  2.16it/s]\u001b[A\n",
            "Iteration:  56% 282/500 [02:10<01:40,  2.17it/s]\u001b[A\n",
            "Iteration:  57% 283/500 [02:10<01:40,  2.17it/s]\u001b[A\n",
            "Iteration:  57% 284/500 [02:10<01:39,  2.17it/s]\u001b[A\n",
            "Iteration:  57% 285/500 [02:11<01:39,  2.17it/s]\u001b[A\n",
            "Iteration:  57% 286/500 [02:11<01:38,  2.18it/s]\u001b[A\n",
            "Iteration:  57% 287/500 [02:12<01:37,  2.18it/s]\u001b[A\n",
            "Iteration:  58% 288/500 [02:12<01:37,  2.17it/s]\u001b[A\n",
            "Iteration:  58% 289/500 [02:13<01:37,  2.17it/s]\u001b[A\n",
            "Iteration:  58% 290/500 [02:13<01:36,  2.17it/s]\u001b[A\n",
            "Iteration:  58% 291/500 [02:14<01:36,  2.17it/s]\u001b[A\n",
            "Iteration:  58% 292/500 [02:14<01:36,  2.16it/s]\u001b[A\n",
            "Iteration:  59% 293/500 [02:15<01:35,  2.17it/s]\u001b[A\n",
            "Iteration:  59% 294/500 [02:15<01:35,  2.17it/s]\u001b[A\n",
            "Iteration:  59% 295/500 [02:16<01:34,  2.17it/s]\u001b[A\n",
            "Iteration:  59% 296/500 [02:16<01:33,  2.17it/s]\u001b[A\n",
            "Iteration:  59% 297/500 [02:16<01:33,  2.18it/s]\u001b[A\n",
            "Iteration:  60% 298/500 [02:17<01:32,  2.18it/s]\u001b[A\n",
            "Iteration:  60% 299/500 [02:17<01:32,  2.17it/s]\u001b[A{\"learning_rate\": 1e-05, \"loss\": 0.6507140809297561, \"step\": 800}\n",
            "\n",
            "Iteration:  60% 300/500 [02:18<01:32,  2.17it/s]\u001b[A\n",
            "Iteration:  60% 301/500 [02:18<01:31,  2.18it/s]\u001b[A\n",
            "Iteration:  60% 302/500 [02:19<01:30,  2.18it/s]\u001b[A\n",
            "Iteration:  61% 303/500 [02:19<01:30,  2.17it/s]\u001b[A\n",
            "Iteration:  61% 304/500 [02:20<01:30,  2.17it/s]\u001b[A\n",
            "Iteration:  61% 305/500 [02:20<01:29,  2.17it/s]\u001b[A\n",
            "Iteration:  61% 306/500 [02:21<01:29,  2.16it/s]\u001b[A\n",
            "Iteration:  61% 307/500 [02:21<01:29,  2.16it/s]\u001b[A\n",
            "Iteration:  62% 308/500 [02:22<01:28,  2.16it/s]\u001b[A\n",
            "Iteration:  62% 309/500 [02:22<01:28,  2.17it/s]\u001b[A\n",
            "Iteration:  62% 310/500 [02:22<01:27,  2.17it/s]\u001b[A\n",
            "Iteration:  62% 311/500 [02:23<01:26,  2.17it/s]\u001b[A\n",
            "Iteration:  62% 312/500 [02:23<01:26,  2.18it/s]\u001b[A\n",
            "Iteration:  63% 313/500 [02:24<01:25,  2.18it/s]\u001b[A\n",
            "Iteration:  63% 314/500 [02:24<01:25,  2.17it/s]\u001b[A\n",
            "Iteration:  63% 315/500 [02:25<01:25,  2.17it/s]\u001b[A\n",
            "Iteration:  63% 316/500 [02:25<01:24,  2.17it/s]\u001b[A\n",
            "Iteration:  63% 317/500 [02:26<01:24,  2.17it/s]\u001b[A\n",
            "Iteration:  64% 318/500 [02:26<01:23,  2.17it/s]\u001b[A\n",
            "Iteration:  64% 319/500 [02:27<01:23,  2.16it/s]\u001b[A\n",
            "Iteration:  64% 320/500 [02:27<01:23,  2.17it/s]\u001b[A\n",
            "Iteration:  64% 321/500 [02:27<01:22,  2.17it/s]\u001b[A\n",
            "Iteration:  64% 322/500 [02:28<01:21,  2.17it/s]\u001b[A\n",
            "Iteration:  65% 323/500 [02:28<01:21,  2.17it/s]\u001b[A\n",
            "Iteration:  65% 324/500 [02:29<01:20,  2.18it/s]\u001b[A\n",
            "Iteration:  65% 325/500 [02:29<01:20,  2.16it/s]\u001b[A\n",
            "Iteration:  65% 326/500 [02:30<01:20,  2.17it/s]\u001b[A\n",
            "Iteration:  65% 327/500 [02:30<01:19,  2.17it/s]\u001b[A\n",
            "Iteration:  66% 328/500 [02:31<01:19,  2.17it/s]\u001b[A\n",
            "Iteration:  66% 329/500 [02:31<01:18,  2.17it/s]\u001b[A\n",
            "Iteration:  66% 330/500 [02:32<01:18,  2.17it/s]\u001b[A\n",
            "Iteration:  66% 331/500 [02:32<01:17,  2.17it/s]\u001b[A\n",
            "Iteration:  66% 332/500 [02:33<01:17,  2.17it/s]\u001b[A\n",
            "Iteration:  67% 333/500 [02:33<01:16,  2.17it/s]\u001b[A\n",
            "Iteration:  67% 334/500 [02:33<01:16,  2.18it/s]\u001b[A\n",
            "Iteration:  67% 335/500 [02:34<01:15,  2.18it/s]\u001b[A\n",
            "Iteration:  67% 336/500 [02:34<01:15,  2.17it/s]\u001b[A\n",
            "Iteration:  67% 337/500 [02:35<01:15,  2.17it/s]\u001b[A\n",
            "Iteration:  68% 338/500 [02:35<01:14,  2.17it/s]\u001b[A\n",
            "Iteration:  68% 339/500 [02:36<01:14,  2.16it/s]\u001b[A\n",
            "Iteration:  68% 340/500 [02:36<01:13,  2.17it/s]\u001b[A\n",
            "Iteration:  68% 341/500 [02:37<01:13,  2.17it/s]\u001b[A\n",
            "Iteration:  68% 342/500 [02:37<01:12,  2.17it/s]\u001b[A\n",
            "Iteration:  69% 343/500 [02:38<01:12,  2.18it/s]\u001b[A\n",
            "Iteration:  69% 344/500 [02:38<01:11,  2.18it/s]\u001b[A\n",
            "Iteration:  69% 345/500 [02:39<01:11,  2.17it/s]\u001b[A\n",
            "Iteration:  69% 346/500 [02:39<01:11,  2.17it/s]\u001b[A\n",
            "Iteration:  69% 347/500 [02:39<01:10,  2.16it/s]\u001b[A\n",
            "Iteration:  70% 348/500 [02:40<01:10,  2.15it/s]\u001b[A\n",
            "Iteration:  70% 349/500 [02:40<01:10,  2.16it/s]\u001b[A{\"learning_rate\": 7.5e-06, \"loss\": 0.6350980940461158, \"step\": 850}\n",
            "\n",
            "Iteration:  70% 350/500 [02:41<01:09,  2.16it/s]\u001b[A\n",
            "Iteration:  70% 351/500 [02:41<01:08,  2.17it/s]\u001b[A\n",
            "Iteration:  70% 352/500 [02:42<01:08,  2.17it/s]\u001b[A\n",
            "Iteration:  71% 353/500 [02:42<01:07,  2.17it/s]\u001b[A\n",
            "Iteration:  71% 354/500 [02:43<01:07,  2.16it/s]\u001b[A\n",
            "Iteration:  71% 355/500 [02:43<01:07,  2.16it/s]\u001b[A\n",
            "Iteration:  71% 356/500 [02:44<01:06,  2.17it/s]\u001b[A\n",
            "Iteration:  71% 357/500 [02:44<01:05,  2.17it/s]\u001b[A\n",
            "Iteration:  72% 358/500 [02:45<01:05,  2.16it/s]\u001b[A\n",
            "Iteration:  72% 359/500 [02:45<01:05,  2.15it/s]\u001b[A\n",
            "Iteration:  72% 360/500 [02:45<01:04,  2.16it/s]\u001b[A\n",
            "Iteration:  72% 361/500 [02:46<01:04,  2.16it/s]\u001b[A\n",
            "Iteration:  72% 362/500 [02:46<01:03,  2.17it/s]\u001b[A\n",
            "Iteration:  73% 363/500 [02:47<01:03,  2.17it/s]\u001b[A\n",
            "Iteration:  73% 364/500 [02:47<01:02,  2.17it/s]\u001b[A\n",
            "Iteration:  73% 365/500 [02:48<01:01,  2.18it/s]\u001b[A\n",
            "Iteration:  73% 366/500 [02:48<01:01,  2.18it/s]\u001b[A\n",
            "Iteration:  73% 367/500 [02:49<01:01,  2.18it/s]\u001b[A\n",
            "Iteration:  74% 368/500 [02:49<01:00,  2.18it/s]\u001b[A\n",
            "Iteration:  74% 369/500 [02:50<01:00,  2.16it/s]\u001b[A\n",
            "Iteration:  74% 370/500 [02:50<01:00,  2.16it/s]\u001b[A\n",
            "Iteration:  74% 371/500 [02:51<00:59,  2.16it/s]\u001b[A\n",
            "Iteration:  74% 372/500 [02:51<00:59,  2.17it/s]\u001b[A\n",
            "Iteration:  75% 373/500 [02:51<00:58,  2.17it/s]\u001b[A\n",
            "Iteration:  75% 374/500 [02:52<00:57,  2.17it/s]\u001b[A\n",
            "Iteration:  75% 375/500 [02:52<00:57,  2.17it/s]\u001b[A\n",
            "Iteration:  75% 376/500 [02:53<00:56,  2.18it/s]\u001b[A\n",
            "Iteration:  75% 377/500 [02:53<00:56,  2.18it/s]\u001b[A\n",
            "Iteration:  76% 378/500 [02:54<00:56,  2.18it/s]\u001b[A\n",
            "Iteration:  76% 379/500 [02:54<00:55,  2.17it/s]\u001b[A\n",
            "Iteration:  76% 380/500 [02:55<00:55,  2.16it/s]\u001b[A\n",
            "Iteration:  76% 381/500 [02:55<00:55,  2.16it/s]\u001b[A\n",
            "Iteration:  76% 382/500 [02:56<00:54,  2.17it/s]\u001b[A\n",
            "Iteration:  77% 383/500 [02:56<00:53,  2.17it/s]\u001b[A\n",
            "Iteration:  77% 384/500 [02:57<00:53,  2.17it/s]\u001b[A\n",
            "Iteration:  77% 385/500 [02:57<00:52,  2.18it/s]\u001b[A\n",
            "Iteration:  77% 386/500 [02:57<00:52,  2.18it/s]\u001b[A\n",
            "Iteration:  77% 387/500 [02:58<00:51,  2.18it/s]\u001b[A\n",
            "Iteration:  78% 388/500 [02:58<00:51,  2.18it/s]\u001b[A\n",
            "Iteration:  78% 389/500 [02:59<00:50,  2.18it/s]\u001b[A\n",
            "Iteration:  78% 390/500 [02:59<00:50,  2.17it/s]\u001b[A\n",
            "Iteration:  78% 391/500 [03:00<00:50,  2.16it/s]\u001b[A\n",
            "Iteration:  78% 392/500 [03:00<00:49,  2.17it/s]\u001b[A\n",
            "Iteration:  79% 393/500 [03:01<00:49,  2.17it/s]\u001b[A\n",
            "Iteration:  79% 394/500 [03:01<00:48,  2.17it/s]\u001b[A\n",
            "Iteration:  79% 395/500 [03:02<00:48,  2.17it/s]\u001b[A\n",
            "Iteration:  79% 396/500 [03:02<00:47,  2.18it/s]\u001b[A\n",
            "Iteration:  79% 397/500 [03:03<00:47,  2.18it/s]\u001b[A\n",
            "Iteration:  80% 398/500 [03:03<00:46,  2.18it/s]\u001b[A\n",
            "Iteration:  80% 399/500 [03:03<00:46,  2.17it/s]\u001b[A{\"learning_rate\": 5e-06, \"loss\": 0.6171472027897835, \"step\": 900}\n",
            "\n",
            "Iteration:  80% 400/500 [03:04<00:45,  2.18it/s]\u001b[A\n",
            "Iteration:  80% 401/500 [03:04<00:45,  2.17it/s]\u001b[A\n",
            "Iteration:  80% 402/500 [03:05<00:45,  2.16it/s]\u001b[A\n",
            "Iteration:  81% 403/500 [03:05<00:44,  2.17it/s]\u001b[A\n",
            "Iteration:  81% 404/500 [03:06<00:44,  2.17it/s]\u001b[A\n",
            "Iteration:  81% 405/500 [03:06<00:43,  2.17it/s]\u001b[A\n",
            "Iteration:  81% 406/500 [03:07<00:43,  2.18it/s]\u001b[A\n",
            "Iteration:  81% 407/500 [03:07<00:42,  2.18it/s]\u001b[A\n",
            "Iteration:  82% 408/500 [03:08<00:42,  2.18it/s]\u001b[A\n",
            "Iteration:  82% 409/500 [03:08<00:41,  2.18it/s]\u001b[A\n",
            "Iteration:  82% 410/500 [03:08<00:41,  2.17it/s]\u001b[A\n",
            "Iteration:  82% 411/500 [03:09<00:41,  2.17it/s]\u001b[A\n",
            "Iteration:  82% 412/500 [03:09<00:40,  2.17it/s]\u001b[A\n",
            "Iteration:  83% 413/500 [03:10<00:40,  2.16it/s]\u001b[A\n",
            "Iteration:  83% 414/500 [03:10<00:39,  2.17it/s]\u001b[A\n",
            "Iteration:  83% 415/500 [03:11<00:39,  2.17it/s]\u001b[A\n",
            "Iteration:  83% 416/500 [03:11<00:38,  2.16it/s]\u001b[A\n",
            "Iteration:  83% 417/500 [03:12<00:38,  2.16it/s]\u001b[A\n",
            "Iteration:  84% 418/500 [03:12<00:37,  2.17it/s]\u001b[A\n",
            "Iteration:  84% 419/500 [03:13<00:37,  2.17it/s]\u001b[A\n",
            "Iteration:  84% 420/500 [03:13<00:36,  2.18it/s]\u001b[A\n",
            "Iteration:  84% 421/500 [03:14<00:36,  2.18it/s]\u001b[A\n",
            "Iteration:  84% 422/500 [03:14<00:35,  2.18it/s]\u001b[A\n",
            "Iteration:  85% 423/500 [03:14<00:35,  2.18it/s]\u001b[A\n",
            "Iteration:  85% 424/500 [03:15<00:35,  2.17it/s]\u001b[A\n",
            "Iteration:  85% 425/500 [03:15<00:34,  2.17it/s]\u001b[A\n",
            "Iteration:  85% 426/500 [03:16<00:34,  2.17it/s]\u001b[A\n",
            "Iteration:  85% 427/500 [03:16<00:33,  2.17it/s]\u001b[A\n",
            "Iteration:  86% 428/500 [03:17<00:33,  2.17it/s]\u001b[A\n",
            "Iteration:  86% 429/500 [03:17<00:32,  2.17it/s]\u001b[A\n",
            "Iteration:  86% 430/500 [03:18<00:32,  2.16it/s]\u001b[A\n",
            "Iteration:  86% 431/500 [03:18<00:31,  2.17it/s]\u001b[A\n",
            "Iteration:  86% 432/500 [03:19<00:31,  2.17it/s]\u001b[A\n",
            "Iteration:  87% 433/500 [03:19<00:30,  2.17it/s]\u001b[A\n",
            "Iteration:  87% 434/500 [03:20<00:30,  2.17it/s]\u001b[A\n",
            "Iteration:  87% 435/500 [03:20<00:30,  2.16it/s]\u001b[A\n",
            "Iteration:  87% 436/500 [03:20<00:29,  2.17it/s]\u001b[A\n",
            "Iteration:  87% 437/500 [03:21<00:29,  2.15it/s]\u001b[A\n",
            "Iteration:  88% 438/500 [03:21<00:28,  2.16it/s]\u001b[A\n",
            "Iteration:  88% 439/500 [03:22<00:28,  2.17it/s]\u001b[A\n",
            "Iteration:  88% 440/500 [03:22<00:27,  2.17it/s]\u001b[A\n",
            "Iteration:  88% 441/500 [03:23<00:27,  2.16it/s]\u001b[A\n",
            "Iteration:  88% 442/500 [03:23<00:26,  2.16it/s]\u001b[A\n",
            "Iteration:  89% 443/500 [03:24<00:26,  2.17it/s]\u001b[A\n",
            "Iteration:  89% 444/500 [03:24<00:25,  2.17it/s]\u001b[A\n",
            "Iteration:  89% 445/500 [03:25<00:25,  2.17it/s]\u001b[A\n",
            "Iteration:  89% 446/500 [03:25<00:24,  2.16it/s]\u001b[A\n",
            "Iteration:  89% 447/500 [03:26<00:24,  2.17it/s]\u001b[A\n",
            "Iteration:  90% 448/500 [03:26<00:23,  2.17it/s]\u001b[A\n",
            "Iteration:  90% 449/500 [03:26<00:23,  2.17it/s]\u001b[A{\"learning_rate\": 2.5e-06, \"loss\": 0.6144977104663849, \"step\": 950}\n",
            "\n",
            "Iteration:  90% 450/500 [03:27<00:23,  2.17it/s]\u001b[A\n",
            "Iteration:  90% 451/500 [03:27<00:22,  2.17it/s]\u001b[A\n",
            "Iteration:  90% 452/500 [03:28<00:22,  2.18it/s]\u001b[A\n",
            "Iteration:  91% 453/500 [03:28<00:21,  2.18it/s]\u001b[A\n",
            "Iteration:  91% 454/500 [03:29<00:21,  2.18it/s]\u001b[A\n",
            "Iteration:  91% 455/500 [03:29<00:20,  2.18it/s]\u001b[A\n",
            "Iteration:  91% 456/500 [03:30<00:20,  2.18it/s]\u001b[A\n",
            "Iteration:  91% 457/500 [03:30<00:19,  2.17it/s]\u001b[A\n",
            "Iteration:  92% 458/500 [03:31<00:19,  2.17it/s]\u001b[A\n",
            "Iteration:  92% 459/500 [03:31<00:18,  2.18it/s]\u001b[A\n",
            "Iteration:  92% 460/500 [03:32<00:18,  2.18it/s]\u001b[A\n",
            "Iteration:  92% 461/500 [03:32<00:17,  2.17it/s]\u001b[A\n",
            "Iteration:  92% 462/500 [03:32<00:17,  2.17it/s]\u001b[A\n",
            "Iteration:  93% 463/500 [03:33<00:17,  2.17it/s]\u001b[A\n",
            "Iteration:  93% 464/500 [03:33<00:16,  2.18it/s]\u001b[A\n",
            "Iteration:  93% 465/500 [03:34<00:16,  2.18it/s]\u001b[A\n",
            "Iteration:  93% 466/500 [03:34<00:15,  2.18it/s]\u001b[A\n",
            "Iteration:  93% 467/500 [03:35<00:15,  2.18it/s]\u001b[A\n",
            "Iteration:  94% 468/500 [03:35<00:14,  2.17it/s]\u001b[A\n",
            "Iteration:  94% 469/500 [03:36<00:14,  2.17it/s]\u001b[A\n",
            "Iteration:  94% 470/500 [03:36<00:13,  2.16it/s]\u001b[A\n",
            "Iteration:  94% 471/500 [03:37<00:13,  2.17it/s]\u001b[A\n",
            "Iteration:  94% 472/500 [03:37<00:12,  2.17it/s]\u001b[A\n",
            "Iteration:  95% 473/500 [03:38<00:12,  2.17it/s]\u001b[A\n",
            "Iteration:  95% 474/500 [03:38<00:11,  2.18it/s]\u001b[A\n",
            "Iteration:  95% 475/500 [03:38<00:11,  2.18it/s]\u001b[A\n",
            "Iteration:  95% 476/500 [03:39<00:11,  2.18it/s]\u001b[A\n",
            "Iteration:  95% 477/500 [03:39<00:10,  2.18it/s]\u001b[A\n",
            "Iteration:  96% 478/500 [03:40<00:10,  2.18it/s]\u001b[A\n",
            "Iteration:  96% 479/500 [03:40<00:09,  2.17it/s]\u001b[A\n",
            "Iteration:  96% 480/500 [03:41<00:09,  2.17it/s]\u001b[A\n",
            "Iteration:  96% 481/500 [03:41<00:08,  2.15it/s]\u001b[A\n",
            "Iteration:  96% 482/500 [03:42<00:08,  2.16it/s]\u001b[A\n",
            "Iteration:  97% 483/500 [03:42<00:07,  2.16it/s]\u001b[A\n",
            "Iteration:  97% 484/500 [03:43<00:07,  2.17it/s]\u001b[A\n",
            "Iteration:  97% 485/500 [03:43<00:06,  2.17it/s]\u001b[A\n",
            "Iteration:  97% 486/500 [03:44<00:06,  2.17it/s]\u001b[A\n",
            "Iteration:  97% 487/500 [03:44<00:05,  2.17it/s]\u001b[A\n",
            "Iteration:  98% 488/500 [03:44<00:05,  2.18it/s]\u001b[A\n",
            "Iteration:  98% 489/500 [03:45<00:05,  2.18it/s]\u001b[A\n",
            "Iteration:  98% 490/500 [03:45<00:04,  2.16it/s]\u001b[A\n",
            "Iteration:  98% 491/500 [03:46<00:04,  2.17it/s]\u001b[A\n",
            "Iteration:  98% 492/500 [03:46<00:03,  2.17it/s]\u001b[A\n",
            "Iteration:  99% 493/500 [03:47<00:03,  2.17it/s]\u001b[A\n",
            "Iteration:  99% 494/500 [03:47<00:02,  2.18it/s]\u001b[A\n",
            "Iteration:  99% 495/500 [03:48<00:02,  2.18it/s]\u001b[A\n",
            "Iteration:  99% 496/500 [03:48<00:01,  2.18it/s]\u001b[A\n",
            "Iteration:  99% 497/500 [03:49<00:01,  2.17it/s]\u001b[A\n",
            "Iteration: 100% 498/500 [03:49<00:00,  2.17it/s]\u001b[A\n",
            "Iteration: 100% 499/500 [03:49<00:00,  2.16it/s]\u001b[A{\"learning_rate\": 0.0, \"loss\": 0.6224822691082954, \"step\": 1000}\n",
            "\n",
            "Iteration: 100% 500/500 [03:50<00:00,  2.17it/s]\n",
            "Epoch: 100% 2/2 [07:41<00:00, 230.57s/it]\n",
            "10/16/2020 16:08:32 - INFO - __main__ -    global_step = 1000, average loss = 0.8788259804993868\n",
            "10/16/2020 16:08:32 - INFO - utils_ichi -   Loading features from cached file ./data/ichi/cached_dev_bert-base-uncased_256_ichi\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_ichi\n",
            "10/16/2020 16:08:33 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "10/16/2020 16:08:33 - INFO - __main__ -     Num examples = 3000\n",
            "10/16/2020 16:08:33 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 188/188 [00:26<00:00,  7.02it/s]\n",
            "10/16/2020 16:09:00 - INFO - __main__ -   ***** Eval results  *****\n",
            "10/16/2020 16:09:00 - INFO - __main__ -     acc = 0.6973333333333334\n",
            "10/16/2020 16:09:00 - INFO - __main__ -     f1 = 0.6967641508197268\n",
            "10/16/2020 16:09:00 - INFO - __main__ -   Saving model checkpoint to ./tmp/ichi_bert_base_new\n",
            "10/16/2020 16:09:06 - INFO - transformers.tokenization_utils -   Model name './tmp/ichi_bert_base_new' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming './tmp/ichi_bert_base_new' is a path or url to a directory containing tokenizer files.\n",
            "10/16/2020 16:09:06 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/vocab.txt\n",
            "10/16/2020 16:09:06 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/added_tokens.json\n",
            "10/16/2020 16:09:06 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/special_tokens_map.json\n",
            "10/16/2020 16:09:06 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/tokenizer_config.json\n",
            "10/16/2020 16:09:06 - INFO - transformers.tokenization_utils -   Model name './tmp/ichi_bert_base_new' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming './tmp/ichi_bert_base_new' is a path or url to a directory containing tokenizer files.\n",
            "10/16/2020 16:09:06 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/vocab.txt\n",
            "10/16/2020 16:09:06 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/added_tokens.json\n",
            "10/16/2020 16:09:06 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/special_tokens_map.json\n",
            "10/16/2020 16:09:06 - INFO - transformers.tokenization_utils -   loading file ./tmp/ichi_bert_base_new/tokenizer_config.json\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_ichi\n",
            "10/16/2020 16:09:06 - INFO - __main__ -   Evaluate the following checkpoints: ['./tmp/ichi_bert_base_new']\n",
            "10/16/2020 16:09:11 - INFO - utils_ichi -   Loading features from cached file ./data/ichi/cached_dev_bert-base-uncased_256_ichi\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_ichi\n",
            "10/16/2020 16:09:12 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "10/16/2020 16:09:12 - INFO - __main__ -     Num examples = 3000\n",
            "10/16/2020 16:09:12 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 188/188 [00:26<00:00,  7.01it/s]\n",
            "10/16/2020 16:09:39 - INFO - __main__ -   ***** Eval results  *****\n",
            "10/16/2020 16:09:39 - INFO - __main__ -     acc = 0.6973333333333334\n",
            "10/16/2020 16:09:39 - INFO - __main__ -     f1 = 0.6967641508197268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H01TYmyzS8n4",
        "outputId": "80cdd7f2-2e8a-4f2d-b3b8-371f0b747450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Oct 16 15:17:42 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PlJzq0GsRjF",
        "outputId": "23ca1369-e83c-4d1f-dd8c-7bab9eb15d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bioasq.lip6.fr\t\t      hubconf.py\tsetup.cfg\n",
            "biomedicalWordVectors.tar.gz  index.html\tsetup.py\n",
            "CONTRIBUTING.md\t\t      index.html.1\tsrc\n",
            "data\t\t\t      LICENSE\t\ttemplates\n",
            "deploy_multi_version_doc.sh   Makefile\t\ttests\n",
            "docker\t\t\t      MANIFEST.in\ttmp\n",
            "docs\t\t\t      notebooks\t\ttransformers-cli\n",
            "examples\t\t      README.md\t\tutils\n",
            "glove.840B.300d.txt\t      requirements.txt\tvalohai.yaml\n",
            "glove.840B.300d.zip\t      runs\t\tword2vecTools\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g11ukVnhuyD2",
        "outputId": "a0b60df4-7592-48a7-b7e8-1fa2a778f21f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-15 22:47:26.878782: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "10/15/2020 22:47:28 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "10/15/2020 22:47:29 - INFO - filelock -   Lock 140380687211376 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "10/15/2020 22:47:29 - INFO - filelock -   Lock 140380687211376 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "10/15/2020 22:47:29 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "10/15/2020 22:47:29 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"ichi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 7,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "10/15/2020 22:47:29 - INFO - filelock -   Lock 140380687703400 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "10/15/2020 22:47:29 - INFO - filelock -   Lock 140380687703400 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "10/15/2020 22:47:29 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "10/15/2020 22:47:29 - INFO - utils_ichi -   Loading features from cached file ./data/ichi/cached_train_bert-base-uncased_256_ichi\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_ichi\n",
            "10/15/2020 22:47:33 - INFO - filelock -   Lock 140380687208744 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "10/15/2020 22:47:33 - INFO - filelock -   Lock 140380687208744 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "10/15/2020 22:47:33 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "10/15/2020 22:47:37 - INFO - transformers.modeling_utils -   Weights of lcf_BERT not initialized from pretrained model: ['bert_SA.SA.query.weight', 'bert_SA.SA.query.bias', 'bert_SA.SA.key.weight', 'bert_SA.SA.key.bias', 'bert_SA.SA.value.weight', 'bert_SA.SA.value.bias', 'linear_double_cdm_or_cdw.weight', 'linear_double_cdm_or_cdw.bias', 'linear_triple_lcf_global.weight', 'linear_triple_lcf_global.bias', 'bert_pooler_org.dense.weight', 'bert_pooler_org.dense.bias', 'bert_pooler.dense.weight', 'bert_pooler.dense.bias', 'dense.weight', 'dense.bias']\n",
            "10/15/2020 22:47:37 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in lcf_BERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "10/15/2020 22:47:42 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='./data/ichi', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, embedding_dim_word2vec=300, embedding_type='glove', eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_context_focus='cdm', local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=256, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=2.0, output_dir='./tmp/ichi_bert_base_new', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=16, save_steps=10000, seed=42, server_ip='', server_port='', task_name='ichi', tokenizer_name='', use_single_bert=False, warmup_steps=0, weight_decay=0.0)\n",
            "10/15/2020 22:47:42 - INFO - utils_ichi -   Loading features from cached file ./data/ichi/cached_dev_bert-base-uncased_256_ichi\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_ichi\n",
            "10/15/2020 22:47:43 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "10/15/2020 22:47:43 - INFO - __main__ -     Num examples = 3000\n",
            "10/15/2020 22:47:43 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 188/188 [00:45<00:00,  4.13it/s]\n",
            "10/15/2020 22:48:29 - INFO - __main__ -   ***** Eval results  *****\n",
            "10/15/2020 22:48:29 - INFO - __main__ -     acc = 0.12166666666666667\n",
            "10/15/2020 22:48:29 - INFO - __main__ -     f1 = 0.07237215449401717\n",
            "10/15/2020 22:48:29 - INFO - transformers.tokenization_utils -   Model name './tmp/ichi_bert_base_new' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming './tmp/ichi_bert_base_new' is a path or url to a directory containing tokenizer files.\n",
            "10/15/2020 22:48:29 - INFO - transformers.tokenization_utils -   Didn't find file ./tmp/ichi_bert_base_new/vocab.txt. We won't load it.\n",
            "10/15/2020 22:48:29 - INFO - transformers.tokenization_utils -   Didn't find file ./tmp/ichi_bert_base_new/added_tokens.json. We won't load it.\n",
            "10/15/2020 22:48:29 - INFO - transformers.tokenization_utils -   Didn't find file ./tmp/ichi_bert_base_new/special_tokens_map.json. We won't load it.\n",
            "10/15/2020 22:48:29 - INFO - transformers.tokenization_utils -   Didn't find file ./tmp/ichi_bert_base_new/tokenizer_config.json. We won't load it.\n",
            "Traceback (most recent call last):\n",
            "  File \"./examples/ichi/run_ichi.py\", line 704, in <module>\n",
            "    main()\n",
            "  File \"./examples/ichi/run_ichi.py\", line 660, in main\n",
            "    tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\", line 309, in from_pretrained\n",
            "    return cls._from_pretrained(*inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\", line 382, in _from_pretrained\n",
            "    list(cls.vocab_files_names.values()),\n",
            "OSError: Model name './tmp/ichi_bert_base_new' was not found in tokenizers model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). We assumed './tmp/ichi_bert_base_new' was a path or url to a directory containing vocabulary files named ['vocab.txt'] but couldn't find such vocabulary files at this path or url.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9QFTiYbc0nA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}