{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CADEC Ablation bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqx9cKKKkqBr",
        "outputId": "d44d22dc-a3c9-4ffa-92bf-1596b7a61920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers/\n",
        "!git checkout 896a0eb1fd861bc37097a9b669ebf4cb8d523de7\n",
        "\n",
        "%cd transformers/\n",
        "!mkdir examples/cadec/\n",
        "!pip install -r requirements.txt\n",
        "!pip install .\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 47193 (delta 0), reused 2 (delta 0), pack-reused 47185\u001b[K\n",
            "Receiving objects: 100% (47193/47193), 33.80 MiB | 27.19 MiB/s, done.\n",
            "Resolving deltas: 100% (32817/32817), done.\n",
            "/content/transformers\n",
            "Note: checking out '896a0eb1fd861bc37097a9b669ebf4cb8d523de7'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 896a0eb1 Merge pull request #2459 from Perseus14/patch-4\n",
            "/content\n",
            "Cloning into 'ICHI-dataset'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 54 (delta 21), reused 42 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (54/54), done.\n",
            "/content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.18.5)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 4.4MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/08/f1ff665147a5d75b871bbe5ba76916f6490419c52a33e588385c4b69281b/boto3-1.15.18-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 34.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 36.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 27.7MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.19.0,>=1.18.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/72/984ac8f33b5c8df5ff63f323a8724f65b4d0f8956968b942b77d35d3a1ef/botocore-1.18.18-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 49.7MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 5)) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->-r requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->-r requirements.txt (line 9)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->-r requirements.txt (line 9)) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.19.0,>=1.18.18->boto3->-r requirements.txt (line 3)) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=fd0bb3777ad21cc79684d61097387f182b95c39f28c9b7fe450ec565e5f96132\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, jmespath, botocore, s3transfer, boto3, sentencepiece, sacremoses\n",
            "Successfully installed boto3-1.15.18 botocore-1.18.18 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.0.11\n",
            "Processing /content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (0.0.11)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.15.18)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (0.0.43)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.19.0,>=1.18.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (1.18.18)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0) (2020.6.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.19.0,>=1.18.18->boto3->transformers==2.3.0) (2.8.1)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.3.0-cp36-none-any.whl size=451157 sha256=a69b7d55585faeeebcc95415f68cb0a102d3ff386eaafc074c2846f48f0ac7fc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7z8wcr0l/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-2.3.0\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D79M5NpS8vh"
      },
      "source": [
        "# ########### Uncomment it to download Glove Vectors\n",
        "\n",
        "# !curl -O -J -L http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "# !unzip glove.840B.300d.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-EzqBB_PvmT"
      },
      "source": [
        "# ########### Uncomment it to download BioASQ Embeddings\n",
        "\n",
        "# !curl -O -J -L http://bioasq.lip6.fr/tools/BioASQword2vec/\n",
        "# !tar -xvzf biomedicalWordVectors.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL0KtyeJkv6Z"
      },
      "source": [
        "# class ICHIDataset(Dataset):\n",
        "#     def __init__(self, fname, tokenizer):\n",
        "#         fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "#         lines = fin.readlines()\n",
        "#         fin.close()\n",
        "\n",
        "#         all_data = []\n",
        "#         for i in range(0, len(lines), 3):\n",
        "#             text_left, _, text_right = [s.lower().strip() for s in lines[i].partition(\"$T$\")]\n",
        "#             aspect = lines[i + 1].lower().strip()\n",
        "#             polarity = lines[i + 2].strip()\n",
        "\n",
        "#             text_raw_indices = tokenizer.text_to_sequence(text_left + \" \" + aspect + \" \" + text_right)\n",
        "#             text_raw_without_aspect_indices = tokenizer.text_to_sequence(text_left + \" \" + text_right)\n",
        "#             text_left_indices = tokenizer.text_to_sequence(text_left)\n",
        "#             text_left_with_aspect_indices = tokenizer.text_to_sequence(text_left + \" \" + aspect)\n",
        "#             text_right_indices = tokenizer.text_to_sequence(text_right, reverse=True)\n",
        "#             text_right_with_aspect_indices = tokenizer.text_to_sequence(\" \" + aspect + \" \" + text_right, reverse=True)\n",
        "#             aspect_indices = tokenizer.text_to_sequence(aspect)\n",
        "#             left_context_len = np.sum(text_left_indices != 0)\n",
        "#             aspect_len = np.sum(aspect_indices != 0)\n",
        "#             aspect_in_text = torch.tensor([left_context_len.item(), (left_context_len + aspect_len - 1).item()])\n",
        "#             polarity = int(polarity) + 1\n",
        "\n",
        "#             text_bert_indices = tokenizer.text_to_sequence('[CLS] ' + text_left + \" \" + aspect + \" \" + text_right + ' [SEP] ' + aspect + \" [SEP]\")\n",
        "#             bert_segments_ids = np.asarray([0] * (np.sum(text_raw_indices != 0) + 2) + [1] * (aspect_len + 1))\n",
        "#             bert_segments_ids = pad_and_truncate(bert_segments_ids, tokenizer.max_seq_len)\n",
        "\n",
        "#             text_raw_bert_indices = tokenizer.text_to_sequence(\"[CLS] \" + text_left + \" \" + aspect + \" \" + text_right + \" [SEP]\")\n",
        "#             aspect_bert_indices = tokenizer.text_to_sequence(\"[CLS] \" + aspect + \" [SEP]\")\n",
        "\n",
        "#             data = {\n",
        "#                 'text_bert_indices': text_bert_indices,\n",
        "#                 'bert_segments_ids': bert_segments_ids,\n",
        "#                 'text_raw_bert_indices': text_raw_bert_indices,\n",
        "#                 'aspect_bert_indices': aspect_bert_indices,\n",
        "#                 'text_raw_indices': text_raw_indices,\n",
        "#                 'text_raw_without_aspect_indices': text_raw_without_aspect_indices,\n",
        "#                 'text_left_indices': text_left_indices,\n",
        "#                 'text_left_with_aspect_indices': text_left_with_aspect_indices,\n",
        "#                 'text_right_indices': text_right_indices,\n",
        "#                 'text_right_with_aspect_indices': text_right_with_aspect_indices,\n",
        "#                 'aspect_indices': aspect_indices,\n",
        "#                 'aspect_in_text': aspect_in_text,\n",
        "#                 'polarity': polarity,\n",
        "#             }\n",
        "\n",
        "#             all_data.append(data)\n",
        "#         self.data = all_data\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         return self.data[index]\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG8YjUsTm2Eg",
        "outputId": "de1d532d-2b00-41f5-9c7a-a427dd76b75e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGkNpSjDrXjh",
        "outputId": "39b8c102-6b2d-4e64-dad0-a33791e2bb32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile /content/transformers/examples/cadec/utils_ichi.py\n",
        "import logging\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import re\n",
        "import csv\n",
        "import pickle\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from sklearn.metrics import matthews_corrcoef, f1_score\n",
        "from transformers.file_utils import is_tf_available \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "if is_tf_available():\n",
        "    import tensorflow as tf\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def simple_accuracy(preds, labels):\n",
        "    return (preds == labels).mean()\n",
        "\n",
        "def acc_and_f1(preds, labels):\n",
        "    acc_0 = simple_accuracy(preds[:,0], labels[:,0])\n",
        "    f1_0 = f1_score(y_true=labels[:,0], y_pred=preds[:,0], average='macro')\n",
        "    acc_1 = simple_accuracy(preds[:,1], labels[:,1])\n",
        "    f1_1 = f1_score(y_true=labels[:,1], y_pred=preds[:,1], average='macro')\n",
        "    acc_2 = simple_accuracy(preds[:,2], labels[:,2])\n",
        "    f1_2 = f1_score(y_true=labels[:,2], y_pred=preds[:,2], average='macro')\n",
        "    acc_3 = simple_accuracy(preds[:,3], labels[:,3])\n",
        "    f1_3 = f1_score(y_true=labels[:,3], y_pred=preds[:,3], average='macro')\n",
        "    acc_4 = simple_accuracy(preds[:,4], labels[:,4])\n",
        "    f1_4 = f1_score(y_true=labels[:,4], y_pred=preds[:,4], average='macro')\n",
        "    return {\n",
        "        \"acc_0\": acc_0,\n",
        "        \"f1_0\": f1_0,\n",
        "        \"acc_1\": acc_1,\n",
        "        \"f1_1\": f1_1,\n",
        "        \"acc_2\": acc_2,\n",
        "        \"f1_2\": f1_2,\n",
        "        \"acc_3\": acc_3,\n",
        "        \"f1_3\": f1_3,\n",
        "        \"acc_4\": acc_4,\n",
        "        \"f1_4\": f1_4,\n",
        "    }\n",
        "\n",
        "def compute_metrics(preds, labels):\n",
        "    # return {\"acc\": simple_accuracy(preds, labels)}\n",
        "    return acc_and_f1(preds, labels)\n",
        "\n",
        "\n",
        "def pad_and_truncate(sequence, maxlen, dtype='int64', padding='pre', truncating='post', value=0):\n",
        "    x = (np.ones(maxlen) * value).astype(dtype)\n",
        "    if truncating == 'pre':\n",
        "        trunc = sequence[-maxlen:]\n",
        "    else:\n",
        "        trunc = sequence[:maxlen]\n",
        "    trunc = np.asarray(trunc, dtype=dtype)\n",
        "    if padding == 'post':\n",
        "        x[:len(trunc)] = trunc\n",
        "    else:\n",
        "        x[-len(trunc):] = trunc\n",
        "    return x\n",
        "\n",
        "class Tokenizer(object):\n",
        "    def __init__(self, max_seq_len, max_num_words=None,lower=True):\n",
        "        self.lower = lower\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.word2idx = {}\n",
        "        self.word_freq = {}\n",
        "        self.idx2word = {}\n",
        "        self.idx2word[0] = '<PAD>'\n",
        "        self.word2idx['<PAD>'] = 0\n",
        "        self.word_freq['<PAD>'] = 100000\n",
        "        self.idx = 1\n",
        "        self.max_num_words = max_num_words\n",
        "\n",
        "    def fit_on_text(self, text):\n",
        "        if self.lower:\n",
        "            text = text.lower()\n",
        "        words = text.split()\n",
        "        for word in words:\n",
        "            if word not in self.word2idx:\n",
        "                self.word2idx[word] = self.idx\n",
        "                self.word_freq[word] = 1\n",
        "                self.idx2word[self.idx] = word\n",
        "                self.idx += 1\n",
        "            else:\n",
        "                self.word_freq[word] = self.word_freq[word] + 1\n",
        "    \n",
        "    def update_tokenizer(self):\n",
        "        if self.max_num_words == None:\n",
        "            return\n",
        "        elif self.max_num_words >= self.idx:\n",
        "            return \n",
        "        else:\n",
        "            del self.word_freq['<PAD>']\n",
        "            self.word_freq = {k: v for k, v in sorted(self.word_freq.items(), key=lambda item: item[1], reverse=True)}\n",
        "            self.word2idx = {}\n",
        "            self.idx2word = {}\n",
        "            self.idx2word[0] = '<PAD>'\n",
        "            self.word2idx['<PAD>'] = 0\n",
        "            self.idx = 1\n",
        "            for i, key in enumerate(self.word_freq):\n",
        "                if i >= self.max_num_words:\n",
        "                    break\n",
        "                else:\n",
        "                    self.word2idx[key] = i+1\n",
        "                    self.idx2word[i+1] = key\n",
        "                    self.idx += 1\n",
        "            self.word_freq['<PAD>'] = 100000\n",
        "\n",
        "\n",
        "\n",
        "    def fit_on_examples(self, examples):\n",
        "        is_tf_dataset = False\n",
        "        if is_tf_available() and isinstance(examples, tf.data.Dataset):\n",
        "            is_tf_dataset = True\n",
        "        processor = CADECProcessor()\n",
        "        for example in examples:\n",
        "            if is_tf_dataset:\n",
        "                example = processor.get_example_from_tensor_dict(example)\n",
        "                example = processor.tfds_map(example)\n",
        "            self.fit_on_text(example.clean_text)\n",
        "\n",
        "    def text_to_sequence(self, text, reverse=False, padding='pre', truncating='post'):\n",
        "        if self.lower:\n",
        "            text = text.lower()\n",
        "        words = text.split()\n",
        "        unknownidx = len(self.word2idx)+1\n",
        "        if (self.max_num_words == None) or (self.max_num_words >= self.idx):\n",
        "            sequence = [self.word2idx[w] if w in self.word2idx else unknownidx for w in words]\n",
        "        else:\n",
        "            sequence = []\n",
        "            for w in words:\n",
        "                if w in self.word2idx:\n",
        "                    if self.word2idx[w] > self.max_num_words:\n",
        "                        sequence.append(unknownidx)\n",
        "                    else:\n",
        "                        sequence.append(self.word2idx[w])\n",
        "                else:\n",
        "                    sequence.append(unknownidx)\n",
        "        if len(sequence) == 0:\n",
        "            sequence = [0]\n",
        "        if reverse:\n",
        "            sequence = sequence[::-1]\n",
        "        return pad_and_truncate(sequence, self.max_seq_len, padding=padding, truncating=truncating)\n",
        "\n",
        "def _load_word_vec_glove(path, word2idx=None):\n",
        "    fin = open(path, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    word_vec = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split()\n",
        "        if word2idx is None or tokens[0] in word2idx.keys():\n",
        "            try:\n",
        "                word_vec[tokens[0]] = np.asarray(tokens[1:], dtype='float32')\n",
        "            except:\n",
        "                pass\n",
        "    return word_vec\n",
        "    \n",
        "def build_embedding_matrix_glove(word2idx, embed_dim, dat_fname, fname):\n",
        "    if os.path.exists(dat_fname):\n",
        "        print('loading embedding_matrix(glove): ', dat_fname)\n",
        "        embedding_matrix = pickle.load(open(dat_fname, 'rb'))\n",
        "    else:\n",
        "        print('loading word vectors...(glove)')\n",
        "        embedding_matrix = np.zeros((len(word2idx) + 2, embed_dim))  # idx 0 and len(word2idx)+1 are all-zeros\n",
        "        fname = fname + '/glove.twitter.27B/glove.twitter.27B.' + str(embed_dim) + 'd.txt' \\\n",
        "            if embed_dim != 300 else fname + '/glove.840B.300d.txt'\n",
        "        word_vec = _load_word_vec_glove(fname, word2idx=word2idx)\n",
        "        print('building embedding_matrix:', dat_fname)\n",
        "        for word, i in word2idx.items():\n",
        "            vec = word_vec.get(word)\n",
        "            if vec is not None:\n",
        "                # words not found in embedding index will be all-zeros.\n",
        "                embedding_matrix[i] = vec\n",
        "        pickle.dump(embedding_matrix, open(dat_fname, 'wb'))\n",
        "    return embedding_matrix\n",
        "\n",
        "def build_embedding_matrix_BioASQ(word2idx, embed_dim, dat_fname, fname):\n",
        "    if os.path.exists(dat_fname):\n",
        "        print('loading embedding_matrix(BioASQ):', dat_fname)\n",
        "        embedding_matrix = pickle.load(open(dat_fname, 'rb'))\n",
        "    else:\n",
        "        print('loading word vectors...(BioASQ)')\n",
        "        embedding_matrix = np.zeros((len(word2idx) + 2, embed_dim))  # idx 0 and len(word2idx)+1 are all-zeros\n",
        "        f = open(fname + \"/word2vecTools/types.txt\",\"r\")\n",
        "        i = 0\n",
        "        names = []\n",
        "        for line in f:\n",
        "            names.append(line.split('\\n')[0])\n",
        "            i = i + 1\n",
        "        vectors = np.loadtxt(fname + \"/word2vecTools/vectors.txt\")\n",
        "        word_vec = {}\n",
        "        for (index, name) in enumerate(names):\n",
        "            word_vec[name] = index\n",
        "\n",
        "        print('building embedding_matrix:', dat_fname)\n",
        "        for word, i in word2idx.items():\n",
        "            if word in word_vec.keys():\n",
        "                vec = vectors[word_vec[word]]\n",
        "            else:\n",
        "                vec = None\n",
        "            if vec is not None:\n",
        "                # words not found in embedding index will be all-zeros.\n",
        "                embedding_matrix[i] = vec\n",
        "        pickle.dump(embedding_matrix, open(dat_fname, 'wb'))\n",
        "    return embedding_matrix\n",
        "\n",
        "def convert_examples_to_features(\n",
        "    examples,\n",
        "    tokenizer,\n",
        "    tokenizer_cleantext,\n",
        "    max_length=512,\n",
        "    task=None,\n",
        "    label_list=None,\n",
        "    output_mode=None,\n",
        "    pad_on_left=False,\n",
        "    pad_token=0,\n",
        "    pad_token_segment_id=0,\n",
        "    mask_padding_with_zero=True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Loads a data file into a list of ``CADEC_InputFeatures``\n",
        "\n",
        "    Args:\n",
        "        examples: List of ``CADEC_InputExamples`` or ``tf.data.Dataset`` containing the examples.\n",
        "        tokenizer: Instance of a tokenizer that will tokenize the examples\n",
        "        tokenizer_cleantext: Instance of a tokenizer that will tokenize the examples clean text(used for our medical module) \n",
        "        max_length: Maximum example length\n",
        "        task: GLUE task\n",
        "        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n",
        "        output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n",
        "        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n",
        "        pad_token: Padding token\n",
        "        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n",
        "        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n",
        "            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n",
        "            actual values)\n",
        "\n",
        "    Returns:\n",
        "        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n",
        "        containing the task-specific features. If the input is a list of ``CADEC_InputExamples``, will return\n",
        "        a list of task-specific ``CADEC_InputFeatures`` which can be fed to the model.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    is_tf_dataset = False\n",
        "    if is_tf_available() and isinstance(examples, tf.data.Dataset):\n",
        "        is_tf_dataset = True\n",
        "\n",
        "    \"\"\"      Initialisation of Data Processor    \"\"\"\n",
        "    if task is not None:\n",
        "        processor = CADECProcessor()  \n",
        "        if label_list is None:\n",
        "            label_list = processor.get_labels()\n",
        "            logger.info(\"Using label list %s for task %s\" % (label_list, task))\n",
        "        if output_mode is None:\n",
        "            output_mode = \"classification\"\n",
        "            logger.info(\"Using output mode %s for task %s\" % (output_mode, task))\n",
        "\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "    \"\"\"      Processing the examples    \"\"\"\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            logger.info(\"Writing example %d/%d\" % (ex_index, len(examples)))\n",
        "        if is_tf_dataset:\n",
        "            example = processor.get_example_from_tensor_dict(example)\n",
        "            example = processor.tfds_map(example)\n",
        "        \"\"\"      Assuming that each aspect consist of max 4 tokens hence making sure that aspects total tokens coming from aspects are not greater than max sequence length    \"\"\"\n",
        "        aspect_present = bool(example.aspects is not None)\n",
        "        if aspect_present:\n",
        "            if 4 * len(example.aspects) > max_length:\n",
        "                example.aspects = random.sample(example.aspects, k = int(max_length/4))\n",
        "                \n",
        "        \"\"\"      Using tokenizer.encode_plus_lcf the global features are encoded as [<special token> + text_tokens + <special token> + heading_tokens + <special token> + aspect1_token + <special token> + .... + aspectn_token + <special token>] \"\"\"\n",
        "        inputs_global = tokenizer.encode_plus_lcf(example.text, add_special_tokens=True, max_length=max_length,) ######## edittttttt\n",
        "        \"\"\"      Using tokenizer.encode_plus_lcf the local features(medical module) are encoded as [<special token> + text_tokens + <special token>] \"\"\"\n",
        "        inputs_local = tokenizer.encode_plus_lcf(example.text, add_special_tokens=True, max_length=max_length,)\n",
        "        \"\"\" Generating tokens for the clean_text i.e. tokenising text based on glove or BioASQ \"\"\"\n",
        "        text_clean_indices = tokenizer_cleantext.text_to_sequence(example.clean_text)\n",
        "        \n",
        "        \"\"\"      Using tokenizer.encode_plus_lcf the aspect_indices are encoded as [<special token> + aspect1_token + <special token> + .... + aspectn_token + <special token>] \"\"\"\n",
        "        if len(example.aspects) > 2:\n",
        "            aspect_indices = tokenizer.encode_plus_lcf(example.aspects[0], example.aspects[1], example.aspects[2:], add_special_tokens=False, max_length=max_length,)\n",
        "        elif len(example.aspects) == 2:\n",
        "            aspect_indices = tokenizer.encode_plus_lcf(example.aspects[0], example.aspects[1], add_special_tokens=False, max_length=max_length,)\n",
        "        else:\n",
        "            aspect_indices = tokenizer.encode_plus_lcf(example.aspects[0], add_special_tokens=False, max_length=max_length,)\n",
        "        \n",
        "        input_global_ids, token_global_type_ids = inputs_global[\"input_ids\"], inputs_global[\"token_type_ids\"]\n",
        "        input_local_ids, token_local_type_ids = inputs_local[\"input_ids\"], inputs_local[\"token_type_ids\"]\n",
        "        \n",
        "        aspect_indices = aspect_indices[\"input_ids\"]\n",
        "        padding_length_aspect = max_length - len(aspect_indices)\n",
        "        aspect_indices = aspect_indices + ([pad_token] * padding_length_aspect)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        attention_mask_global = [1 if mask_padding_with_zero else 0] * len(input_global_ids)\n",
        "        attention_mask_local = [1 if mask_padding_with_zero else 0] * len(input_local_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding_length_global = max_length - len(input_global_ids)\n",
        "        padding_length_local = max_length - len(input_local_ids)\n",
        "        if pad_on_left:\n",
        "            input_global_ids = ([pad_token] * padding_length_global) + input_global_ids\n",
        "            attention_mask_global = ([0 if mask_padding_with_zero else 1] * padding_length_global) + attention_mask_global\n",
        "            token_global_type_ids = ([pad_token_segment_id] * padding_length_global) + token_global_type_ids\n",
        "            input_local_ids = ([pad_token] * padding_length_local) + input_local_ids\n",
        "            attention_mask_local = ([0 if mask_padding_with_zero else 1] * padding_length_local) + attention_mask_local\n",
        "            token_local_type_ids = ([pad_token_segment_id] * padding_length_local) + token_local_type_ids\n",
        "        else:\n",
        "            input_global_ids = input_global_ids + ([pad_token] * padding_length_global)\n",
        "            attention_mask_global = attention_mask_global + ([0 if mask_padding_with_zero else 1] * padding_length_global)\n",
        "            token_global_type_ids = token_global_type_ids + ([pad_token_segment_id] * padding_length_global)\n",
        "            input_local_ids = input_local_ids + ([pad_token] * padding_length_local)\n",
        "            attention_mask_local = attention_mask_local + ([0 if mask_padding_with_zero else 1] * padding_length_local)\n",
        "            token_local_type_ids = token_local_type_ids + ([pad_token_segment_id] * padding_length_local)\n",
        "\n",
        "        assert len(input_global_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_global_ids), max_length)\n",
        "        assert len(input_local_ids) == max_length, \"Error with input length {} vs {}\".format(len(input_local_ids), max_length)\n",
        "        assert len(attention_mask_global) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(attention_mask_global), max_length\n",
        "        )\n",
        "        assert len(attention_mask_local) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(attention_mask_local), max_length\n",
        "        )\n",
        "        assert len(token_global_type_ids) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(token_global_type_ids), max_length\n",
        "        )\n",
        "        assert len(token_local_type_ids) == max_length, \"Error with input length {} vs {}\".format(\n",
        "            len(token_local_type_ids), max_length\n",
        "        )\n",
        "\n",
        "        if output_mode == \"classification\":\n",
        "            label = example.label\n",
        "        elif output_mode == \"regression\":\n",
        "            label = float(example.label)\n",
        "        else:\n",
        "            raise KeyError(output_mode)\n",
        "\n",
        "        if ex_index < 5:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"input_global_ids: %s\" % \" \".join([str(x) for x in input_global_ids]))\n",
        "            logger.info(\"attention_mask_global: %s\" % \" \".join([str(x) for x in attention_mask_global]))\n",
        "            logger.info(\"token_global_type_ids: %s\" % \" \".join([str(x) for x in token_global_type_ids]))\n",
        "            logger.info(\"input_local_ids: %s\" % \" \".join([str(x) for x in input_local_ids]))\n",
        "            logger.info(\"attention_mask_local: %s\" % \" \".join([str(x) for x in attention_mask_local]))\n",
        "            logger.info(\"token_local_type_ids: %s\" % \" \".join([str(x) for x in token_local_type_ids]))\n",
        "            logger.info(\"text_clean_indices: %s\" % \" \".join([str(x) for x in text_clean_indices]))\n",
        "            logger.info(\"aspect_indices: %s\" % \" \".join([str(x) for x in aspect_indices]))\n",
        "            logger.info(\"label: %s (id = %s)\" % (str(example.label), str(label)))\n",
        "\n",
        "        features.append(\n",
        "            CADEC_InputFeatures(\n",
        "                input_global_ids=input_global_ids, input_local_ids=input_local_ids, attention_mask_global=attention_mask_global, attention_mask_local=attention_mask_local,\n",
        "                token_global_type_ids=token_global_type_ids, token_local_type_ids=token_local_type_ids, text_clean_indices=text_clean_indices, aspect_indices=aspect_indices, label=label\n",
        "            )\n",
        "        )\n",
        "\n",
        "    if is_tf_available() and is_tf_dataset:\n",
        "\n",
        "        def gen():\n",
        "            for ex in features:\n",
        "                yield (\n",
        "                    {\n",
        "                        \"input_global_ids\": ex.input_global_ids,\n",
        "                        \"input_local_ids\": ex.input_local_ids,\n",
        "                        \"attention_mask_global\": ex.attention_mask_global,\n",
        "                        \"attention_mask_local\": ex.attention_mask_local,\n",
        "                        \"token_global_type_ids\": ex.token_global_type_ids,\n",
        "                        \"token_local_type_ids\": ex.token_local_type_ids,\n",
        "                        \"text_clean_indices\": ex.text_clean_indices,\n",
        "                        \"aspect_indices\": ex.aspect_indices,\n",
        "                    },\n",
        "                    ex.label,\n",
        "                )\n",
        "\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            gen,\n",
        "            ({\"input_global_ids\": tf.int32, \"input_local_ids\": tf.int32, \"attention_mask_global\": tf.int32, \"attention_mask_local\": tf.int32, \"token_global_type_ids\": tf.int32, \"token_local_type_ids\": tf.int32, \"text_clean_indices\": tf.int32, \"aspect_indices\": tf.int32}, tf.int64),\n",
        "            (\n",
        "                {\n",
        "                    \"input_global_ids\": tf.TensorShape([None]),\n",
        "                    \"input_local_ids\": tf.TensorShape([None]),\n",
        "                    \"attention_mask_global\": tf.TensorShape([None]),\n",
        "                    \"attention_mask_local\": tf.TensorShape([None]),\n",
        "                    \"token_global_type_ids\": tf.TensorShape([None]),\n",
        "                    \"token_local_type_ids\": tf.TensorShape([None]),\n",
        "                    \"text_clean_indices\": tf.TensorShape([None]),\n",
        "                    \"aspect_indices\": tf.TensorShape([None]),\n",
        "                },\n",
        "                tf.TensorShape([]),\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    return features\n",
        "\n",
        "class CADECProcessor(object):\n",
        "    \"\"\"Processor for the CADEC data set (GLUE version).\"\"\"\n",
        "\n",
        "    def get_example_from_tensor_dict(self, tensor_dict):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return CADEC_InputExample(tensor_dict['idx'].numpy(),\n",
        "                            tensor_dict['heading'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['text'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['clean_text'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['aspects'].numpy().decode('utf-8'),\n",
        "                            tensor_dict['label'].numpy())\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"cadec_train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, \"cadec_dev.tsv\")),\n",
        "            \"dev\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"Uncertainity of Post_Diagnosis\", \"Results and Side-Effects Observed\", \"Medical Assistance\", \"Diet and Maintenance\", \"Information Source\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        for (i, line) in enumerate(lines):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            label = [int(line[3]), int(line[4]), int(line[5]), int(line[6]), int(line[7])]\n",
        "            heading = None\n",
        "            text = line[2]\n",
        "            try:\n",
        "                aspects = [' ' + x for x in line[8].split('|')]\n",
        "                temp_clean_text = \" \".join(line[8].split('|'))\n",
        "            except:\n",
        "                aspects = None\n",
        "                temp_clean_text = \"\"\n",
        "                print(\"Sed\")\n",
        "            \n",
        "            # print(aspects)\n",
        "            \"\"\"    IMPORTANT    IMPORTANT    IMPORTANT    IMPORTANT    IMPORTANT   \"\"\"\n",
        "            clean_text = self.clean_str( text, lemmatizer) ######## for using glove embeddings over sentence\n",
        "            # clean_text = self.clean_str( temp_clean_text, lemmatizer) ##### for using BioASQ embeddings in aspects\n",
        "            examples.append(\n",
        "                CADEC_InputExample(guid=guid, heading=heading, text=text, clean_text=clean_text, aspects=aspects, label=label))\n",
        "        return examples\n",
        "\n",
        "    def tfds_map(self, example):\n",
        "        \"\"\"Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are.\n",
        "        This method converts examples to the correct format.\"\"\"\n",
        "        # if len(self.get_labels()) > 1:\n",
        "        #     example.label = self.get_labels()[int(example.label)]\n",
        "        return example\n",
        "\n",
        "    def clean_str(self, string1, lemmatizer):\n",
        "        \"\"\"\n",
        "        Tokenization/string cleaning for dataset\n",
        "        Every dataset is lower cased except\n",
        "        \"\"\"\n",
        "        str_stop = \"\"\n",
        "        string1 = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '',string1)\n",
        "        string1 = re.sub(r\"\\\\\", \" \", string1)    \n",
        "        string1 = re.sub(r\"\\'\", \" \", string1)    \n",
        "        string1 = re.sub(r\"\\\"\", \" \", string1)   \n",
        "        string1 = re.sub(r'(\\W)\\1+', r'\\1', string1)\n",
        "        word_list=string1.split(\" \")\n",
        "        filtered_words = [word for word in word_list if word not in stopwords.words('english')]\n",
        "        for kj in filtered_words:\n",
        "            new=lemmatizer.lemmatize(str(kj)) \n",
        "            str_stop=str_stop +\" \"+new\n",
        "            str_stop.encode('utf-8')\n",
        "        return str_stop.strip().lower()\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "            return list(csv.reader(f, delimiter=\"\\t\", quotechar=quotechar))\n",
        "\n",
        "class CADEC_InputExample(object):\n",
        "    \"\"\"\n",
        "    A single training/test example for simple sequence classification.\n",
        "\n",
        "    Args:\n",
        "        guid: Unique id for the example.\n",
        "        heading: string. The untokenized heading of the sequence\n",
        "        text: string. The untokenized text part of the sequence.\n",
        "        clean_text: string. The untokenized text part of the sequence used for medical module(as tokenization will be different for glove and BioASQ than BERT).\n",
        "        aspects: list of string. The untokenized aspects for the sequence as a list of strings\n",
        "        Only must be specified for sequence pair tasks.\n",
        "        label: (Optional) list. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, guid, heading, text, clean_text, aspects, label=None):\n",
        "        self.guid = guid\n",
        "        self.heading = heading\n",
        "        self.text = text\n",
        "        self.clean_text = clean_text\n",
        "        self.aspects = aspects\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "class CADEC_InputFeatures(object):\n",
        "    \"\"\"\n",
        "    A single set of features of data.\n",
        "\n",
        "    Args:\n",
        "        input_ids: Indices of input sequence tokens in the vocabulary.\n",
        "        attention_mask: Mask to avoid performing attention on padding token indices.\n",
        "            Mask values selected in ``[0, 1]``:\n",
        "            Usually  ``1`` for tokens that are NOT MASKED, ``0`` for MASKED (padded) tokens.\n",
        "        token_type_ids: Segment token indices to indicate first and second portions of the inputs.\n",
        "        label: Label corresponding to the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_global_ids, input_local_ids, attention_mask_global=None, attention_mask_local=None, token_global_type_ids=None, token_local_type_ids=None, text_clean_indices=None, aspect_indices=None, label=None):\n",
        "        self.input_global_ids = input_global_ids\n",
        "        self.attention_mask_global = attention_mask_global\n",
        "        self.token_global_type_ids = token_global_type_ids\n",
        "        self.input_local_ids = input_local_ids\n",
        "        self.attention_mask_local = attention_mask_local\n",
        "        self.token_local_type_ids = token_local_type_ids\n",
        "        self.text_clean_indices = text_clean_indices\n",
        "        self.aspect_indices = aspect_indices\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "def load_and_cache_examples(args, task, tokenizer, tokenizer_cleantext, evaluate=False):\n",
        "    if args.local_rank not in [-1, 0] and not evaluate:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "    processor = CADECProcessor()  \n",
        "    output_mode = \"classification\"\n",
        "    # Load data features from cache or dataset file\n",
        "    cached_features_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cached_{}_{}_{}_{}\".format(\n",
        "            \"dev\" if evaluate else \"train\",\n",
        "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "            str(args.max_seq_length),\n",
        "            str(task),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    \"\"\" Load saved tokenizer for the clean_text\"\"\"\n",
        "    cached_tokenizer_cleantext_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cachedtokenizer_{}_{}_{}\".format(\n",
        "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "            str(args.embedding_type),\n",
        "            str(task),\n",
        "        ),\n",
        "    )\n",
        "    \"\"\" if overwrite cache is disabled and saved feature and tokenizer file exists then load from the saved file else process them \"\"\"\n",
        "    if os.path.exists(cached_features_file) and os.path.exists(cached_tokenizer_cleantext_file) and not args.overwrite_cache:\n",
        "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        features = torch.load(cached_features_file)\n",
        "        print('loading tokenizer from cache:', cached_tokenizer_cleantext_file)\n",
        "        tokenizer_cleantext = pickle.load(open(cached_tokenizer_cleantext_file, 'rb'))\n",
        "    else:\n",
        "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
        "        label_list = processor.get_labels()\n",
        "        if task in [\"mnli\", \"mnli-mm\"] and args.model_type in [\"roberta\", \"xlmroberta\"]:\n",
        "            # HACK(label indices are swapped in RoBERTa pretrained model)\n",
        "            label_list[1], label_list[2] = label_list[2], label_list[1]\n",
        "        examples = (\n",
        "            processor.get_dev_examples(args.data_dir) if evaluate else processor.get_train_examples(args.data_dir)\n",
        "        )\n",
        "        if (not evaluate):\n",
        "            tokenizer_cleantext.fit_on_examples(examples)\n",
        "            tokenizer_cleantext.update_tokenizer()\n",
        "        \"\"\" features are created using this function which is defined above\"\"\"\n",
        "        features = convert_examples_to_features(\n",
        "            examples,\n",
        "            tokenizer,\n",
        "            tokenizer_cleantext,\n",
        "            label_list=label_list,\n",
        "            max_length=args.max_seq_length,\n",
        "            output_mode=output_mode,\n",
        "            pad_on_left=bool(args.model_type in [\"xlnet\"]),  # pad on the left for xlnet\n",
        "            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
        "            pad_token_segment_id=4 if args.model_type in [\"xlnet\"] else 0,\n",
        "        )\n",
        "        if args.local_rank in [-1, 0]:\n",
        "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "            torch.save(features, cached_features_file)\n",
        "            pickle.dump(tokenizer_cleantext, open(cached_tokenizer_cleantext_file, 'wb'))\n",
        "\n",
        "    if args.local_rank == 0 and not evaluate:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
        "\n",
        "    # Convert to Tensors and build dataset\n",
        "    all_input_global_ids = torch.tensor([f.input_global_ids for f in features], dtype=torch.long)\n",
        "    all_input_local_ids = torch.tensor([f.input_local_ids for f in features], dtype=torch.long)\n",
        "    all_attention_mask_global = torch.tensor([f.attention_mask_global for f in features], dtype=torch.long)\n",
        "    all_attention_mask_local = torch.tensor([f.attention_mask_local for f in features], dtype=torch.long)\n",
        "    all_token_global_type_ids = torch.tensor([f.token_global_type_ids for f in features], dtype=torch.long)\n",
        "    all_token_local_type_ids = torch.tensor([f.token_local_type_ids for f in features], dtype=torch.long)\n",
        "    all_text_clean_indices = torch.tensor([f.text_clean_indices for f in features], dtype=torch.long)\n",
        "    all_aspect_indices = torch.tensor([f.aspect_indices for f in features], dtype=torch.long)\n",
        "    all_labels = torch.tensor([f.label for f in features], dtype=torch.float32)\n",
        "    \n",
        "    dataset = TensorDataset(all_input_global_ids, all_input_local_ids, all_attention_mask_global, all_attention_mask_local, all_token_global_type_ids, all_token_local_type_ids, all_text_clean_indices, all_aspect_indices, all_labels)\n",
        "    \n",
        "    return dataset, tokenizer_cleantext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/transformers/examples/cadec/utils_ichi.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyy-AEpoS8Lx",
        "outputId": "e39b0034-1fe9-4d11-cfda-2b4d423cc094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile /content/transformers/examples/cadec/lcf_ichi.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "import numpy as np\n",
        "from transformers.modeling_bert import BertPooler, BertSelfAttention, BertPreTrainedModel, BertModel\n",
        "from torch.nn import CrossEntropyLoss, MSELoss, BCEWithLogitsLoss\n",
        "\n",
        "def compute_average_with_padding(tensor, padding):\n",
        "    \"\"\"\n",
        "    :param tensor: dimension batch_size, seq_length, hidden_size\n",
        "    :param padding: dimension batch_size, seq_length\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    batch_size, seq_length, emb_size = tensor.shape\n",
        "    entry_sizes = torch.sum(padding, axis=1)\n",
        "    return torch.sum(tensor, axis=1) / entry_sizes\n",
        "\n",
        "\n",
        "class BertMaxPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states, mask):\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        first_token_tensor = compute_average_with_padding(hidden_states, mask)\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, config, args):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.args = args\n",
        "        self.SA = BertSelfAttention(config)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        zero_tensor = torch.tensor(np.zeros((inputs.size(0), 1, 1, self.args.max_seq_length),\n",
        "                                            dtype=np.float32), dtype=torch.float32).to(self.args.device)\n",
        "        SA_out = self.SA(inputs, zero_tensor)\n",
        "        return self.tanh(SA_out[0])\n",
        "\n",
        "\n",
        "class lcf_BERT(BertPreTrainedModel):\n",
        "    def __init__(self, config, args):\n",
        "        super(lcf_BERT, self).__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.args = args\n",
        "        self.config =config\n",
        "        self.bert = BertModel(config)\n",
        "        # self.bert_global_focus = self.bert\n",
        "        # self.bert_local_focus = copy.deepcopy(self.bert_global_focus) if args.use_single_bert else self.bert_global_focus\n",
        "        # self.embedder = nn.Embedding.from_pretrained(torch.from_numpy(args.word2vec).float(), freeze=True, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        # self.lstm = nn.LSTM(args.emb_size, 100, 1, batch_first=True, bidirectional=True)\n",
        "        # Co = 100\n",
        "        # self.conv13 = nn.Conv2d(1, Co, (3, 2*args.emb_size))\n",
        "        # self.conv14 = nn.Conv2d(1, Co, (4, 2*args.emb_size))\n",
        "        # self.conv15 = nn.Conv2d(1, Co, (5, 2*args.emb_size))\n",
        "        # self.dropout_1 = nn.Dropout(0.4)\n",
        "        # self.fc1 = nn.Linear(3*Co, config.num_labels)\n",
        "        # self.fc = nn.Linear(200, config.num_labels)\n",
        "        self.bert_SA = SelfAttention(config, args) ### change\n",
        "        self.linear_double_cdm_or_cdw = nn.Linear(config.hidden_size * 2,config.hidden_size)\n",
        "        self.linear_triple_lcf_global = nn.Linear(config.hidden_size * 3, config.hidden_size)\n",
        "        self.bert_pooler_org = BertPooler(config)\n",
        "        self.bert_pooler = BertMaxPooler(config) ### change\n",
        "        self.dense = nn.Linear(config.hidden_size, config.num_labels)\n",
        "        self.init_weights()\n",
        "\n",
        "    def conv_and_pool(self, x, conv):\n",
        "        x = F.gelu(conv(x)).squeeze(3) # (n, Co, W)\n",
        "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "        return x\n",
        "\n",
        "    def feature_dynamic_mask(self, text_local_indices, aspect_indices):\n",
        "        texts = text_local_indices\n",
        "        # mask_len = self.args.SRD\n",
        "        masked_text_raw_indices = torch.zeros((text_local_indices.size(0), self.args.max_seq_length, self.config.hidden_size),\n",
        "                                          dtype=torch.float)\n",
        "        \n",
        "        masked_text_raw_indices[:, 0, :] = torch.ones((text_local_indices.size(0), self.config.hidden_size), dtype=torch.float) \n",
        "        zero_tensor = torch.tensor(0).to(self.args.device)\n",
        "        for i in range(aspect_indices.shape[0]):\n",
        "            for j in range(aspect_indices[i].shape[0]):\n",
        "                if aspect_indices[i][j] == zero_tensor:\n",
        "                    break\n",
        "                else:\n",
        "                    indices = (text_local_indices[i] == aspect_indices[i][j]).nonzero()\n",
        "                    for k in indices:\n",
        "                        masked_text_raw_indices[i][k] = torch.ones(self.config.hidden_size, dtype=torch.float)\n",
        "        return masked_text_raw_indices.to(self.args.device)\n",
        "\n",
        "    # # create the weights tensor for local context features\n",
        "    # def feature_dynamic_weighted(self, text_local_indices, aspect_indices):\n",
        "    #     texts = text_local_indices\n",
        "    #     asps = aspect_indices\n",
        "    #     # mask_len = self.args.SRD\n",
        "    #     masked_text_raw_indices = torch.zeros((text_local_indices.size(0), self.args.max_seq_length, self.config.hidden_size),\n",
        "    #                                       dtype=torch.float)\n",
        "    #     for text_i, asp_i in zip(range(len(texts)), range(len(asps))):\n",
        "    #         asp_len = np.count_nonzero(asps[asp_i]) - 2\n",
        "    #         try:\n",
        "    #             asp_begin = np.argwhere(texts[text_i] == asps[asp_i][1])[0][0]\n",
        "    #             asp_avg_index = (asp_begin * 2 + asp_len) / 2\n",
        "    #         except:\n",
        "    #             continue\n",
        "    #         distances = np.zeros(np.count_nonzero(texts[text_i]), dtype=np.float32)\n",
        "    #         for i in range(1, np.count_nonzero(texts[text_i])-1):\n",
        "    #             if abs(i - asp_avg_index) + asp_len / 2 > self.args.SRD:\n",
        "    #                 distances[i] = 1 - (abs(i - asp_avg_index)+asp_len/2\n",
        "    #                                     - self.args.SRD)/np.count_nonzero(texts[text_i])\n",
        "    #             else:\n",
        "    #                 distances[i] = 1\n",
        "    #         for i in range(len(distances)):\n",
        "    #             masked_text_raw_indices[text_i][i] = masked_text_raw_indices[text_i][i] * distances[i]\n",
        "    #     # masked_text_raw_indices = torch.from_numpy(masked_text_raw_indices)\n",
        "    #     return masked_text_raw_indices.to(self.args.device)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_global_ids=None,\n",
        "        attention_mask_global=None,\n",
        "        token_global_type_ids=None,\n",
        "        input_local_ids=None,\n",
        "        attention_mask_local=None,\n",
        "        token_local_type_ids=None,\n",
        "        text_clean_indices=None,\n",
        "        aspect_indices=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "\n",
        "        # word_vectors = self.embedder(text_clean_indices)\n",
        "        # self.lstm.flatten_parameters()\n",
        "        # out, _ = self.lstm(word_vectors)\n",
        "        # # out = out.unsqueeze(1)   #### for using CNN\n",
        "        # # print(out.size())\n",
        "        # # print(out)\n",
        "        # logits = self.fc(out[:, -1, :])\n",
        "        # # print(logits.size())\n",
        "        # # print(logits)\n",
        "        # # raise ValueError\n",
        "        # # logits = self.fc(torch.div(word_vectors.sum(axis=1), word_vectors.shape[1]))\n",
        "\n",
        "        # global_outputs, _ = self.bert(\n",
        "        #     input_global_ids,\n",
        "        #     attention_mask=attention_mask_global,\n",
        "        #     token_type_ids=token_global_type_ids,\n",
        "        #     position_ids=position_ids,\n",
        "        #     head_mask=head_mask,\n",
        "        #     inputs_embeds=inputs_embeds,\n",
        "        # )\n",
        "\n",
        "        local_outputs, _ = self.bert(\n",
        "            input_local_ids,\n",
        "            attention_mask=attention_mask_local,\n",
        "            token_type_ids=token_local_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        # out_cat = torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "        # out_cat = self.linear_double_cdm_or_cdw(out_cat)\n",
        "        \n",
        "        # if self.args.local_context_focus == 'cdm':\n",
        "        #     masked_local_text_vec = self.feature_dynamic_mask(input_local_ids, aspect_indices)\n",
        "        #     local_outputs = torch.mul(local_outputs, masked_local_text_vec)\n",
        "        #     # out_cat = torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "        #     # out_cat = self.linear_double_cdm_or_cdw(out_cat)\n",
        "\n",
        "        # elif self.args.local_context_focus == 'cdw':\n",
        "        #     weighted_text_local_features = self.feature_dynamic_weighted(input_local_ids, aspect_indices)\n",
        "        #     local_outputs = torch.mul(local_outputs, weighted_text_local_features)\n",
        "        #     out_cat = torch.cat((local_outputs, global_outputs), dim=-1)\n",
        "        #     out_cat = self.linear_double_cdm_or_cdw(out_cat)\n",
        "\n",
        "        # elif self.args.local_context_focus == 'lcf_fusion':\n",
        "        #     masked_local_text_vec = self.feature_dynamic_mask(text_local_indices, aspect_indices)\n",
        "        #     masked_local_out = torch.mul(local_outputs, masked_local_text_vec)\n",
        "        #     weighted_text_local_features = self.feature_dynamic_weighted(text_local_indices, aspect_indices)\n",
        "        #     weighted_local_out = torch.mul(local_outputs, weighted_text_local_features)\n",
        "        #     out_cat = torch.cat((masked_local_out, global_outputs, weighted_local_out), dim=-1)\n",
        "        #     out_cat = self.linear_triple_lcf_global(out_cat)\n",
        "\n",
        "        # self_attention_out = self.bert_SA(local_outputs)\n",
        "        self_attention_out = self.dropout(local_outputs)\n",
        "        local_pooled_out = self.bert_pooler_org(self_attention_out)\n",
        "        # self_attention_out = self.dropout(global_outputs)\n",
        "        # global_pooled_out = self.bert_pooler_org(self_attention_out)\n",
        "        # pooled_out = torch.cat((local_pooled_out, global_pooled_out), dim=-1)\n",
        "        logits = self.dense(local_pooled_out)\n",
        "        outputs = (logits,)\n",
        "\n",
        "        if labels is not None:\n",
        "            if self.num_labels == 1:\n",
        "                #  We are doing regression\n",
        "                loss_fct = MSELoss()\n",
        "                loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "            else:\n",
        "                loss_fct = BCEWithLogitsLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
        "            outputs = (loss,) + outputs\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/transformers/examples/cadec/lcf_ichi.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWhlcZgHS8a9",
        "outputId": "c56fa8ec-6d16-4051-cddd-06b4f66b3319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile /content/transformers/examples/cadec/run_ichi.py\n",
        "import argparse\n",
        "import glob\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AlbertConfig,\n",
        "    AlbertForSequenceClassification,\n",
        "    AlbertTokenizer,\n",
        "    BertConfig,\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    DistilBertConfig,\n",
        "    DistilBertForSequenceClassification,\n",
        "    DistilBertTokenizer,\n",
        "    RobertaConfig,\n",
        "    RobertaForSequenceClassification,\n",
        "    RobertaTokenizer,\n",
        "    XLMConfig,\n",
        "    XLMForSequenceClassification,\n",
        "    XLMRobertaConfig,\n",
        "    XLMRobertaForSequenceClassification,\n",
        "    XLMRobertaTokenizer,\n",
        "    XLMTokenizer,\n",
        "    XLNetConfig,\n",
        "    XLNetForSequenceClassification,\n",
        "    XLNetTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "from lcf_ichi import lcf_BERT#, lcf_XLNET, lcf_XLM, lcf_Roberta, lcf_DistilBert, lcf_Albert, lcf_XLMRoberta\n",
        "from utils_ichi import convert_examples_to_features, CADECProcessor, compute_metrics, load_and_cache_examples, Tokenizer, pad_and_truncate, build_embedding_matrix_glove, build_embedding_matrix_BioASQ\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "ALL_MODELS = sum(\n",
        "    (\n",
        "        tuple(conf.pretrained_config_archive_map.keys())\n",
        "        for conf in (\n",
        "            BertConfig,\n",
        "            XLNetConfig,\n",
        "            XLMConfig,\n",
        "            RobertaConfig,\n",
        "            DistilBertConfig,\n",
        "            AlbertConfig,\n",
        "            XLMRobertaConfig,\n",
        "        )\n",
        "    ),\n",
        "    (),\n",
        ")\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    \"bert\": (BertConfig, BertForSequenceClassification, BertTokenizer, lcf_BERT),\n",
        "}\n",
        "#     \"xlnet\": (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer, lcf_XLNET),\n",
        "#     \"xlm\": (XLMConfig, XLMForSequenceClassification, XLMTokenizer, lcf_XLM),\n",
        "#     \"roberta\": (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer, lcf_Roberta),\n",
        "#     \"distilbert\": (DistilBertConfig, DistilBertForSequenceClassification, DistilBertTokenizer, lcf_DistilBert),\n",
        "#     \"albert\": (AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer, lcf_Albert),\n",
        "#     \"xlmroberta\": (XLMRobertaConfig, XLMRobertaForSequenceClassification, XLMRobertaTokenizer, lcf_XLMRoberta),\n",
        "# }\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "\n",
        "def train(args, train_dataset, model, tokenizer, tokenizer_cleantext):\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer = SummaryWriter()\n",
        "\n",
        "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
        "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args.train_batch_size)\n",
        "\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "\n",
        "    # Check if saved optimizer or scheduler states exist\n",
        "    if os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\")) and os.path.isfile(\n",
        "        os.path.join(args.model_name_or_path, \"scheduler.pt\")\n",
        "    ):\n",
        "        # Load in optimizer and scheduler states\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
        "\n",
        "    if args.fp16:\n",
        "        try:\n",
        "            from apex import amp\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
        "\n",
        "    # multi-gpu training (should be after apex fp16 initialization)\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Distributed training (should be after apex fp16 initialization)\n",
        "    if args.local_rank != -1:\n",
        "        model = torch.nn.parallel.DistributedDataParallel(\n",
        "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True,\n",
        "        )\n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
        "    logger.info(\n",
        "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "        args.train_batch_size\n",
        "        * args.gradient_accumulation_steps\n",
        "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
        "    )\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    epochs_trained = 0\n",
        "    steps_trained_in_current_epoch = 0\n",
        "    # Check if continuing training from a checkpoint\n",
        "    if os.path.exists(args.model_name_or_path):\n",
        "        # set global_step to gobal_step of last saved checkpoint from model path\n",
        "        global_step = int(args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0])\n",
        "        epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "        steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "\n",
        "        logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "        logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
        "        logger.info(\"  Continuing training from global step %d\", global_step)\n",
        "        logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
        "\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    model.zero_grad()\n",
        "    train_iterator = trange(\n",
        "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0],\n",
        "    )\n",
        "    set_seed(args)  # Added here for reproductibility\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "\n",
        "            # Skip past any already trained steps if resuming training\n",
        "            if steps_trained_in_current_epoch > 0:\n",
        "                steps_trained_in_current_epoch -= 1\n",
        "                continue\n",
        "\n",
        "            model.train()\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "            inputs = {\"input_global_ids\": batch[0], \"attention_mask_global\": batch[2], \"input_local_ids\": batch[1], \"attention_mask_local\": batch[3], \"text_clean_indices\": batch[6], \"aspect_indices\": batch[7], \"labels\": batch[8]}\n",
        "            if args.model_type != \"distilbert\":\n",
        "                inputs[\"token_global_type_ids\"] = (\n",
        "                    batch[4] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                )\n",
        "                inputs[\"token_local_type_ids\"] = (\n",
        "                    batch[5] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                )\n",
        "            # inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[3]}\n",
        "            # if args.model_type != \"distilbert\":\n",
        "            #     inputs[\"token_type_ids\"] = (\n",
        "            #         batch[2] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "            #     )  # XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            if args.fp16:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                if args.fp16:\n",
        "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "\n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    logs = {}\n",
        "                    if (\n",
        "                        args.local_rank == -1 and args.evaluate_during_training\n",
        "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(args, model, tokenizer, tokenizer_cleantext)\n",
        "                        for key, value in results.items():\n",
        "                            eval_key = \"eval_{}\".format(key)\n",
        "                            logs[eval_key] = value\n",
        "\n",
        "                    loss_scalar = (tr_loss - logging_loss) / args.logging_steps\n",
        "                    learning_rate_scalar = scheduler.get_lr()[0]\n",
        "                    logs[\"learning_rate\"] = learning_rate_scalar\n",
        "                    logs[\"loss\"] = loss_scalar\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                    for key, value in logs.items():\n",
        "                        tb_writer.add_scalar(key, value, global_step)\n",
        "                    print(json.dumps({**logs, **{\"step\": global_step}}))\n",
        "\n",
        "                # if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                #     # Save model checkpoint\n",
        "                #     output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n",
        "                #     if not os.path.exists(output_dir):\n",
        "                #         os.makedirs(output_dir)\n",
        "                #     # model_to_save = (\n",
        "                #     #     model.module if hasattr(model, \"module\") else model\n",
        "                #     # )  # Take care of distributed/parallel training\n",
        "                #     # model_to_save.save_pretrained(output_dir)\n",
        "                #     torch.save(model.state_dict(), args.output_dir)\n",
        "                #     tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "                #     torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                #     logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "                #     torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "                #     torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "                #     logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                epoch_iterator.close()\n",
        "                break\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step\n",
        "\n",
        "\n",
        "def evaluate(args, model, tokenizer, tokenizer_cleantext, prefix=\"\"):\n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    eval_task_names = (\"cadec\",)\n",
        "    eval_outputs_dirs = (args.output_dir,)\n",
        "\n",
        "    results = {}\n",
        "    for eval_task, eval_output_dir in zip(eval_task_names, eval_outputs_dirs):\n",
        "        eval_dataset, tokenizer_cleantext = load_and_cache_examples(args, eval_task, tokenizer, tokenizer_cleantext, evaluate=True)\n",
        "\n",
        "        if not os.path.exists(eval_output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(eval_output_dir)\n",
        "\n",
        "        args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "        # Note that DistributedSampler samples randomly\n",
        "        eval_sampler = SequentialSampler(eval_dataset)\n",
        "        eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size)\n",
        "\n",
        "        # multi-gpu eval\n",
        "        if args.n_gpu > 1:\n",
        "            model = torch.nn.DataParallel(model)\n",
        "\n",
        "        # Eval!\n",
        "        logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "        logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "        logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "        eval_loss = 0.0\n",
        "        nb_eval_steps = 0\n",
        "        preds = None\n",
        "        preds_original = None\n",
        "        out_label_ids = None\n",
        "        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "            model.eval()\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                inputs = {\"input_global_ids\": batch[0], \"attention_mask_global\": batch[2], \"input_local_ids\": batch[1], \"attention_mask_local\": batch[3], \"text_clean_indices\": batch[6], \"aspect_indices\": batch[7], \"labels\": batch[8]}\n",
        "                if args.model_type != \"distilbert\":\n",
        "                    inputs[\"token_global_type_ids\"] = (\n",
        "                        batch[4] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                    )\n",
        "                    inputs[\"token_local_type_ids\"] = (\n",
        "                        batch[5] if args.model_type in [\"bert\", \"xlnet\", \"albert\"] else None\n",
        "                    )  # XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids\n",
        "                outputs = model(**inputs)\n",
        "                tmp_eval_loss, logits = outputs[:2]\n",
        "\n",
        "                eval_loss += tmp_eval_loss.mean().item()\n",
        "            nb_eval_steps += 1\n",
        "            if preds is None:\n",
        "                preds = logits.detach().cpu().numpy()\n",
        "                preds_original = logits.detach().cpu().numpy()\n",
        "                out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
        "            else:\n",
        "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "                preds_original = np.append(preds_original, logits.detach().cpu().numpy(), axis=0)\n",
        "                out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "        eval_loss = eval_loss / nb_eval_steps\n",
        "        preds = (preds > 0)\n",
        "\n",
        "        result = compute_metrics(preds, out_label_ids) ######################update kar !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "        results.update(result)\n",
        "\n",
        "        output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
        "        with open(output_eval_file, \"w\") as writer:\n",
        "            logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "            for key in sorted(result.keys()):\n",
        "                logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "                writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "            # for a in preds:\n",
        "            #     writer.write(str(a)+'\\n')\n",
        "            writer.write('[')\n",
        "            for a in preds_original:\n",
        "                writer.write('[')\n",
        "                for c in range(len(a)):\n",
        "                    b = a[c]\n",
        "                    if c!=6:\n",
        "                        writer.write(str(b)+',')\n",
        "                    else:\n",
        "                        writer.write(str(b))\n",
        "                writer.write(']')\n",
        "                writer.write('\\n')\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Required parameters\n",
        "    parser.add_argument(\n",
        "        \"--data_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_type\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Model type selected in the list: \" + \", \".join(MODEL_CLASSES.keys()),\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model_name_or_path\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"Path to pre-trained model or shortcut name selected in the list: \" + \", \".join(ALL_MODELS),\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--output_dir\",\n",
        "        default=None,\n",
        "        type=str,\n",
        "        required=True,\n",
        "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
        "    )\n",
        "\n",
        "    # Other parameters\n",
        "    parser.add_argument(\n",
        "        \"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--tokenizer_name\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--cache_dir\",\n",
        "        default=\"\",\n",
        "        type=str,\n",
        "        help=\"Where do you want to store the pre-trained models downloaded from s3\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_seq_length\",\n",
        "        default=128,\n",
        "        type=int,\n",
        "        help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "        \"than this will be truncated, sequences shorter will be padded.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--embedding_dim_word2vec\",\n",
        "        default=300,\n",
        "        type=int,\n",
        "        help=\"embedding dimension for the word vectors in the medical module\",\n",
        "    )\n",
        "    parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
        "    parser.add_argument(\"--do_eval\", action=\"store_true\", help=\"Whether to run eval on the dev set.\")\n",
        "    parser.add_argument(\n",
        "        \"--evaluate_during_training\", action=\"store_true\", help=\"Rul evaluation during training at each logging step.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--do_lower_case\", action=\"store_true\", help=\"Set this flag if you are using an uncased model.\",\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--per_gpu_train_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for training.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--per_gpu_eval_batch_size\", default=8, type=int, help=\"Batch size per GPU/CPU for evaluation.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--gradient_accumulation_steps\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
        "    )\n",
        "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
        "    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
        "    parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
        "    parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
        "    parser.add_argument(\n",
        "        \"--num_train_epochs\", default=3.0, type=float, help=\"Total number of training epochs to perform.\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--max_steps\",\n",
        "        default=-1,\n",
        "        type=int,\n",
        "        help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
        "    )\n",
        "    parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
        "\n",
        "    parser.add_argument(\"--logging_steps\", type=int, default=50, help=\"Log every X updates steps.\")\n",
        "    parser.add_argument(\"--save_steps\", type=int, default=10000, help=\"Save checkpoint every X updates steps.\")\n",
        "    parser.add_argument(\n",
        "        \"--eval_all_checkpoints\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
        "    )\n",
        "    parser.add_argument(\"--no_cuda\", action=\"store_true\", help=\"Avoid using CUDA when available\")\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_output_dir\", action=\"store_true\", help=\"Overwrite the content of the output directory\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--overwrite_cache\", action=\"store_true\", help=\"Overwrite the cached training and evaluation sets\",\n",
        "    )\n",
        "    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"--fp16\",\n",
        "        action=\"store_true\",\n",
        "        help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--fp16_opt_level\",\n",
        "        type=str,\n",
        "        default=\"O1\",\n",
        "        help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
        "        \"See details at https://nvidia.github.io/apex/amp.html\",\n",
        "    )\n",
        "    parser.add_argument(\"--local_rank\", type=int, default=-1, help=\"For distributed training: local_rank\")\n",
        "    parser.add_argument(\"--server_ip\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    parser.add_argument(\"--server_port\", type=str, default=\"\", help=\"For distant debugging.\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if (\n",
        "        os.path.exists(args.output_dir)\n",
        "        and os.listdir(args.output_dir)\n",
        "        and args.do_train\n",
        "        and not args.overwrite_output_dir\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
        "                args.output_dir\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Setup distant debugging if needed\n",
        "    if args.server_ip and args.server_port:\n",
        "        # Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script\n",
        "        import ptvsd\n",
        "\n",
        "        print(\"Waiting for debugger attach\")\n",
        "        ptvsd.enable_attach(address=(args.server_ip, args.server_port), redirect_output=True)\n",
        "        ptvsd.wait_for_attach()\n",
        "\n",
        "    # Setup CUDA, GPU & distributed training\n",
        "    if args.local_rank == -1 or args.no_cuda:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
        "        args.n_gpu = torch.cuda.device_count()\n",
        "    else:  # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "        torch.cuda.set_device(args.local_rank)\n",
        "        device = torch.device(\"cuda\", args.local_rank)\n",
        "        torch.distributed.init_process_group(backend=\"nccl\")\n",
        "        args.n_gpu = 1\n",
        "    args.device = device\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
        "    )\n",
        "    logger.warning(\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        args.local_rank,\n",
        "        device,\n",
        "        args.n_gpu,\n",
        "        bool(args.local_rank != -1),\n",
        "        args.fp16,\n",
        "    )\n",
        "\n",
        "    # Set seed\n",
        "    set_seed(args)\n",
        "\n",
        "    # Prepare GLUE task\n",
        "    args.task_name = 'cadec'\n",
        "    processor = CADECProcessor()\n",
        "    args.output_mode = \"classification\"\n",
        "    label_list = processor.get_labels()\n",
        "    num_labels = len(label_list)\n",
        "\n",
        "    # Load pretrained model and tokenizer\n",
        "    if args.local_rank not in [-1, 0]:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
        "\n",
        "    args.model_type = args.model_type.lower()\n",
        "    config_class, model_class, tokenizer_class, lcf_model = MODEL_CLASSES[args.model_type]\n",
        "    config = config_class.from_pretrained(\n",
        "        args.config_name if args.config_name else args.model_name_or_path,\n",
        "        num_labels=num_labels,\n",
        "        finetuning_task=args.task_name,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    tokenizer = tokenizer_class.from_pretrained(\n",
        "        args.tokenizer_name if args.tokenizer_name else args.model_name_or_path,\n",
        "        do_lower_case=args.do_lower_case,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    tokenizer_cleantext = Tokenizer(max_seq_len = 1600, max_num_words=20000,lower=True)\n",
        "    # model = model_class.from_pretrained(\n",
        "    #     args.model_name_or_path,\n",
        "    #     from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "    #     config=config,\n",
        "    #     cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    #     force_download=True,\n",
        "    # )\n",
        "\n",
        "    args.use_single_bert = False\n",
        "    args.local_context_focus = 'cdm'\n",
        "    args.embedding_type = 'glove'\n",
        "\n",
        "    cached_embeddingmatrix_file = os.path.join(\n",
        "        args.data_dir,\n",
        "        \"cachedword2vec_{}_{}\".format(\n",
        "            str(args.task_name),\n",
        "            str(\"glove\"),\n",
        "        ),\n",
        "    )\n",
        "    cached_embeddingmatrix_path = \".\"\n",
        "    \n",
        "    train_dataset, tokenizer_cleantext = load_and_cache_examples(args, args.task_name, tokenizer, tokenizer_cleantext, evaluate=False)\n",
        "    # embedding_matrix = build_embedding_matrix_glove(tokenizer_cleantext.word2idx, args.embedding_dim_word2vec, cached_embeddingmatrix_file, cached_embeddingmatrix_path)\n",
        "    # print(embedding_matrix.shape)\n",
        "    # print(tokenizer_cleantext.word2idx)\n",
        "    \n",
        "    # args.word2vec = embedding_matrix\n",
        "    # args.emb_size = embedding_matrix.shape[1]\n",
        "    model = lcf_model.from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "        config=config,\n",
        "        args=args,\n",
        "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    )\n",
        "    # model = lcf_Roberta.from_pretrained(\n",
        "    #     \"/home/bt1/17CS10037/new_transformers/transformers/roberta-large-pytorch_model.bin\",\n",
        "    #     from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "    #     config=config,\n",
        "    #     args=args,\n",
        "    #     cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "    #     force_download=True,\n",
        "    # )\n",
        "\n",
        "    if args.local_rank == 0:\n",
        "        torch.distributed.barrier()  # Make sure only the first process in distributed training will download model & vocab\n",
        "\n",
        "    model.to(args.device)\n",
        "\n",
        "    logger.info(\"Training/evaluation parameters %s\", args)\n",
        "    \n",
        "    # Training\n",
        "    if args.do_train:\n",
        "        # train_dataset, tokenizer_cleantext = load_and_cache_examples(args, args.task_name, tokenizer, tokenizer_cleantext, evaluate=False)\n",
        "        # matrix = build_embedding_matrix_glove(tokenizer_cleantext.word2idx, args.embedding_dim_word2vec, cached_glove_embeddingmatrix_file, cached_glove_embeddingmatrix_path)\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer, tokenizer_cleantext)\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "    result = evaluate(args, model, tokenizer, tokenizer_cleantext)\n",
        "    # Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "    if args.do_train and (args.local_rank == -1 or torch.distributed.get_rank() == 0):\n",
        "        # Create output directory if needed\n",
        "        if not os.path.exists(args.output_dir) and args.local_rank in [-1, 0]:\n",
        "            os.makedirs(args.output_dir)\n",
        "\n",
        "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        # model_to_save = (\n",
        "        #     model.module if hasattr(model, \"module\") else model\n",
        "        # )  # Take care of distributed/parallel training\n",
        "        # model_to_save.save_pretrained(args.output_dir)\n",
        "        model_name = \"{}.pt\".format(args.model_type)\n",
        "        torch.save(model.state_dict(), os.path.join(args.output_dir,model_name))\n",
        "        tokenizer.save_pretrained(args.output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
        "\n",
        "        # Load a trained model and vocabulary that you have fine-tuned\n",
        "        # model = model_class.from_pretrained(args.output_dir)\n",
        "        model = lcf_model(config, args)\n",
        "        model.load_state_dict(torch.load(os.path.join(args.output_dir,model_name)))\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.output_dir)\n",
        "        model.to(args.device)\n",
        "\n",
        "    # Evaluation\n",
        "    results = {}\n",
        "    if args.do_eval and args.local_rank in [-1, 0]:\n",
        "        tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
        "        cached_tokenizer_cleantext_file = os.path.join(\n",
        "            args.data_dir,\n",
        "            \"cachedtokenizer_{}_{}_{}\".format(\n",
        "                list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
        "                str(args.embedding_type),\n",
        "                str(args.task_name),\n",
        "            ),\n",
        "        )\n",
        "        if os.path.exists(cached_tokenizer_cleantext_file):\n",
        "            print('loading tokenizer from cache:', cached_tokenizer_cleantext_file)\n",
        "            tokenizer_cleantext = pickle.load(open(cached_tokenizer_cleantext_file, 'rb'))\n",
        "        checkpoints = [args.output_dir]\n",
        "        if args.eval_all_checkpoints:\n",
        "            checkpoints = list(\n",
        "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
        "            )\n",
        "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
        "            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
        "\n",
        "            # model = model_class.from_pretrained(checkpoint)\n",
        "            # model = lcf_model.from_pretrained(\n",
        "            #     args.model_name_or_path,\n",
        "            #     from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "            #     config=config,\n",
        "            #     args=args,\n",
        "            #     cache_dir=args.cache_dir if args.cache_dir else None,\n",
        "            # )\n",
        "\n",
        "            model = lcf_model(config, args)\n",
        "            model_name = \"{}.pt\".format(args.model_type)\n",
        "            model.load_state_dict(torch.load(os.path.join(args.output_dir,model_name)))\n",
        "            model.to(args.device)\n",
        "            result = evaluate(args, model, tokenizer, tokenizer_cleantext, prefix=prefix)\n",
        "            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
        "            results.update(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing /content/transformers/examples/cadec/run_ichi.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmpFdc6sbALY",
        "outputId": "df89ce8a-3b27-48ff-f653-9afd715151c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python ./examples/cadec/run_ichi.py --model_type bert --model_name_or_path bert-base-uncased --do_lower_case --do_train --do_eval --data_dir ./data/ichi --max_seq_length 256 --per_gpu_eval_batch_size=16 --per_gpu_train_batch_size=16 --learning_rate 5e-5 --num_train_epochs 10 --output_dir ./tmp/cadec_bert_base_new --overwrite_output_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-16 12:03:28.426570: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "10/16/2020 12:03:30 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "10/16/2020 12:03:30 - INFO - filelock -   Lock 139635833904992 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "10/16/2020 12:03:30 - INFO - filelock -   Lock 139635833904992 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "10/16/2020 12:03:30 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "10/16/2020 12:03:30 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"cadec\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 5,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "10/16/2020 12:03:31 - INFO - filelock -   Lock 139636314923472 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "10/16/2020 12:03:31 - INFO - filelock -   Lock 139636314923472 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "10/16/2020 12:03:31 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "10/16/2020 12:03:31 - INFO - utils_ichi -   Loading features from cached file ./data/ichi/cached_train_bert-base-uncased_256_cadec\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_cadec\n",
            "10/16/2020 12:03:32 - INFO - filelock -   Lock 139635695538752 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "10/16/2020 12:03:32 - INFO - filelock -   Lock 139635695538752 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "10/16/2020 12:03:32 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "10/16/2020 12:03:36 - INFO - transformers.modeling_utils -   Weights of lcf_BERT not initialized from pretrained model: ['bert_SA.SA.query.weight', 'bert_SA.SA.query.bias', 'bert_SA.SA.key.weight', 'bert_SA.SA.key.bias', 'bert_SA.SA.value.weight', 'bert_SA.SA.value.bias', 'linear_double_cdm_or_cdw.weight', 'linear_double_cdm_or_cdw.bias', 'linear_triple_lcf_global.weight', 'linear_triple_lcf_global.bias', 'bert_pooler_org.dense.weight', 'bert_pooler_org.dense.bias', 'bert_pooler.dense.weight', 'bert_pooler.dense.bias', 'dense.weight', 'dense.bias']\n",
            "10/16/2020 12:03:36 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in lcf_BERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "10/16/2020 12:03:40 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='./data/ichi', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, embedding_dim_word2vec=300, embedding_type='glove', eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_context_focus='cdm', local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=256, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='./tmp/cadec_bert_base_new', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=16, save_steps=10000, seed=42, server_ip='', server_port='', task_name='cadec', tokenizer_name='', use_single_bert=False, warmup_steps=0, weight_decay=0.0)\n",
            "10/16/2020 12:03:40 - INFO - __main__ -   ***** Running training *****\n",
            "10/16/2020 12:03:40 - INFO - __main__ -     Num examples = 942\n",
            "10/16/2020 12:03:40 - INFO - __main__ -     Num Epochs = 10\n",
            "10/16/2020 12:03:40 - INFO - __main__ -     Instantaneous batch size per GPU = 16\n",
            "10/16/2020 12:03:40 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "10/16/2020 12:03:40 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "10/16/2020 12:03:40 - INFO - __main__ -     Total optimization steps = 590\n",
            "Epoch:   0% 0/10 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/59 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   2% 1/59 [00:00<00:27,  2.12it/s]\u001b[A\n",
            "Iteration:   3% 2/59 [00:00<00:26,  2.16it/s]\u001b[A\n",
            "Iteration:   5% 3/59 [00:01<00:25,  2.19it/s]\u001b[A\n",
            "Iteration:   7% 4/59 [00:01<00:24,  2.21it/s]\u001b[A\n",
            "Iteration:   8% 5/59 [00:02<00:24,  2.23it/s]\u001b[A\n",
            "Iteration:  10% 6/59 [00:02<00:23,  2.24it/s]\u001b[A\n",
            "Iteration:  12% 7/59 [00:03<00:23,  2.25it/s]\u001b[A\n",
            "Iteration:  14% 8/59 [00:03<00:22,  2.26it/s]\u001b[A\n",
            "Iteration:  15% 9/59 [00:04<00:22,  2.26it/s]\u001b[A\n",
            "Iteration:  17% 10/59 [00:04<00:21,  2.26it/s]\u001b[A\n",
            "Iteration:  19% 11/59 [00:04<00:21,  2.26it/s]\u001b[A\n",
            "Iteration:  20% 12/59 [00:05<00:20,  2.27it/s]\u001b[A\n",
            "Iteration:  22% 13/59 [00:05<00:20,  2.27it/s]\u001b[A\n",
            "Iteration:  24% 14/59 [00:06<00:19,  2.27it/s]\u001b[A\n",
            "Iteration:  25% 15/59 [00:06<00:19,  2.26it/s]\u001b[A\n",
            "Iteration:  27% 16/59 [00:07<00:18,  2.26it/s]\u001b[A\n",
            "Iteration:  29% 17/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  31% 18/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  32% 19/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  34% 20/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  36% 21/59 [00:09<00:16,  2.27it/s]\u001b[A\n",
            "Iteration:  37% 22/59 [00:09<00:16,  2.27it/s]\u001b[A\n",
            "Iteration:  39% 23/59 [00:10<00:15,  2.28it/s]\u001b[A\n",
            "Iteration:  41% 24/59 [00:10<00:15,  2.28it/s]\u001b[A\n",
            "Iteration:  42% 25/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  44% 26/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  46% 27/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  47% 28/59 [00:12<00:13,  2.27it/s]\u001b[A\n",
            "Iteration:  49% 29/59 [00:12<00:13,  2.27it/s]\u001b[A\n",
            "Iteration:  51% 30/59 [00:13<00:12,  2.27it/s]\u001b[A\n",
            "Iteration:  53% 31/59 [00:13<00:12,  2.27it/s]\u001b[A\n",
            "Iteration:  54% 32/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  56% 33/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  58% 34/59 [00:15<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  59% 35/59 [00:15<00:10,  2.27it/s]\u001b[A\n",
            "Iteration:  61% 36/59 [00:15<00:10,  2.27it/s]\u001b[A\n",
            "Iteration:  63% 37/59 [00:16<00:09,  2.27it/s]\u001b[A\n",
            "Iteration:  64% 38/59 [00:16<00:09,  2.27it/s]\u001b[A\n",
            "Iteration:  66% 39/59 [00:17<00:08,  2.27it/s]\u001b[A\n",
            "Iteration:  68% 40/59 [00:17<00:08,  2.27it/s]\u001b[A\n",
            "Iteration:  69% 41/59 [00:18<00:07,  2.26it/s]\u001b[A\n",
            "Iteration:  71% 42/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  73% 43/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  75% 44/59 [00:19<00:06,  2.27it/s]\u001b[A\n",
            "Iteration:  76% 45/59 [00:19<00:06,  2.27it/s]\u001b[A\n",
            "Iteration:  78% 46/59 [00:20<00:05,  2.27it/s]\u001b[A\n",
            "Iteration:  80% 47/59 [00:20<00:05,  2.27it/s]\u001b[A\n",
            "Iteration:  81% 48/59 [00:21<00:04,  2.27it/s]\u001b[A\n",
            "Iteration:  83% 49/59 [00:21<00:04,  2.27it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"learning_rate\": 4.5762711864406784e-05, \"loss\": 0.3454242813587189, \"step\": 50}\n",
            "\n",
            "Iteration:  85% 50/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  86% 51/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  88% 52/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  90% 53/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  92% 54/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  93% 55/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  95% 56/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  97% 57/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration:  98% 58/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration: 100% 59/59 [00:25<00:00,  2.27it/s]\n",
            "Epoch:  10% 1/10 [00:25<03:53, 25.98s/it]\n",
            "Iteration:   0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/59 [00:00<00:25,  2.28it/s]\u001b[A\n",
            "Iteration:   3% 2/59 [00:00<00:25,  2.28it/s]\u001b[A\n",
            "Iteration:   5% 3/59 [00:01<00:24,  2.28it/s]\u001b[A\n",
            "Iteration:   7% 4/59 [00:01<00:24,  2.28it/s]\u001b[A\n",
            "Iteration:   8% 5/59 [00:02<00:23,  2.27it/s]\u001b[A\n",
            "Iteration:  10% 6/59 [00:02<00:23,  2.27it/s]\u001b[A\n",
            "Iteration:  12% 7/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  14% 8/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  15% 9/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  17% 10/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  19% 11/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  20% 12/59 [00:05<00:20,  2.28it/s]\u001b[A\n",
            "Iteration:  22% 13/59 [00:05<00:20,  2.28it/s]\u001b[A\n",
            "Iteration:  24% 14/59 [00:06<00:19,  2.28it/s]\u001b[A\n",
            "Iteration:  25% 15/59 [00:06<00:19,  2.27it/s]\u001b[A\n",
            "Iteration:  27% 16/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  29% 17/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  31% 18/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  32% 19/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  34% 20/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  36% 21/59 [00:09<00:16,  2.27it/s]\u001b[A\n",
            "Iteration:  37% 22/59 [00:09<00:16,  2.28it/s]\u001b[A\n",
            "Iteration:  39% 23/59 [00:10<00:15,  2.28it/s]\u001b[A\n",
            "Iteration:  41% 24/59 [00:10<00:15,  2.27it/s]\u001b[A\n",
            "Iteration:  42% 25/59 [00:10<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  44% 26/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  46% 27/59 [00:11<00:14,  2.28it/s]\u001b[A\n",
            "Iteration:  47% 28/59 [00:12<00:13,  2.27it/s]\u001b[A\n",
            "Iteration:  49% 29/59 [00:12<00:13,  2.26it/s]\u001b[A\n",
            "Iteration:  51% 30/59 [00:13<00:12,  2.26it/s]\u001b[A\n",
            "Iteration:  53% 31/59 [00:13<00:12,  2.27it/s]\u001b[A\n",
            "Iteration:  54% 32/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  56% 33/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  58% 34/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  59% 35/59 [00:15<00:10,  2.26it/s]\u001b[A\n",
            "Iteration:  61% 36/59 [00:15<00:10,  2.27it/s]\u001b[A\n",
            "Iteration:  63% 37/59 [00:16<00:09,  2.27it/s]\u001b[A\n",
            "Iteration:  64% 38/59 [00:16<00:09,  2.27it/s]\u001b[A\n",
            "Iteration:  66% 39/59 [00:17<00:08,  2.27it/s]\u001b[A\n",
            "Iteration:  68% 40/59 [00:17<00:08,  2.27it/s]\u001b[A{\"learning_rate\": 4.152542372881356e-05, \"loss\": 0.2730940353870392, \"step\": 100}\n",
            "\n",
            "Iteration:  69% 41/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  71% 42/59 [00:18<00:07,  2.26it/s]\u001b[A\n",
            "Iteration:  73% 43/59 [00:18<00:07,  2.26it/s]\u001b[A\n",
            "Iteration:  75% 44/59 [00:19<00:06,  2.26it/s]\u001b[A\n",
            "Iteration:  76% 45/59 [00:19<00:06,  2.25it/s]\u001b[A\n",
            "Iteration:  78% 46/59 [00:20<00:05,  2.25it/s]\u001b[A\n",
            "Iteration:  80% 47/59 [00:20<00:05,  2.26it/s]\u001b[A\n",
            "Iteration:  81% 48/59 [00:21<00:04,  2.26it/s]\u001b[A\n",
            "Iteration:  83% 49/59 [00:21<00:04,  2.26it/s]\u001b[A\n",
            "Iteration:  85% 50/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  86% 51/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  88% 52/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  90% 53/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  92% 54/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  93% 55/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  95% 56/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  97% 57/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration:  98% 58/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration: 100% 59/59 [00:25<00:00,  2.27it/s]\n",
            "Epoch:  20% 2/10 [00:51<03:27, 25.97s/it]\n",
            "Iteration:   0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/59 [00:00<00:25,  2.26it/s]\u001b[A\n",
            "Iteration:   3% 2/59 [00:00<00:25,  2.25it/s]\u001b[A\n",
            "Iteration:   5% 3/59 [00:01<00:24,  2.26it/s]\u001b[A\n",
            "Iteration:   7% 4/59 [00:01<00:24,  2.26it/s]\u001b[A\n",
            "Iteration:   8% 5/59 [00:02<00:23,  2.27it/s]\u001b[A\n",
            "Iteration:  10% 6/59 [00:02<00:23,  2.27it/s]\u001b[A\n",
            "Iteration:  12% 7/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  14% 8/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  15% 9/59 [00:03<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  17% 10/59 [00:04<00:21,  2.28it/s]\u001b[A\n",
            "Iteration:  19% 11/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  20% 12/59 [00:05<00:20,  2.26it/s]\u001b[A\n",
            "Iteration:  22% 13/59 [00:05<00:20,  2.26it/s]\u001b[A\n",
            "Iteration:  24% 14/59 [00:06<00:19,  2.26it/s]\u001b[A\n",
            "Iteration:  25% 15/59 [00:06<00:19,  2.27it/s]\u001b[A\n",
            "Iteration:  27% 16/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  29% 17/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  31% 18/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  32% 19/59 [00:08<00:17,  2.26it/s]\u001b[A\n",
            "Iteration:  34% 20/59 [00:08<00:17,  2.25it/s]\u001b[A\n",
            "Iteration:  36% 21/59 [00:09<00:16,  2.26it/s]\u001b[A\n",
            "Iteration:  37% 22/59 [00:09<00:16,  2.26it/s]\u001b[A\n",
            "Iteration:  39% 23/59 [00:10<00:15,  2.26it/s]\u001b[A\n",
            "Iteration:  41% 24/59 [00:10<00:15,  2.27it/s]\u001b[A\n",
            "Iteration:  42% 25/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  44% 26/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  46% 27/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  47% 28/59 [00:12<00:13,  2.27it/s]\u001b[A\n",
            "Iteration:  49% 29/59 [00:12<00:13,  2.27it/s]\u001b[A\n",
            "Iteration:  51% 30/59 [00:13<00:12,  2.27it/s]\u001b[A\n",
            "Iteration:  53% 31/59 [00:13<00:12,  2.26it/s]\u001b[A{\"learning_rate\": 3.728813559322034e-05, \"loss\": 0.22042002648115158, \"step\": 150}\n",
            "\n",
            "Iteration:  54% 32/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  56% 33/59 [00:14<00:11,  2.26it/s]\u001b[A\n",
            "Iteration:  58% 34/59 [00:15<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  59% 35/59 [00:15<00:10,  2.27it/s]\u001b[A\n",
            "Iteration:  61% 36/59 [00:15<00:10,  2.27it/s]\u001b[A\n",
            "Iteration:  63% 37/59 [00:16<00:09,  2.27it/s]\u001b[A\n",
            "Iteration:  64% 38/59 [00:16<00:09,  2.26it/s]\u001b[A\n",
            "Iteration:  66% 39/59 [00:17<00:08,  2.26it/s]\u001b[A\n",
            "Iteration:  68% 40/59 [00:17<00:08,  2.26it/s]\u001b[A\n",
            "Iteration:  69% 41/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  71% 42/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  73% 43/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  75% 44/59 [00:19<00:06,  2.27it/s]\u001b[A\n",
            "Iteration:  76% 45/59 [00:19<00:06,  2.26it/s]\u001b[A\n",
            "Iteration:  78% 46/59 [00:20<00:05,  2.26it/s]\u001b[A\n",
            "Iteration:  80% 47/59 [00:20<00:05,  2.27it/s]\u001b[A\n",
            "Iteration:  81% 48/59 [00:21<00:04,  2.27it/s]\u001b[A\n",
            "Iteration:  83% 49/59 [00:21<00:04,  2.27it/s]\u001b[A\n",
            "Iteration:  85% 50/59 [00:22<00:03,  2.26it/s]\u001b[A\n",
            "Iteration:  86% 51/59 [00:22<00:03,  2.26it/s]\u001b[A\n",
            "Iteration:  88% 52/59 [00:22<00:03,  2.26it/s]\u001b[A\n",
            "Iteration:  90% 53/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  92% 54/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  93% 55/59 [00:24<00:01,  2.26it/s]\u001b[A\n",
            "Iteration:  95% 56/59 [00:24<00:01,  2.26it/s]\u001b[A\n",
            "Iteration:  97% 57/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration:  98% 58/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration: 100% 59/59 [00:26<00:00,  2.27it/s]\n",
            "Epoch:  30% 3/10 [01:17<03:01, 25.98s/it]\n",
            "Iteration:   0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/59 [00:00<00:25,  2.26it/s]\u001b[A\n",
            "Iteration:   3% 2/59 [00:00<00:25,  2.26it/s]\u001b[A\n",
            "Iteration:   5% 3/59 [00:01<00:24,  2.27it/s]\u001b[A\n",
            "Iteration:   7% 4/59 [00:01<00:24,  2.27it/s]\u001b[A\n",
            "Iteration:   8% 5/59 [00:02<00:23,  2.26it/s]\u001b[A\n",
            "Iteration:  10% 6/59 [00:02<00:23,  2.26it/s]\u001b[A\n",
            "Iteration:  12% 7/59 [00:03<00:22,  2.26it/s]\u001b[A\n",
            "Iteration:  14% 8/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  15% 9/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  17% 10/59 [00:04<00:21,  2.26it/s]\u001b[A\n",
            "Iteration:  19% 11/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  20% 12/59 [00:05<00:20,  2.27it/s]\u001b[A\n",
            "Iteration:  22% 13/59 [00:05<00:20,  2.27it/s]\u001b[A\n",
            "Iteration:  24% 14/59 [00:06<00:19,  2.27it/s]\u001b[A\n",
            "Iteration:  25% 15/59 [00:06<00:19,  2.27it/s]\u001b[A\n",
            "Iteration:  27% 16/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  29% 17/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  31% 18/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  32% 19/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  34% 20/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  36% 21/59 [00:09<00:16,  2.27it/s]\u001b[A\n",
            "Iteration:  37% 22/59 [00:09<00:16,  2.27it/s]\u001b[A{\"learning_rate\": 3.305084745762712e-05, \"loss\": 0.1719462253153324, \"step\": 200}\n",
            "\n",
            "Iteration:  39% 23/59 [00:10<00:15,  2.27it/s]\u001b[A\n",
            "Iteration:  41% 24/59 [00:10<00:15,  2.26it/s]\u001b[A\n",
            "Iteration:  42% 25/59 [00:11<00:15,  2.26it/s]\u001b[A\n",
            "Iteration:  44% 26/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  46% 27/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  47% 28/59 [00:12<00:13,  2.27it/s]\u001b[A\n",
            "Iteration:  49% 29/59 [00:12<00:13,  2.26it/s]\u001b[A\n",
            "Iteration:  51% 30/59 [00:13<00:12,  2.27it/s]\u001b[A\n",
            "Iteration:  53% 31/59 [00:13<00:12,  2.27it/s]\u001b[A\n",
            "Iteration:  54% 32/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  56% 33/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  58% 34/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  59% 35/59 [00:15<00:10,  2.26it/s]\u001b[A\n",
            "Iteration:  61% 36/59 [00:15<00:10,  2.26it/s]\u001b[A\n",
            "Iteration:  63% 37/59 [00:16<00:09,  2.26it/s]\u001b[A\n",
            "Iteration:  64% 38/59 [00:16<00:09,  2.26it/s]\u001b[A\n",
            "Iteration:  66% 39/59 [00:17<00:08,  2.27it/s]\u001b[A\n",
            "Iteration:  68% 40/59 [00:17<00:08,  2.27it/s]\u001b[A\n",
            "Iteration:  69% 41/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  71% 42/59 [00:18<00:07,  2.26it/s]\u001b[A\n",
            "Iteration:  73% 43/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  75% 44/59 [00:19<00:06,  2.27it/s]\u001b[A\n",
            "Iteration:  76% 45/59 [00:19<00:06,  2.26it/s]\u001b[A\n",
            "Iteration:  78% 46/59 [00:20<00:05,  2.26it/s]\u001b[A\n",
            "Iteration:  80% 47/59 [00:20<00:05,  2.25it/s]\u001b[A\n",
            "Iteration:  81% 48/59 [00:21<00:04,  2.26it/s]\u001b[A\n",
            "Iteration:  83% 49/59 [00:21<00:04,  2.26it/s]\u001b[A\n",
            "Iteration:  85% 50/59 [00:22<00:03,  2.26it/s]\u001b[A\n",
            "Iteration:  86% 51/59 [00:22<00:03,  2.26it/s]\u001b[A\n",
            "Iteration:  88% 52/59 [00:22<00:03,  2.26it/s]\u001b[A\n",
            "Iteration:  90% 53/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  92% 54/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  93% 55/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  95% 56/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  97% 57/59 [00:25<00:00,  2.26it/s]\u001b[A\n",
            "Iteration:  98% 58/59 [00:25<00:00,  2.26it/s]\u001b[A\n",
            "Iteration: 100% 59/59 [00:26<00:00,  2.27it/s]\n",
            "Epoch:  40% 4/10 [01:43<02:35, 25.99s/it]\n",
            "Iteration:   0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/59 [00:00<00:25,  2.24it/s]\u001b[A\n",
            "Iteration:   3% 2/59 [00:00<00:25,  2.25it/s]\u001b[A\n",
            "Iteration:   5% 3/59 [00:01<00:24,  2.26it/s]\u001b[A\n",
            "Iteration:   7% 4/59 [00:01<00:24,  2.25it/s]\u001b[A\n",
            "Iteration:   8% 5/59 [00:02<00:23,  2.26it/s]\u001b[A\n",
            "Iteration:  10% 6/59 [00:02<00:23,  2.26it/s]\u001b[A\n",
            "Iteration:  12% 7/59 [00:03<00:22,  2.26it/s]\u001b[A\n",
            "Iteration:  14% 8/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  15% 9/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  17% 10/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  19% 11/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  20% 12/59 [00:05<00:20,  2.28it/s]\u001b[A\n",
            "Iteration:  22% 13/59 [00:05<00:20,  2.28it/s]\u001b[A{\"learning_rate\": 2.88135593220339e-05, \"loss\": 0.1423068918287754, \"step\": 250}\n",
            "\n",
            "Iteration:  24% 14/59 [00:06<00:19,  2.27it/s]\u001b[A\n",
            "Iteration:  25% 15/59 [00:06<00:19,  2.27it/s]\u001b[A\n",
            "Iteration:  27% 16/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  29% 17/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  31% 18/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  32% 19/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  34% 20/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  36% 21/59 [00:09<00:16,  2.26it/s]\u001b[A\n",
            "Iteration:  37% 22/59 [00:09<00:16,  2.27it/s]\u001b[A\n",
            "Iteration:  39% 23/59 [00:10<00:15,  2.27it/s]\u001b[A\n",
            "Iteration:  41% 24/59 [00:10<00:15,  2.27it/s]\u001b[A\n",
            "Iteration:  42% 25/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  44% 26/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  46% 27/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  47% 28/59 [00:12<00:13,  2.27it/s]\u001b[A\n",
            "Iteration:  49% 29/59 [00:12<00:13,  2.27it/s]\u001b[A\n",
            "Iteration:  51% 30/59 [00:13<00:12,  2.27it/s]\u001b[A\n",
            "Iteration:  53% 31/59 [00:13<00:12,  2.27it/s]\u001b[A\n",
            "Iteration:  54% 32/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  56% 33/59 [00:14<00:11,  2.26it/s]\u001b[A\n",
            "Iteration:  58% 34/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  59% 35/59 [00:15<00:10,  2.27it/s]\u001b[A\n",
            "Iteration:  61% 36/59 [00:15<00:10,  2.27it/s]\u001b[A\n",
            "Iteration:  63% 37/59 [00:16<00:09,  2.27it/s]\u001b[A\n",
            "Iteration:  64% 38/59 [00:16<00:09,  2.25it/s]\u001b[A\n",
            "Iteration:  66% 39/59 [00:17<00:08,  2.26it/s]\u001b[A\n",
            "Iteration:  68% 40/59 [00:17<00:08,  2.26it/s]\u001b[A\n",
            "Iteration:  69% 41/59 [00:18<00:07,  2.26it/s]\u001b[A\n",
            "Iteration:  71% 42/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  73% 43/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  75% 44/59 [00:19<00:06,  2.26it/s]\u001b[A\n",
            "Iteration:  76% 45/59 [00:19<00:06,  2.25it/s]\u001b[A\n",
            "Iteration:  78% 46/59 [00:20<00:05,  2.26it/s]\u001b[A\n",
            "Iteration:  80% 47/59 [00:20<00:05,  2.26it/s]\u001b[A\n",
            "Iteration:  81% 48/59 [00:21<00:04,  2.26it/s]\u001b[A\n",
            "Iteration:  83% 49/59 [00:21<00:04,  2.27it/s]\u001b[A\n",
            "Iteration:  85% 50/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  86% 51/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  88% 52/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  90% 53/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  92% 54/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  93% 55/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  95% 56/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  97% 57/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration:  98% 58/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration: 100% 59/59 [00:25<00:00,  2.27it/s]\n",
            "Epoch:  50% 5/10 [02:09<02:09, 25.98s/it]\n",
            "Iteration:   0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/59 [00:00<00:25,  2.27it/s]\u001b[A\n",
            "Iteration:   3% 2/59 [00:00<00:25,  2.26it/s]\u001b[A\n",
            "Iteration:   5% 3/59 [00:01<00:24,  2.27it/s]\u001b[A\n",
            "Iteration:   7% 4/59 [00:01<00:24,  2.27it/s]\u001b[A{\"learning_rate\": 2.457627118644068e-05, \"loss\": 0.09245281681418419, \"step\": 300}\n",
            "\n",
            "Iteration:   8% 5/59 [00:02<00:23,  2.27it/s]\u001b[A\n",
            "Iteration:  10% 6/59 [00:02<00:23,  2.27it/s]\u001b[A\n",
            "Iteration:  12% 7/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  14% 8/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  15% 9/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  17% 10/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  19% 11/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  20% 12/59 [00:05<00:20,  2.26it/s]\u001b[A\n",
            "Iteration:  22% 13/59 [00:05<00:20,  2.26it/s]\u001b[A\n",
            "Iteration:  24% 14/59 [00:06<00:19,  2.27it/s]\u001b[A\n",
            "Iteration:  25% 15/59 [00:06<00:19,  2.27it/s]\u001b[A\n",
            "Iteration:  27% 16/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  29% 17/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  31% 18/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  32% 19/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  34% 20/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  36% 21/59 [00:09<00:16,  2.27it/s]\u001b[A\n",
            "Iteration:  37% 22/59 [00:09<00:16,  2.26it/s]\u001b[A\n",
            "Iteration:  39% 23/59 [00:10<00:15,  2.27it/s]\u001b[A\n",
            "Iteration:  41% 24/59 [00:10<00:15,  2.26it/s]\u001b[A\n",
            "Iteration:  42% 25/59 [00:11<00:15,  2.27it/s]\u001b[A\n",
            "Iteration:  44% 26/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  46% 27/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  47% 28/59 [00:12<00:13,  2.27it/s]\u001b[A\n",
            "Iteration:  49% 29/59 [00:12<00:13,  2.27it/s]\u001b[A\n",
            "Iteration:  51% 30/59 [00:13<00:12,  2.27it/s]\u001b[A\n",
            "Iteration:  53% 31/59 [00:13<00:12,  2.27it/s]\u001b[A\n",
            "Iteration:  54% 32/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  56% 33/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  58% 34/59 [00:14<00:11,  2.26it/s]\u001b[A\n",
            "Iteration:  59% 35/59 [00:15<00:10,  2.26it/s]\u001b[A\n",
            "Iteration:  61% 36/59 [00:15<00:10,  2.26it/s]\u001b[A\n",
            "Iteration:  63% 37/59 [00:16<00:09,  2.27it/s]\u001b[A\n",
            "Iteration:  64% 38/59 [00:16<00:09,  2.27it/s]\u001b[A\n",
            "Iteration:  66% 39/59 [00:17<00:08,  2.27it/s]\u001b[A\n",
            "Iteration:  68% 40/59 [00:17<00:08,  2.26it/s]\u001b[A\n",
            "Iteration:  69% 41/59 [00:18<00:07,  2.26it/s]\u001b[A\n",
            "Iteration:  71% 42/59 [00:18<00:07,  2.26it/s]\u001b[A\n",
            "Iteration:  73% 43/59 [00:18<00:07,  2.26it/s]\u001b[A\n",
            "Iteration:  75% 44/59 [00:19<00:06,  2.27it/s]\u001b[A\n",
            "Iteration:  76% 45/59 [00:19<00:06,  2.27it/s]\u001b[A\n",
            "Iteration:  78% 46/59 [00:20<00:05,  2.27it/s]\u001b[A\n",
            "Iteration:  80% 47/59 [00:20<00:05,  2.27it/s]\u001b[A\n",
            "Iteration:  81% 48/59 [00:21<00:04,  2.27it/s]\u001b[A\n",
            "Iteration:  83% 49/59 [00:21<00:04,  2.26it/s]\u001b[A\n",
            "Iteration:  85% 50/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  86% 51/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  88% 52/59 [00:22<00:03,  2.26it/s]\u001b[A\n",
            "Iteration:  90% 53/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  92% 54/59 [00:23<00:02,  2.27it/s]\u001b[A{\"learning_rate\": 2.033898305084746e-05, \"loss\": 0.06284790270030499, \"step\": 350}\n",
            "\n",
            "Iteration:  93% 55/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  95% 56/59 [00:24<00:01,  2.26it/s]\u001b[A\n",
            "Iteration:  97% 57/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration:  98% 58/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration: 100% 59/59 [00:25<00:00,  2.27it/s]\n",
            "Epoch:  60% 6/10 [02:35<01:43, 25.98s/it]\n",
            "Iteration:   0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/59 [00:00<00:25,  2.28it/s]\u001b[A\n",
            "Iteration:   3% 2/59 [00:00<00:25,  2.27it/s]\u001b[A\n",
            "Iteration:   5% 3/59 [00:01<00:24,  2.26it/s]\u001b[A\n",
            "Iteration:   7% 4/59 [00:01<00:24,  2.26it/s]\u001b[A\n",
            "Iteration:   8% 5/59 [00:02<00:23,  2.27it/s]\u001b[A\n",
            "Iteration:  10% 6/59 [00:02<00:23,  2.27it/s]\u001b[A\n",
            "Iteration:  12% 7/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  14% 8/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  15% 9/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  17% 10/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  19% 11/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  20% 12/59 [00:05<00:20,  2.27it/s]\u001b[A\n",
            "Iteration:  22% 13/59 [00:05<00:20,  2.27it/s]\u001b[A\n",
            "Iteration:  24% 14/59 [00:06<00:19,  2.27it/s]\u001b[A\n",
            "Iteration:  25% 15/59 [00:06<00:19,  2.27it/s]\u001b[A\n",
            "Iteration:  27% 16/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  29% 17/59 [00:07<00:18,  2.28it/s]\u001b[A\n",
            "Iteration:  31% 18/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  32% 19/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  34% 20/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  36% 21/59 [00:09<00:16,  2.27it/s]\u001b[A\n",
            "Iteration:  37% 22/59 [00:09<00:16,  2.27it/s]\u001b[A\n",
            "Iteration:  39% 23/59 [00:10<00:15,  2.28it/s]\u001b[A\n",
            "Iteration:  41% 24/59 [00:10<00:15,  2.27it/s]\u001b[A\n",
            "Iteration:  42% 25/59 [00:11<00:14,  2.28it/s]\u001b[A\n",
            "Iteration:  44% 26/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  46% 27/59 [00:11<00:14,  2.26it/s]\u001b[A\n",
            "Iteration:  47% 28/59 [00:12<00:13,  2.26it/s]\u001b[A\n",
            "Iteration:  49% 29/59 [00:12<00:13,  2.27it/s]\u001b[A\n",
            "Iteration:  51% 30/59 [00:13<00:12,  2.27it/s]\u001b[A\n",
            "Iteration:  53% 31/59 [00:13<00:12,  2.28it/s]\u001b[A\n",
            "Iteration:  54% 32/59 [00:14<00:11,  2.28it/s]\u001b[A\n",
            "Iteration:  56% 33/59 [00:14<00:11,  2.28it/s]\u001b[A\n",
            "Iteration:  58% 34/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  59% 35/59 [00:15<00:10,  2.27it/s]\u001b[A\n",
            "Iteration:  61% 36/59 [00:15<00:10,  2.28it/s]\u001b[A\n",
            "Iteration:  63% 37/59 [00:16<00:09,  2.28it/s]\u001b[A\n",
            "Iteration:  64% 38/59 [00:16<00:09,  2.28it/s]\u001b[A\n",
            "Iteration:  66% 39/59 [00:17<00:08,  2.28it/s]\u001b[A\n",
            "Iteration:  68% 40/59 [00:17<00:08,  2.27it/s]\u001b[A\n",
            "Iteration:  69% 41/59 [00:18<00:07,  2.26it/s]\u001b[A\n",
            "Iteration:  71% 42/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  73% 43/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  75% 44/59 [00:19<00:06,  2.27it/s]\u001b[A\n",
            "Iteration:  76% 45/59 [00:19<00:06,  2.27it/s]\u001b[A{\"learning_rate\": 1.6101694915254237e-05, \"loss\": 0.04902080625295639, \"step\": 400}\n",
            "\n",
            "Iteration:  78% 46/59 [00:20<00:05,  2.27it/s]\u001b[A\n",
            "Iteration:  80% 47/59 [00:20<00:05,  2.27it/s]\u001b[A\n",
            "Iteration:  81% 48/59 [00:21<00:04,  2.26it/s]\u001b[A\n",
            "Iteration:  83% 49/59 [00:21<00:04,  2.27it/s]\u001b[A\n",
            "Iteration:  85% 50/59 [00:22<00:03,  2.26it/s]\u001b[A\n",
            "Iteration:  86% 51/59 [00:22<00:03,  2.26it/s]\u001b[A\n",
            "Iteration:  88% 52/59 [00:22<00:03,  2.25it/s]\u001b[A\n",
            "Iteration:  90% 53/59 [00:23<00:02,  2.26it/s]\u001b[A\n",
            "Iteration:  92% 54/59 [00:23<00:02,  2.26it/s]\u001b[A\n",
            "Iteration:  93% 55/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  95% 56/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  97% 57/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration:  98% 58/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration: 100% 59/59 [00:25<00:00,  2.27it/s]\n",
            "Epoch:  70% 7/10 [03:01<01:17, 25.98s/it]\n",
            "Iteration:   0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/59 [00:00<00:25,  2.27it/s]\u001b[A\n",
            "Iteration:   3% 2/59 [00:00<00:25,  2.27it/s]\u001b[A\n",
            "Iteration:   5% 3/59 [00:01<00:24,  2.27it/s]\u001b[A\n",
            "Iteration:   7% 4/59 [00:01<00:24,  2.27it/s]\u001b[A\n",
            "Iteration:   8% 5/59 [00:02<00:23,  2.28it/s]\u001b[A\n",
            "Iteration:  10% 6/59 [00:02<00:23,  2.27it/s]\u001b[A\n",
            "Iteration:  12% 7/59 [00:03<00:22,  2.28it/s]\u001b[A\n",
            "Iteration:  14% 8/59 [00:03<00:22,  2.28it/s]\u001b[A\n",
            "Iteration:  15% 9/59 [00:03<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  17% 10/59 [00:04<00:21,  2.28it/s]\u001b[A\n",
            "Iteration:  19% 11/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  20% 12/59 [00:05<00:20,  2.28it/s]\u001b[A\n",
            "Iteration:  22% 13/59 [00:05<00:20,  2.28it/s]\u001b[A\n",
            "Iteration:  24% 14/59 [00:06<00:19,  2.28it/s]\u001b[A\n",
            "Iteration:  25% 15/59 [00:06<00:19,  2.28it/s]\u001b[A\n",
            "Iteration:  27% 16/59 [00:07<00:18,  2.26it/s]\u001b[A\n",
            "Iteration:  29% 17/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  31% 18/59 [00:07<00:18,  2.27it/s]\u001b[A\n",
            "Iteration:  32% 19/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  34% 20/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  36% 21/59 [00:09<00:16,  2.27it/s]\u001b[A\n",
            "Iteration:  37% 22/59 [00:09<00:16,  2.27it/s]\u001b[A\n",
            "Iteration:  39% 23/59 [00:10<00:15,  2.28it/s]\u001b[A\n",
            "Iteration:  41% 24/59 [00:10<00:15,  2.28it/s]\u001b[A\n",
            "Iteration:  42% 25/59 [00:10<00:14,  2.28it/s]\u001b[A\n",
            "Iteration:  44% 26/59 [00:11<00:14,  2.28it/s]\u001b[A\n",
            "Iteration:  46% 27/59 [00:11<00:14,  2.28it/s]\u001b[A\n",
            "Iteration:  47% 28/59 [00:12<00:13,  2.28it/s]\u001b[A\n",
            "Iteration:  49% 29/59 [00:12<00:13,  2.28it/s]\u001b[A\n",
            "Iteration:  51% 30/59 [00:13<00:12,  2.28it/s]\u001b[A\n",
            "Iteration:  53% 31/59 [00:13<00:12,  2.28it/s]\u001b[A\n",
            "Iteration:  54% 32/59 [00:14<00:11,  2.28it/s]\u001b[A\n",
            "Iteration:  56% 33/59 [00:14<00:11,  2.28it/s]\u001b[A\n",
            "Iteration:  58% 34/59 [00:14<00:10,  2.28it/s]\u001b[A\n",
            "Iteration:  59% 35/59 [00:15<00:10,  2.28it/s]\u001b[A\n",
            "Iteration:  61% 36/59 [00:15<00:10,  2.26it/s]\u001b[A{\"learning_rate\": 1.1864406779661018e-05, \"loss\": 0.03606283405795693, \"step\": 450}\n",
            "\n",
            "Iteration:  63% 37/59 [00:16<00:09,  2.27it/s]\u001b[A\n",
            "Iteration:  64% 38/59 [00:16<00:09,  2.27it/s]\u001b[A\n",
            "Iteration:  66% 39/59 [00:17<00:08,  2.28it/s]\u001b[A\n",
            "Iteration:  68% 40/59 [00:17<00:08,  2.28it/s]\u001b[A\n",
            "Iteration:  69% 41/59 [00:18<00:07,  2.28it/s]\u001b[A\n",
            "Iteration:  71% 42/59 [00:18<00:07,  2.28it/s]\u001b[A\n",
            "Iteration:  73% 43/59 [00:18<00:07,  2.28it/s]\u001b[A\n",
            "Iteration:  75% 44/59 [00:19<00:06,  2.27it/s]\u001b[A\n",
            "Iteration:  76% 45/59 [00:19<00:06,  2.27it/s]\u001b[A\n",
            "Iteration:  78% 46/59 [00:20<00:05,  2.28it/s]\u001b[A\n",
            "Iteration:  80% 47/59 [00:20<00:05,  2.27it/s]\u001b[A\n",
            "Iteration:  81% 48/59 [00:21<00:04,  2.27it/s]\u001b[A\n",
            "Iteration:  83% 49/59 [00:21<00:04,  2.27it/s]\u001b[A\n",
            "Iteration:  85% 50/59 [00:21<00:03,  2.28it/s]\u001b[A\n",
            "Iteration:  86% 51/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  88% 52/59 [00:22<00:03,  2.26it/s]\u001b[A\n",
            "Iteration:  90% 53/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  92% 54/59 [00:23<00:02,  2.26it/s]\u001b[A\n",
            "Iteration:  93% 55/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  95% 56/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  97% 57/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration:  98% 58/59 [00:25<00:00,  2.26it/s]\u001b[A\n",
            "Iteration: 100% 59/59 [00:25<00:00,  2.28it/s]\n",
            "Epoch:  80% 8/10 [03:27<00:51, 25.96s/it]\n",
            "Iteration:   0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/59 [00:00<00:25,  2.28it/s]\u001b[A\n",
            "Iteration:   3% 2/59 [00:00<00:25,  2.27it/s]\u001b[A\n",
            "Iteration:   5% 3/59 [00:01<00:24,  2.27it/s]\u001b[A\n",
            "Iteration:   7% 4/59 [00:01<00:24,  2.28it/s]\u001b[A\n",
            "Iteration:   8% 5/59 [00:02<00:23,  2.28it/s]\u001b[A\n",
            "Iteration:  10% 6/59 [00:02<00:23,  2.28it/s]\u001b[A\n",
            "Iteration:  12% 7/59 [00:03<00:22,  2.28it/s]\u001b[A\n",
            "Iteration:  14% 8/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  15% 9/59 [00:03<00:22,  2.26it/s]\u001b[A\n",
            "Iteration:  17% 10/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  19% 11/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  20% 12/59 [00:05<00:20,  2.27it/s]\u001b[A\n",
            "Iteration:  22% 13/59 [00:05<00:20,  2.28it/s]\u001b[A\n",
            "Iteration:  24% 14/59 [00:06<00:19,  2.28it/s]\u001b[A\n",
            "Iteration:  25% 15/59 [00:06<00:19,  2.28it/s]\u001b[A\n",
            "Iteration:  27% 16/59 [00:07<00:18,  2.28it/s]\u001b[A\n",
            "Iteration:  29% 17/59 [00:07<00:18,  2.28it/s]\u001b[A\n",
            "Iteration:  31% 18/59 [00:07<00:18,  2.28it/s]\u001b[A\n",
            "Iteration:  32% 19/59 [00:08<00:17,  2.28it/s]\u001b[A\n",
            "Iteration:  34% 20/59 [00:08<00:17,  2.27it/s]\u001b[A\n",
            "Iteration:  36% 21/59 [00:09<00:16,  2.28it/s]\u001b[A\n",
            "Iteration:  37% 22/59 [00:09<00:16,  2.27it/s]\u001b[A\n",
            "Iteration:  39% 23/59 [00:10<00:15,  2.27it/s]\u001b[A\n",
            "Iteration:  41% 24/59 [00:10<00:15,  2.27it/s]\u001b[A\n",
            "Iteration:  42% 25/59 [00:10<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  44% 26/59 [00:11<00:14,  2.28it/s]\u001b[A\n",
            "Iteration:  46% 27/59 [00:11<00:14,  2.28it/s]\u001b[A{\"learning_rate\": 7.627118644067798e-06, \"loss\": 0.025052083898335697, \"step\": 500}\n",
            "\n",
            "Iteration:  47% 28/59 [00:12<00:13,  2.28it/s]\u001b[A\n",
            "Iteration:  49% 29/59 [00:12<00:13,  2.27it/s]\u001b[A\n",
            "Iteration:  51% 30/59 [00:13<00:12,  2.28it/s]\u001b[A\n",
            "Iteration:  53% 31/59 [00:13<00:12,  2.27it/s]\u001b[A\n",
            "Iteration:  54% 32/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  56% 33/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  58% 34/59 [00:14<00:11,  2.27it/s]\u001b[A\n",
            "Iteration:  59% 35/59 [00:15<00:10,  2.27it/s]\u001b[A\n",
            "Iteration:  61% 36/59 [00:15<00:10,  2.27it/s]\u001b[A\n",
            "Iteration:  63% 37/59 [00:16<00:09,  2.27it/s]\u001b[A\n",
            "Iteration:  64% 38/59 [00:16<00:09,  2.27it/s]\u001b[A\n",
            "Iteration:  66% 39/59 [00:17<00:08,  2.28it/s]\u001b[A\n",
            "Iteration:  68% 40/59 [00:17<00:08,  2.28it/s]\u001b[A\n",
            "Iteration:  69% 41/59 [00:18<00:07,  2.28it/s]\u001b[A\n",
            "Iteration:  71% 42/59 [00:18<00:07,  2.28it/s]\u001b[A\n",
            "Iteration:  73% 43/59 [00:18<00:07,  2.28it/s]\u001b[A\n",
            "Iteration:  75% 44/59 [00:19<00:06,  2.28it/s]\u001b[A\n",
            "Iteration:  76% 45/59 [00:19<00:06,  2.28it/s]\u001b[A\n",
            "Iteration:  78% 46/59 [00:20<00:05,  2.26it/s]\u001b[A\n",
            "Iteration:  80% 47/59 [00:20<00:05,  2.27it/s]\u001b[A\n",
            "Iteration:  81% 48/59 [00:21<00:04,  2.27it/s]\u001b[A\n",
            "Iteration:  83% 49/59 [00:21<00:04,  2.27it/s]\u001b[A\n",
            "Iteration:  85% 50/59 [00:21<00:03,  2.28it/s]\u001b[A\n",
            "Iteration:  86% 51/59 [00:22<00:03,  2.28it/s]\u001b[A\n",
            "Iteration:  88% 52/59 [00:22<00:03,  2.28it/s]\u001b[A\n",
            "Iteration:  90% 53/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  92% 54/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  93% 55/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  95% 56/59 [00:24<00:01,  2.27it/s]\u001b[A\n",
            "Iteration:  97% 57/59 [00:25<00:00,  2.28it/s]\u001b[A\n",
            "Iteration:  98% 58/59 [00:25<00:00,  2.28it/s]\u001b[A\n",
            "Iteration: 100% 59/59 [00:25<00:00,  2.28it/s]\n",
            "Epoch:  90% 9/10 [03:53<00:25, 25.94s/it]\n",
            "Iteration:   0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/59 [00:00<00:25,  2.24it/s]\u001b[A\n",
            "Iteration:   3% 2/59 [00:00<00:25,  2.25it/s]\u001b[A\n",
            "Iteration:   5% 3/59 [00:01<00:24,  2.26it/s]\u001b[A\n",
            "Iteration:   7% 4/59 [00:01<00:24,  2.27it/s]\u001b[A\n",
            "Iteration:   8% 5/59 [00:02<00:23,  2.27it/s]\u001b[A\n",
            "Iteration:  10% 6/59 [00:02<00:23,  2.27it/s]\u001b[A\n",
            "Iteration:  12% 7/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  14% 8/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  15% 9/59 [00:03<00:22,  2.27it/s]\u001b[A\n",
            "Iteration:  17% 10/59 [00:04<00:21,  2.27it/s]\u001b[A\n",
            "Iteration:  19% 11/59 [00:04<00:21,  2.28it/s]\u001b[A\n",
            "Iteration:  20% 12/59 [00:05<00:20,  2.28it/s]\u001b[A\n",
            "Iteration:  22% 13/59 [00:05<00:20,  2.28it/s]\u001b[A\n",
            "Iteration:  24% 14/59 [00:06<00:19,  2.28it/s]\u001b[A\n",
            "Iteration:  25% 15/59 [00:06<00:19,  2.28it/s]\u001b[A\n",
            "Iteration:  27% 16/59 [00:07<00:18,  2.28it/s]\u001b[A\n",
            "Iteration:  29% 17/59 [00:07<00:18,  2.28it/s]\u001b[A\n",
            "Iteration:  31% 18/59 [00:07<00:18,  2.28it/s]\u001b[A{\"learning_rate\": 3.3898305084745763e-06, \"loss\": 0.023205147217959167, \"step\": 550}\n",
            "\n",
            "Iteration:  32% 19/59 [00:08<00:17,  2.28it/s]\u001b[A\n",
            "Iteration:  34% 20/59 [00:08<00:17,  2.28it/s]\u001b[A\n",
            "Iteration:  36% 21/59 [00:09<00:16,  2.26it/s]\u001b[A\n",
            "Iteration:  37% 22/59 [00:09<00:16,  2.27it/s]\u001b[A\n",
            "Iteration:  39% 23/59 [00:10<00:15,  2.27it/s]\u001b[A\n",
            "Iteration:  41% 24/59 [00:10<00:15,  2.27it/s]\u001b[A\n",
            "Iteration:  42% 25/59 [00:10<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  44% 26/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  46% 27/59 [00:11<00:14,  2.27it/s]\u001b[A\n",
            "Iteration:  47% 28/59 [00:12<00:13,  2.28it/s]\u001b[A\n",
            "Iteration:  49% 29/59 [00:12<00:13,  2.28it/s]\u001b[A\n",
            "Iteration:  51% 30/59 [00:13<00:12,  2.28it/s]\u001b[A\n",
            "Iteration:  53% 31/59 [00:13<00:12,  2.28it/s]\u001b[A\n",
            "Iteration:  54% 32/59 [00:14<00:11,  2.28it/s]\u001b[A\n",
            "Iteration:  56% 33/59 [00:14<00:11,  2.28it/s]\u001b[A\n",
            "Iteration:  58% 34/59 [00:14<00:10,  2.28it/s]\u001b[A\n",
            "Iteration:  59% 35/59 [00:15<00:10,  2.28it/s]\u001b[A\n",
            "Iteration:  61% 36/59 [00:15<00:10,  2.28it/s]\u001b[A\n",
            "Iteration:  63% 37/59 [00:16<00:09,  2.28it/s]\u001b[A\n",
            "Iteration:  64% 38/59 [00:16<00:09,  2.28it/s]\u001b[A\n",
            "Iteration:  66% 39/59 [00:17<00:08,  2.28it/s]\u001b[A\n",
            "Iteration:  68% 40/59 [00:17<00:08,  2.28it/s]\u001b[A\n",
            "Iteration:  69% 41/59 [00:18<00:07,  2.28it/s]\u001b[A\n",
            "Iteration:  71% 42/59 [00:18<00:07,  2.28it/s]\u001b[A\n",
            "Iteration:  73% 43/59 [00:18<00:07,  2.27it/s]\u001b[A\n",
            "Iteration:  75% 44/59 [00:19<00:06,  2.28it/s]\u001b[A\n",
            "Iteration:  76% 45/59 [00:19<00:06,  2.28it/s]\u001b[A\n",
            "Iteration:  78% 46/59 [00:20<00:05,  2.27it/s]\u001b[A\n",
            "Iteration:  80% 47/59 [00:20<00:05,  2.27it/s]\u001b[A\n",
            "Iteration:  81% 48/59 [00:21<00:04,  2.27it/s]\u001b[A\n",
            "Iteration:  83% 49/59 [00:21<00:04,  2.27it/s]\u001b[A\n",
            "Iteration:  85% 50/59 [00:21<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  86% 51/59 [00:22<00:03,  2.27it/s]\u001b[A\n",
            "Iteration:  88% 52/59 [00:22<00:03,  2.26it/s]\u001b[A\n",
            "Iteration:  90% 53/59 [00:23<00:02,  2.26it/s]\u001b[A\n",
            "Iteration:  92% 54/59 [00:23<00:02,  2.27it/s]\u001b[A\n",
            "Iteration:  93% 55/59 [00:24<00:01,  2.26it/s]\u001b[A\n",
            "Iteration:  95% 56/59 [00:24<00:01,  2.26it/s]\u001b[A\n",
            "Iteration:  97% 57/59 [00:25<00:00,  2.26it/s]\u001b[A\n",
            "Iteration:  98% 58/59 [00:25<00:00,  2.27it/s]\u001b[A\n",
            "Iteration: 100% 59/59 [00:25<00:00,  2.28it/s]\n",
            "Epoch: 100% 10/10 [04:19<00:00, 25.96s/it]\n",
            "10/16/2020 12:07:59 - INFO - __main__ -    global_step = 590, average loss = 0.12384635455495978\n",
            "10/16/2020 12:07:59 - INFO - utils_ichi -   Loading features from cached file ./data/ichi/cached_dev_bert-base-uncased_256_cadec\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_cadec\n",
            "10/16/2020 12:08:00 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "10/16/2020 12:08:00 - INFO - __main__ -     Num examples = 300\n",
            "10/16/2020 12:08:00 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 19/19 [00:02<00:00,  7.09it/s]\n",
            "10/16/2020 12:08:02 - INFO - __main__ -   ***** Eval results  *****\n",
            "10/16/2020 12:08:02 - INFO - __main__ -     acc_0 = 0.8166666666666667\n",
            "10/16/2020 12:08:02 - INFO - __main__ -     acc_1 = 0.99\n",
            "10/16/2020 12:08:02 - INFO - __main__ -     acc_2 = 0.87\n",
            "10/16/2020 12:08:02 - INFO - __main__ -     acc_3 = 0.9066666666666666\n",
            "10/16/2020 12:08:02 - INFO - __main__ -     acc_4 = 0.93\n",
            "10/16/2020 12:08:02 - INFO - __main__ -     f1_0 = 0.5379574920892722\n",
            "10/16/2020 12:08:02 - INFO - __main__ -     f1_1 = 0.49748743718592964\n",
            "10/16/2020 12:08:02 - INFO - __main__ -     f1_2 = 0.7602016765387059\n",
            "10/16/2020 12:08:02 - INFO - __main__ -     f1_3 = 0.7481712435543831\n",
            "10/16/2020 12:08:02 - INFO - __main__ -     f1_4 = 0.7369629660556971\n",
            "10/16/2020 12:08:02 - INFO - __main__ -   Saving model checkpoint to ./tmp/cadec_bert_base_new\n",
            "10/16/2020 12:08:07 - INFO - transformers.tokenization_utils -   Model name './tmp/cadec_bert_base_new' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming './tmp/cadec_bert_base_new' is a path or url to a directory containing tokenizer files.\n",
            "10/16/2020 12:08:07 - INFO - transformers.tokenization_utils -   loading file ./tmp/cadec_bert_base_new/vocab.txt\n",
            "10/16/2020 12:08:07 - INFO - transformers.tokenization_utils -   loading file ./tmp/cadec_bert_base_new/added_tokens.json\n",
            "10/16/2020 12:08:07 - INFO - transformers.tokenization_utils -   loading file ./tmp/cadec_bert_base_new/special_tokens_map.json\n",
            "10/16/2020 12:08:07 - INFO - transformers.tokenization_utils -   loading file ./tmp/cadec_bert_base_new/tokenizer_config.json\n",
            "10/16/2020 12:08:07 - INFO - transformers.tokenization_utils -   Model name './tmp/cadec_bert_base_new' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming './tmp/cadec_bert_base_new' is a path or url to a directory containing tokenizer files.\n",
            "10/16/2020 12:08:07 - INFO - transformers.tokenization_utils -   loading file ./tmp/cadec_bert_base_new/vocab.txt\n",
            "10/16/2020 12:08:07 - INFO - transformers.tokenization_utils -   loading file ./tmp/cadec_bert_base_new/added_tokens.json\n",
            "10/16/2020 12:08:07 - INFO - transformers.tokenization_utils -   loading file ./tmp/cadec_bert_base_new/special_tokens_map.json\n",
            "10/16/2020 12:08:07 - INFO - transformers.tokenization_utils -   loading file ./tmp/cadec_bert_base_new/tokenizer_config.json\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_cadec\n",
            "10/16/2020 12:08:08 - INFO - __main__ -   Evaluate the following checkpoints: ['./tmp/cadec_bert_base_new']\n",
            "10/16/2020 12:08:11 - INFO - utils_ichi -   Loading features from cached file ./data/ichi/cached_dev_bert-base-uncased_256_cadec\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_cadec\n",
            "10/16/2020 12:08:11 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "10/16/2020 12:08:11 - INFO - __main__ -     Num examples = 300\n",
            "10/16/2020 12:08:11 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 19/19 [00:02<00:00,  7.03it/s]\n",
            "10/16/2020 12:08:14 - INFO - __main__ -   ***** Eval results  *****\n",
            "10/16/2020 12:08:14 - INFO - __main__ -     acc_0 = 0.8166666666666667\n",
            "10/16/2020 12:08:14 - INFO - __main__ -     acc_1 = 0.99\n",
            "10/16/2020 12:08:14 - INFO - __main__ -     acc_2 = 0.87\n",
            "10/16/2020 12:08:14 - INFO - __main__ -     acc_3 = 0.9066666666666666\n",
            "10/16/2020 12:08:14 - INFO - __main__ -     acc_4 = 0.93\n",
            "10/16/2020 12:08:14 - INFO - __main__ -     f1_0 = 0.5379574920892722\n",
            "10/16/2020 12:08:14 - INFO - __main__ -     f1_1 = 0.49748743718592964\n",
            "10/16/2020 12:08:14 - INFO - __main__ -     f1_2 = 0.7602016765387059\n",
            "10/16/2020 12:08:14 - INFO - __main__ -     f1_3 = 0.7481712435543831\n",
            "10/16/2020 12:08:14 - INFO - __main__ -     f1_4 = 0.7369629660556971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H01TYmyzS8n4",
        "outputId": "9fe83dd8-9988-4a91-b861-348622701502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Oct 15 12:38:42 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PlJzq0GsRjF",
        "outputId": "23ca1369-e83c-4d1f-dd8c-7bab9eb15d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bioasq.lip6.fr\t\t      hubconf.py\tsetup.cfg\n",
            "biomedicalWordVectors.tar.gz  index.html\tsetup.py\n",
            "CONTRIBUTING.md\t\t      index.html.1\tsrc\n",
            "data\t\t\t      LICENSE\t\ttemplates\n",
            "deploy_multi_version_doc.sh   Makefile\t\ttests\n",
            "docker\t\t\t      MANIFEST.in\ttmp\n",
            "docs\t\t\t      notebooks\t\ttransformers-cli\n",
            "examples\t\t      README.md\t\tutils\n",
            "glove.840B.300d.txt\t      requirements.txt\tvalohai.yaml\n",
            "glove.840B.300d.zip\t      runs\t\tword2vecTools\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g11ukVnhuyD2",
        "outputId": "a0b60df4-7592-48a7-b7e8-1fa2a778f21f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python ./examples/ichi/run_ichi.py --model_type bert --model_name_or_path bert-base-uncased --do_lower_case --do_eval --data_dir ./data/ichi --max_seq_length 256 --per_gpu_eval_batch_size=16 --per_gpu_train_batch_size=16 --learning_rate 5e-5 --num_train_epochs 2 --output_dir ./tmp/ichi_bert_base_new "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-15 22:47:26.878782: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "10/15/2020 22:47:28 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "10/15/2020 22:47:29 - INFO - filelock -   Lock 140380687211376 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "10/15/2020 22:47:29 - INFO - filelock -   Lock 140380687211376 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "10/15/2020 22:47:29 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "10/15/2020 22:47:29 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"ichi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 7,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "10/15/2020 22:47:29 - INFO - filelock -   Lock 140380687703400 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "10/15/2020 22:47:29 - INFO - filelock -   Lock 140380687703400 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "10/15/2020 22:47:29 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "10/15/2020 22:47:29 - INFO - utils_ichi -   Loading features from cached file ./data/ichi/cached_train_bert-base-uncased_256_ichi\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_ichi\n",
            "10/15/2020 22:47:33 - INFO - filelock -   Lock 140380687208744 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "10/15/2020 22:47:33 - INFO - filelock -   Lock 140380687208744 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "10/15/2020 22:47:33 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "10/15/2020 22:47:37 - INFO - transformers.modeling_utils -   Weights of lcf_BERT not initialized from pretrained model: ['bert_SA.SA.query.weight', 'bert_SA.SA.query.bias', 'bert_SA.SA.key.weight', 'bert_SA.SA.key.bias', 'bert_SA.SA.value.weight', 'bert_SA.SA.value.bias', 'linear_double_cdm_or_cdw.weight', 'linear_double_cdm_or_cdw.bias', 'linear_triple_lcf_global.weight', 'linear_triple_lcf_global.bias', 'bert_pooler_org.dense.weight', 'bert_pooler_org.dense.bias', 'bert_pooler.dense.weight', 'bert_pooler.dense.bias', 'dense.weight', 'dense.bias']\n",
            "10/15/2020 22:47:37 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in lcf_BERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "10/15/2020 22:47:42 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='./data/ichi', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, embedding_dim_word2vec=300, embedding_type='glove', eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_context_focus='cdm', local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=256, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=2.0, output_dir='./tmp/ichi_bert_base_new', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=16, save_steps=10000, seed=42, server_ip='', server_port='', task_name='ichi', tokenizer_name='', use_single_bert=False, warmup_steps=0, weight_decay=0.0)\n",
            "10/15/2020 22:47:42 - INFO - utils_ichi -   Loading features from cached file ./data/ichi/cached_dev_bert-base-uncased_256_ichi\n",
            "loading tokenizer from cache: ./data/ichi/cachedtokenizer_bert-base-uncased_glove_ichi\n",
            "10/15/2020 22:47:43 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "10/15/2020 22:47:43 - INFO - __main__ -     Num examples = 3000\n",
            "10/15/2020 22:47:43 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 188/188 [00:45<00:00,  4.13it/s]\n",
            "10/15/2020 22:48:29 - INFO - __main__ -   ***** Eval results  *****\n",
            "10/15/2020 22:48:29 - INFO - __main__ -     acc = 0.12166666666666667\n",
            "10/15/2020 22:48:29 - INFO - __main__ -     f1 = 0.07237215449401717\n",
            "10/15/2020 22:48:29 - INFO - transformers.tokenization_utils -   Model name './tmp/ichi_bert_base_new' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming './tmp/ichi_bert_base_new' is a path or url to a directory containing tokenizer files.\n",
            "10/15/2020 22:48:29 - INFO - transformers.tokenization_utils -   Didn't find file ./tmp/ichi_bert_base_new/vocab.txt. We won't load it.\n",
            "10/15/2020 22:48:29 - INFO - transformers.tokenization_utils -   Didn't find file ./tmp/ichi_bert_base_new/added_tokens.json. We won't load it.\n",
            "10/15/2020 22:48:29 - INFO - transformers.tokenization_utils -   Didn't find file ./tmp/ichi_bert_base_new/special_tokens_map.json. We won't load it.\n",
            "10/15/2020 22:48:29 - INFO - transformers.tokenization_utils -   Didn't find file ./tmp/ichi_bert_base_new/tokenizer_config.json. We won't load it.\n",
            "Traceback (most recent call last):\n",
            "  File \"./examples/ichi/run_ichi.py\", line 704, in <module>\n",
            "    main()\n",
            "  File \"./examples/ichi/run_ichi.py\", line 660, in main\n",
            "    tokenizer = tokenizer_class.from_pretrained(args.output_dir, do_lower_case=args.do_lower_case)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\", line 309, in from_pretrained\n",
            "    return cls._from_pretrained(*inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\", line 382, in _from_pretrained\n",
            "    list(cls.vocab_files_names.values()),\n",
            "OSError: Model name './tmp/ichi_bert_base_new' was not found in tokenizers model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). We assumed './tmp/ichi_bert_base_new' was a path or url to a directory containing vocabulary files named ['vocab.txt'] but couldn't find such vocabulary files at this path or url.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9QFTiYbc0nA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}