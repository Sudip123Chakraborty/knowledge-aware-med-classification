{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextCNN_ICHI_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KSGWtOi2OTK",
        "outputId": "800798a1-71d9-4edd-f68e-64f35ac47b3a"
      },
      "source": [
        "cd knowledge-aware-med-classification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/knowledge-aware-med-classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-073a1OxUln"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import sys\n",
        "import os\n",
        "os.environ['KERAS_BACKEND']='theano'\n",
        "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer, InputSpec\n",
        "from keras import initializers\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhXGlJSB5ckO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3ed31d-b3e8-4bf9-f747-0b21e7ccc70b"
      },
      "source": [
        "# Downloading Glove Embeddings\n",
        "!curl -O -J -L http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0   308    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0   345    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  822M  100  822M    0     0  5265k      0  0:02:39  0:02:39 --:--:-- 5354k\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kijUst_8xc9R"
      },
      "source": [
        "df_train = pd.read_csv('data/ichi_dataset/final_train_result.tsv',sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "JVwAqPOlxt5z",
        "outputId": "1efede39-ecc8-4bbc-c44b-28f15bb33ee1"
      },
      "source": [
        "df_train.drop(['Title'],axis=1,inplace=True)\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Question</th>\n",
              "      <th>Concepts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>I have a lump on my wrist, right below the rig...</td>\n",
              "      <td>right thumb|right|wrist|pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PREG</td>\n",
              "      <td>I am 12w1d pg with twins and for about the pas...</td>\n",
              "      <td>upper abdomen|ribs|out|spasms|uterus|right|bel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GOAL</td>\n",
              "      <td>Please I need help real quick I have done an m...</td>\n",
              "      <td>eye muscles|sever|scan|weak|eyes|pain in eye|p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>http://www.msnbc.msn.com/id/40820892/ns/techno...</td>\n",
              "      <td>rights|trial|faces|\"miscarriage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRMT</td>\n",
              "      <td>Hey Everyone, :)I'm too busy to wait around fo...</td>\n",
              "      <td>dye|DYE|liquid diet|unpacking|all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>GOAL</td>\n",
              "      <td>Hi :)Just this morning I woke up with blurred ...</td>\n",
              "      <td>symptoms|internal bleeding|head|sickness|eyes|...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>FAML</td>\n",
              "      <td>We gave our 7 years old a journal, as one of h...</td>\n",
              "      <td>old|back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>PREG</td>\n",
              "      <td>My 3.5 yr son does not listen at home, he is a...</td>\n",
              "      <td>old|hand|out|sense</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>DISE</td>\n",
              "      <td>I think the amount billed to my insurance is r...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>well i just got over the canker sore thing... ...</td>\n",
              "      <td>canker sore|all|throat pain|sore throat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category  ...                                           Concepts\n",
              "0        SOCL  ...                       right thumb|right|wrist|pain\n",
              "1        PREG  ...  upper abdomen|ribs|out|spasms|uterus|right|bel...\n",
              "2        GOAL  ...  eye muscles|sever|scan|weak|eyes|pain in eye|p...\n",
              "3        SOCL  ...                    rights|trial|faces|\"miscarriage\n",
              "4        TRMT  ...                  dye|DYE|liquid diet|unpacking|all\n",
              "...       ...  ...                                                ...\n",
              "7995     GOAL  ...  symptoms|internal bleeding|head|sickness|eyes|...\n",
              "7996     FAML  ...                                           old|back\n",
              "7997     PREG  ...                                 old|hand|out|sense\n",
              "7998     DISE  ...                                                NaN\n",
              "7999     SOCL  ...            canker sore|all|throat pain|sore throat\n",
              "\n",
              "[8000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GciW5qaaxwbR"
      },
      "source": [
        "df_test = pd.read_csv('data/ichi_dataset/final_test_result.tsv',sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "mJLq0Stzxz6z",
        "outputId": "2bbadded-9cc8-485b-a799-3115808d3699"
      },
      "source": [
        "df_test.drop(['Title'],axis=1,inplace=True)\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Question</th>\n",
              "      <th>Concepts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DISE</td>\n",
              "      <td>Hi All! I am new here but have been lurking fo...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>My girlfriend and i just got through having se...</td>\n",
              "      <td>swelling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GOAL</td>\n",
              "      <td>Dr. i have dirty yellow buning eyes since my t...</td>\n",
              "      <td>eyes|condition|buning eyes|age|HAND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>Hi, a few nights ago I went to a gay sexclub a...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FAML</td>\n",
              "      <td>my 4 year old is a nightmare. me and my husban...</td>\n",
              "      <td>screaming|all|demanding|fits|nightmare|age|old</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>TRMT</td>\n",
              "      <td>I am definitley having my lap band removed in ...</td>\n",
              "      <td>weight loss|all|weight|acid reflux|out|said</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>PREG</td>\n",
              "      <td>I am in the TWW again. I was on Femara this mo...</td>\n",
              "      <td>follicles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>DISE</td>\n",
              "      <td>I've been advised to try visual routine charts...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>PREG</td>\n",
              "      <td>Just looking for some cycle buddies!    I star...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>GOAL</td>\n",
              "      <td>Early in the day, my vision is fine. But towar...</td>\n",
              "      <td>eye</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category  ...                                        Concepts\n",
              "0        DISE  ...                                             NaN\n",
              "1        SOCL  ...                                        swelling\n",
              "2        GOAL  ...             eyes|condition|buning eyes|age|HAND\n",
              "3        SOCL  ...                                             NaN\n",
              "4        FAML  ...  screaming|all|demanding|fits|nightmare|age|old\n",
              "...       ...  ...                                             ...\n",
              "2995     TRMT  ...     weight loss|all|weight|acid reflux|out|said\n",
              "2996     PREG  ...                                       follicles\n",
              "2997     DISE  ...                                             NaN\n",
              "2998     PREG  ...                                             NaN\n",
              "2999     GOAL  ...                                             eye\n",
              "\n",
              "[3000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie46g7YUx2HO"
      },
      "source": [
        "# Text Preprocessing\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = text.strip(' ')\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NPe5Losx5Io"
      },
      "source": [
        "# Label Categories in the dataset\n",
        "categories = ['DEMO','DISE','FAML','GOAL','PREG','SOCL','TRMT']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMfLA1TDx92P"
      },
      "source": [
        "from nltk import tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLHnFmYiyFeo"
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NB_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y73GW65P2buQ"
      },
      "source": [
        "# Assiging integer ID to each category\n",
        "macronum=sorted(set(df_train['Category']))\n",
        "macro_to_id = dict((note, number) for number, note in enumerate(macronum))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXT1AWeq3dFH",
        "outputId": "d4db18ff-9534-439a-e5a0-f12986183185"
      },
      "source": [
        "macro_to_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DEMO': 0, 'DISE': 1, 'FAML': 2, 'GOAL': 3, 'PREG': 4, 'SOCL': 5, 'TRMT': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-alcY_L2cbf"
      },
      "source": [
        "#Function to return id of a category\n",
        "def fun(i):\n",
        "    return macro_to_id[i]\n",
        "\n",
        "df_train['Category']=df_train['Category'].apply(fun)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SemDugMyyhJA"
      },
      "source": [
        "labels = []\n",
        "texts = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkdDUx4pzSrZ",
        "outputId": "b0d377a6-9010-44cd-9c52-acd55daffcbd"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IALswtMcykvR"
      },
      "source": [
        "# Creating text array\n",
        "for i in range(df_train.Question.shape[0]):\n",
        "  text = BeautifulSoup(df_train.Question[i])\n",
        "  texts.append(clean_text(str(text.get_text().encode()).lower()))\n",
        "\n",
        "# Creating Labels array\n",
        "for i in df_train['Category']:\n",
        "    labels.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmCFcxIfzK9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a993ea-56f3-4948-9b8c-187e543fde7c"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS,oov_token=\"<UKN>\") # Defining the tokenizer\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Number of Unique Tokens',len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Unique Tokens 37221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri_knbH6rBlj",
        "outputId": "30e340cd-fa65-4d6f-c762-464c8da2641c"
      },
      "source": [
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH) #Padding the texts to Maximum Sequence Length\n",
        "\n",
        "labels = to_categorical(np.asarray(labels))\n",
        "print('Shape of Data Tensor:', data.shape)\n",
        "print('Shape of Label Tensor:', labels.shape)\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Data Tensor: (8000, 1000)\n",
            "Shape of Label Tensor: (8000, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0KoctMi1JPc"
      },
      "source": [
        "df_test['Category']=df_test['Category'].apply(fun)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHhhI-Bp3Rwm"
      },
      "source": [
        "labels_val = []\n",
        "texts_val = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q11t7x25344u"
      },
      "source": [
        "# Creating Validation text array\n",
        "for i in range(df_test.Question.shape[0]):\n",
        "  text_val = BeautifulSoup(df_test.Question[i])\n",
        "  texts_val.append(clean_text(str(text_val.get_text().encode()).lower()))\n",
        "\n",
        "# Creating Validation Labels Array\n",
        "for i in df_test['Category']:\n",
        "    labels_val.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcgE3Yemrh_I"
      },
      "source": [
        "sequences_val = tokenizer.texts_to_sequences(texts_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y289FM7zruNJ",
        "outputId": "dcb09d19-e169-42d3-df24-033547ed7c6b"
      },
      "source": [
        "data_val = pad_sequences(sequences_val, maxlen=MAX_SEQUENCE_LENGTH) # Padding validation text to maximum sequence length\n",
        "\n",
        "labels_val = to_categorical(np.asarray(labels_val))\n",
        "print('Shape of Data Tensor:', data_val.shape)\n",
        "print('Shape of Label Tensor:', labels_val.shape)\n",
        "\n",
        "indices = np.arange(data_val.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data_val = data_val[indices]\n",
        "labels_val = labels_val[indices]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Data Tensor: (3000, 1000)\n",
            "Shape of Label Tensor: (3000, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQJRuUIJ4t8l"
      },
      "source": [
        "x_train = data\n",
        "y_train = labels\n",
        "x_val = data_val\n",
        "y_val = labels_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pUi5-3142lP",
        "outputId": "a237462b-804e-47b9-df4b-bc18c9c394b7"
      },
      "source": [
        "# Creating the Embedding Dictionary\n",
        "embeddings_index = {}\n",
        "f = open('glove.6B.100d.txt',encoding='utf8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Total %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2z0hl9p46gY"
      },
      "source": [
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "# Defining the embedding Layer\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrLM6B7K5AJm",
        "outputId": "14cfa64c-6af4-4f5e-a3c6-d93ce2f2771b"
      },
      "source": [
        "# Defining the Model\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
        "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
        "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
        "l_pool2 = MaxPooling1D(5)(l_cov2)\n",
        "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
        "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
        "l_flat = Flatten()(l_pool3)\n",
        "l_dense = Dense(128, activation='relu')(l_flat)\n",
        "preds = Dense(len(macronum), activation='softmax')(l_dense)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(\"Simplified convolutional neural network\")\n",
        "model.summary()\n",
        "cp=ModelCheckpoint('model_cnn.hdf5',monitor='val_acc',verbose=1,save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simplified convolutional neural network\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1000)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 1000, 100)         3722200   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 996, 128)          64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 199, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 195, 128)          82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 39, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 35, 128)           82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 3,967,839\n",
            "Trainable params: 3,967,839\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUx99ZPq5A_e",
        "outputId": "87efc83f-7e4f-4751-ac7c-fe1db50864ec"
      },
      "source": [
        "# Training the Model\n",
        "history=model.fit(x_train, y_train, validation_data=(x_val, y_val),epochs=15, batch_size=2,callbacks=[cp])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "4000/4000 [==============================] - 165s 37ms/step - loss: 1.7489 - acc: 0.2958 - val_loss: 1.4238 - val_acc: 0.4863\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.48633, saving model to model_cnn.hdf5\n",
            "Epoch 2/15\n",
            "4000/4000 [==============================] - 152s 38ms/step - loss: 1.3965 - acc: 0.5128 - val_loss: 1.6985 - val_acc: 0.5207\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.48633 to 0.52067, saving model to model_cnn.hdf5\n",
            "Epoch 3/15\n",
            "4000/4000 [==============================] - 151s 38ms/step - loss: 1.3992 - acc: 0.5394 - val_loss: 1.5255 - val_acc: 0.4800\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.52067\n",
            "Epoch 4/15\n",
            "4000/4000 [==============================] - 149s 37ms/step - loss: 1.3849 - acc: 0.5561 - val_loss: 2.0379 - val_acc: 0.5057\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.52067\n",
            "Epoch 5/15\n",
            "4000/4000 [==============================] - 149s 37ms/step - loss: 1.3834 - acc: 0.5851 - val_loss: 1.6473 - val_acc: 0.5430\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.52067 to 0.54300, saving model to model_cnn.hdf5\n",
            "Epoch 6/15\n",
            "4000/4000 [==============================] - 149s 37ms/step - loss: 1.2672 - acc: 0.6130 - val_loss: 2.0841 - val_acc: 0.4707\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.54300\n",
            "Epoch 7/15\n",
            "4000/4000 [==============================] - 150s 37ms/step - loss: 1.1839 - acc: 0.6545 - val_loss: 2.3283 - val_acc: 0.5313\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.54300\n",
            "Epoch 8/15\n",
            "4000/4000 [==============================] - 149s 37ms/step - loss: 1.1629 - acc: 0.6774 - val_loss: 3.6883 - val_acc: 0.5140\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.54300\n",
            "Epoch 9/15\n",
            "4000/4000 [==============================] - 148s 37ms/step - loss: 1.1916 - acc: 0.7073 - val_loss: 3.6026 - val_acc: 0.4850\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.54300\n",
            "Epoch 10/15\n",
            "4000/4000 [==============================] - 142s 36ms/step - loss: 0.9856 - acc: 0.7420 - val_loss: 4.3997 - val_acc: 0.5037\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.54300\n",
            "Epoch 11/15\n",
            "4000/4000 [==============================] - 144s 36ms/step - loss: 0.8935 - acc: 0.7445 - val_loss: 4.7457 - val_acc: 0.5453\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.54300 to 0.54533, saving model to model_cnn.hdf5\n",
            "Epoch 12/15\n",
            "4000/4000 [==============================] - 143s 36ms/step - loss: 0.8833 - acc: 0.7600 - val_loss: 5.2605 - val_acc: 0.5330\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.54533\n",
            "Epoch 13/15\n",
            "4000/4000 [==============================] - 143s 36ms/step - loss: 0.7828 - acc: 0.7970 - val_loss: 8.0631 - val_acc: 0.5510\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.54533 to 0.55100, saving model to model_cnn.hdf5\n",
            "Epoch 14/15\n",
            "4000/4000 [==============================] - 143s 36ms/step - loss: 0.7705 - acc: 0.8077 - val_loss: 7.8567 - val_acc: 0.5110\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.55100\n",
            "Epoch 15/15\n",
            "4000/4000 [==============================] - 143s 36ms/step - loss: 0.7756 - acc: 0.8294 - val_loss: 6.1418 - val_acc: 0.5127\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.55100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBcfeUoABsUe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}