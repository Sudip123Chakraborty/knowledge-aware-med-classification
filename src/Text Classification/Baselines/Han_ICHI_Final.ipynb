{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Han_ICHI_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozHu9qsg_0rr",
        "outputId": "4d18678f-a0ad-48b4-db62-b41975ad9818"
      },
      "source": [
        "cd knowledge-aware-med-classification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/knowledge-aware-med-classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg4uAJKIxMtJ",
        "outputId": "8ddc28b0-0c5d-4f8f-b5ed-be92c7917963"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-073a1OxUln"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import sys\n",
        "import os\n",
        "os.environ['KERAS_BACKEND']='theano'\n",
        "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer, InputSpec\n",
        "from keras import initializers\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhXGlJSB5ckO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdca9836-f06f-4ff0-d70b-2bc56c2c72ff"
      },
      "source": [
        "# Downloading Glove Embeddings\n",
        "!curl -O -J -L http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0   308    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0   345    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  822M  100  822M    0     0  5222k      0  0:02:41  0:02:41 --:--:-- 5372k\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kijUst_8xc9R"
      },
      "source": [
        "df_train = pd.read_csv('data/ichi_dataset/final_train_result.tsv',sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "JVwAqPOlxt5z",
        "outputId": "9bd3246b-068e-4c22-e7b2-13b4a18d885f"
      },
      "source": [
        "df_train.drop(['Title','Concepts'],axis=1,inplace=True)\n",
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>I have a lump on my wrist, right below the rig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PREG</td>\n",
              "      <td>I am 12w1d pg with twins and for about the pas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GOAL</td>\n",
              "      <td>Please I need help real quick I have done an m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>http://www.msnbc.msn.com/id/40820892/ns/techno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRMT</td>\n",
              "      <td>Hey Everyone, :)I'm too busy to wait around fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>GOAL</td>\n",
              "      <td>Hi :)Just this morning I woke up with blurred ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>FAML</td>\n",
              "      <td>We gave our 7 years old a journal, as one of h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>PREG</td>\n",
              "      <td>My 3.5 yr son does not listen at home, he is a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>DISE</td>\n",
              "      <td>I think the amount billed to my insurance is r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>well i just got over the canker sore thing... ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category                                           Question\n",
              "0        SOCL  I have a lump on my wrist, right below the rig...\n",
              "1        PREG  I am 12w1d pg with twins and for about the pas...\n",
              "2        GOAL  Please I need help real quick I have done an m...\n",
              "3        SOCL  http://www.msnbc.msn.com/id/40820892/ns/techno...\n",
              "4        TRMT  Hey Everyone, :)I'm too busy to wait around fo...\n",
              "...       ...                                                ...\n",
              "7995     GOAL  Hi :)Just this morning I woke up with blurred ...\n",
              "7996     FAML  We gave our 7 years old a journal, as one of h...\n",
              "7997     PREG  My 3.5 yr son does not listen at home, he is a...\n",
              "7998     DISE  I think the amount billed to my insurance is r...\n",
              "7999     SOCL  well i just got over the canker sore thing... ...\n",
              "\n",
              "[8000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "GciW5qaaxwbR",
        "outputId": "7898cd2b-6c1c-4c61-efb8-9c3d49e79046"
      },
      "source": [
        "df_test = pd.read_csv('data/ichi_dataset/final_test_result.tsv',sep='\\t')\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Title</th>\n",
              "      <th>Question</th>\n",
              "      <th>Concepts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DISE</td>\n",
              "      <td>Interrupt TX ???</td>\n",
              "      <td>Hi All! I am new here but have been lurking fo...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>Swollen vagina clit</td>\n",
              "      <td>My girlfriend and i just got through having se...</td>\n",
              "      <td>swelling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GOAL</td>\n",
              "      <td>burning yellow eyes</td>\n",
              "      <td>Dr. i have dirty yellow buning eyes since my t...</td>\n",
              "      <td>eyes|condition|buning eyes|age|HAND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>Drug test and ws</td>\n",
              "      <td>Hi, a few nights ago I went to a gay sexclub a...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FAML</td>\n",
              "      <td>4 year old is out of control</td>\n",
              "      <td>my 4 year old is a nightmare. me and my husban...</td>\n",
              "      <td>screaming|all|demanding|fits|nightmare|age|old</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>TRMT</td>\n",
              "      <td>lap band removal is scheduled</td>\n",
              "      <td>I am definitley having my lap band removed in ...</td>\n",
              "      <td>weight loss|all|weight|acid reflux|out|said</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>PREG</td>\n",
              "      <td>I had my IUI today</td>\n",
              "      <td>I am in the TWW again. I was on Femara this mo...</td>\n",
              "      <td>follicles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>DISE</td>\n",
              "      <td>daily routine charts?</td>\n",
              "      <td>I've been advised to try visual routine charts...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>PREG</td>\n",
              "      <td>anyone starting shots for an IUI?</td>\n",
              "      <td>Just looking for some cycle buddies!    I star...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>GOAL</td>\n",
              "      <td>Blurry eye at the end of the day</td>\n",
              "      <td>Early in the day, my vision is fine. But towar...</td>\n",
              "      <td>eye</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category  ...                                        Concepts\n",
              "0        DISE  ...                                             NaN\n",
              "1        SOCL  ...                                        swelling\n",
              "2        GOAL  ...             eyes|condition|buning eyes|age|HAND\n",
              "3        SOCL  ...                                             NaN\n",
              "4        FAML  ...  screaming|all|demanding|fits|nightmare|age|old\n",
              "...       ...  ...                                             ...\n",
              "2995     TRMT  ...     weight loss|all|weight|acid reflux|out|said\n",
              "2996     PREG  ...                                       follicles\n",
              "2997     DISE  ...                                             NaN\n",
              "2998     PREG  ...                                             NaN\n",
              "2999     GOAL  ...                                             eye\n",
              "\n",
              "[3000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "mJLq0Stzxz6z",
        "outputId": "1b0e5fc8-5da6-4779-bab6-500cb1d17b34"
      },
      "source": [
        "df_test.drop(['Title','Concepts'],axis=1,inplace=True)\n",
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DISE</td>\n",
              "      <td>Hi All! I am new here but have been lurking fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>My girlfriend and i just got through having se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GOAL</td>\n",
              "      <td>Dr. i have dirty yellow buning eyes since my t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SOCL</td>\n",
              "      <td>Hi, a few nights ago I went to a gay sexclub a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FAML</td>\n",
              "      <td>my 4 year old is a nightmare. me and my husban...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>TRMT</td>\n",
              "      <td>I am definitley having my lap band removed in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>PREG</td>\n",
              "      <td>I am in the TWW again. I was on Femara this mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>DISE</td>\n",
              "      <td>I've been advised to try visual routine charts...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>PREG</td>\n",
              "      <td>Just looking for some cycle buddies!    I star...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>GOAL</td>\n",
              "      <td>Early in the day, my vision is fine. But towar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category                                           Question\n",
              "0        DISE  Hi All! I am new here but have been lurking fo...\n",
              "1        SOCL  My girlfriend and i just got through having se...\n",
              "2        GOAL  Dr. i have dirty yellow buning eyes since my t...\n",
              "3        SOCL  Hi, a few nights ago I went to a gay sexclub a...\n",
              "4        FAML  my 4 year old is a nightmare. me and my husban...\n",
              "...       ...                                                ...\n",
              "2995     TRMT  I am definitley having my lap band removed in ...\n",
              "2996     PREG  I am in the TWW again. I was on Femara this mo...\n",
              "2997     DISE  I've been advised to try visual routine charts...\n",
              "2998     PREG  Just looking for some cycle buddies!    I star...\n",
              "2999     GOAL  Early in the day, my vision is fine. But towar...\n",
              "\n",
              "[3000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie46g7YUx2HO"
      },
      "source": [
        "# Text Preprocessing\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = text.strip(' ')\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NPe5Losx5Io"
      },
      "source": [
        "# Label Categories in the dataset\n",
        "categories = ['DEMO','DISE','FAML','GOAL','PREG','SOCL','TRMT']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMfLA1TDx92P"
      },
      "source": [
        "from nltk import tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLHnFmYiyFeo"
      },
      "source": [
        "MAX_SENT_LENGTH = 100\n",
        "MAX_SENTS = 15\n",
        "MAX_NB_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y73GW65P2buQ"
      },
      "source": [
        "# Assiging integer ID to each category\n",
        "macronum=sorted(set(df_train['Category']))\n",
        "macro_to_id = dict((note, number) for number, note in enumerate(macronum))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXT1AWeq3dFH",
        "outputId": "16aa3932-4da0-4f45-f8a9-d7f783977d5d"
      },
      "source": [
        "macro_to_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DEMO': 0, 'DISE': 1, 'FAML': 2, 'GOAL': 3, 'PREG': 4, 'SOCL': 5, 'TRMT': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-alcY_L2cbf"
      },
      "source": [
        "#Function to return id of a category\n",
        "def fun(i):\n",
        "    return macro_to_id[i]\n",
        "\n",
        "df_train['Category']=df_train['Category'].apply(fun)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SemDugMyyhJA"
      },
      "source": [
        "sentence = [] #sent_tokenized train text\n",
        "labels = [] #train labels\n",
        "texts = [] #train texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkdDUx4pzSrZ",
        "outputId": "7b1636e8-404d-4327-c7d5-0580b564139f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IALswtMcykvR"
      },
      "source": [
        "# Creating text and sent_tokenized text array\n",
        "for i in range(df_train.Question.shape[0]):\n",
        "  text = BeautifulSoup(df_train.Question[i])\n",
        "  text=clean_text(str(text.get_text().encode()).lower())\n",
        "  texts.append(text)\n",
        "  sentences = tokenize.sent_tokenize(text)\n",
        "  sentence.append(sentences)\n",
        "\n",
        "# Creating Label array\n",
        "for i in df_train['Category']:\n",
        "    labels.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmCFcxIfzK9h"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, oov_token=\"<UKN>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "# Creating an array data containing tokenized values of words in the format (text,sentence,word)\n",
        "data = np.zeros((len(texts), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
        "\n",
        "for i, sentences in enumerate(sentence):\n",
        "    for j, sent in enumerate(sentences):\n",
        "        if j< MAX_SENTS:\n",
        "            wordTokens = text_to_word_sequence(sent)\n",
        "            k=0\n",
        "            wordSeq = tokenizer.texts_to_sequences(wordTokens)\n",
        "            for _, word in enumerate(wordSeq):\n",
        "                if k<MAX_SENT_LENGTH and word[0]<MAX_NB_WORDS:\n",
        "                    data[i,j,k] = word[0]\n",
        "                    k=k+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6NTyP7Z1BH3",
        "outputId": "fd185435-c0ae-4c5e-f9c0-794da48e4934"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('No. of %s unique tokens.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of 37221 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9Mbp8rP1FkF",
        "outputId": "8ae9b7a8-d885-4c50-c5b1-ed84a878ae79"
      },
      "source": [
        "labels = to_categorical(np.asarray(labels))\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (8000, 15, 100)\n",
            "Shape of label tensor: (8000, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0KoctMi1JPc"
      },
      "source": [
        "df_test['Category']=df_test['Category'].apply(fun)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHhhI-Bp3Rwm"
      },
      "source": [
        "sentence_val = [] #sent_tokenized test text\n",
        "labels_val = [] #test labels\n",
        "texts_val = [] #test texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q11t7x25344u"
      },
      "source": [
        "# Creating text and sent_tokenized text array\n",
        "for i in range(df_test.Question.shape[0]):\n",
        "  text_val = BeautifulSoup(df_test.Question[i])\n",
        "  text_val=clean_text(str(text_val.get_text().encode()).lower())\n",
        "  texts_val.append(text_val)\n",
        "  sentences = tokenize.sent_tokenize(text_val)\n",
        "  sentence_val.append(sentences)\n",
        "\n",
        "# Creating Label array\n",
        "for i in df_test['Category']:\n",
        "    labels_val.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gZan9lY4Jsv"
      },
      "source": [
        "data_val = np.zeros((len(texts_val), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
        "# Creating an array data containing tokenized values of words in the format (text,sentence,word)\n",
        "for i, sentences in enumerate(sentence_val):\n",
        "    for j, sent in enumerate(sentences):\n",
        "        if j< MAX_SENTS:\n",
        "            wordTokens = text_to_word_sequence(sent)\n",
        "            k=0\n",
        "            wordSeq = tokenizer.texts_to_sequences(wordTokens)\n",
        "            for _, word in enumerate(wordSeq):\n",
        "                if k<MAX_SENT_LENGTH and word[0]<MAX_NB_WORDS:\n",
        "                    data_val[i,j,k] = word[0]\n",
        "                    k=k+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YPENTgk4X7_",
        "outputId": "94a126f8-bd39-47e7-b8c4-9ec5fe7fefce"
      },
      "source": [
        "labels_val = to_categorical(np.asarray(labels_val))\n",
        "print('Shape of data tensor:', data_val.shape)\n",
        "print('Shape of label tensor:', labels_val.shape)\n",
        "\n",
        "\n",
        "indices = np.arange(data_val.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data_val = data_val[indices]\n",
        "labels_val = labels_val[indices]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (3000, 15, 100)\n",
            "Shape of label tensor: (3000, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQJRuUIJ4t8l"
      },
      "source": [
        "x_train = data\n",
        "y_train = labels\n",
        "x_val = data_val\n",
        "y_val = labels_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pUi5-3142lP",
        "outputId": "44a63cfd-5260-432a-8192-eefdb23ab325"
      },
      "source": [
        "# Creating the Embedding Dictionary\n",
        "embeddings_index = {}\n",
        "f = open('glove.6B.100d.txt',encoding='utf8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Total %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2z0hl9p46gY"
      },
      "source": [
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "# Defining the embedding Layer\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SENT_LENGTH,\n",
        "                            trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrLM6B7K5AJm",
        "outputId": "a3a4d8ce-4486-463f-a2f8-7a372458e309"
      },
      "source": [
        "# Defining the Model\n",
        "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sentence_input)\n",
        "l_lstm = Bidirectional(LSTM(100))(embedded_sequences)\n",
        "sentEncoder = Model(sentence_input, l_lstm)\n",
        "\n",
        "review_input = Input(shape=(MAX_SENTS,MAX_SENT_LENGTH), dtype='int32')\n",
        "review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
        "l_lstm_sent = Bidirectional(LSTM(100))(review_encoder)\n",
        "preds = Dense(len(macronum), activation='softmax')(l_lstm_sent)\n",
        "model = Model(review_input, preds)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "\n",
        "print(\"Hierachical LSTM\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hierachical LSTM\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 15, 100)]         0         \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 15, 200)           3883000   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200)               240800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 7)                 1407      \n",
            "=================================================================\n",
            "Total params: 4,125,207\n",
            "Trainable params: 4,125,207\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUx99ZPq5A_e",
        "outputId": "120480ee-3b06-47f6-8a15-5e2a4be5896d"
      },
      "source": [
        "# Training the Model\n",
        "cp=ModelCheckpoint('model_han_.hdf5',monitor='val_acc',verbose=1,save_best_only=True)\n",
        "history=model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
        "          epochs=10, batch_size=2,callbacks=[cp])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4000/4000 [==============================] - 750s 180ms/step - loss: 1.7503 - acc: 0.2928 - val_loss: 1.2127 - val_acc: 0.5417\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.54167, saving model to model_han_.hdf5\n",
            "Epoch 2/10\n",
            "4000/4000 [==============================] - 731s 183ms/step - loss: 1.1499 - acc: 0.5799 - val_loss: 1.1484 - val_acc: 0.5917\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.54167 to 0.59167, saving model to model_han_.hdf5\n",
            "Epoch 3/10\n",
            "4000/4000 [==============================] - 716s 179ms/step - loss: 0.9853 - acc: 0.6645 - val_loss: 1.0983 - val_acc: 0.6160\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.59167 to 0.61600, saving model to model_han_.hdf5\n",
            "Epoch 4/10\n",
            "4000/4000 [==============================] - 711s 178ms/step - loss: 0.8682 - acc: 0.7100 - val_loss: 1.1623 - val_acc: 0.6190\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.61600 to 0.61900, saving model to model_han_.hdf5\n",
            "Epoch 5/10\n",
            "4000/4000 [==============================] - 717s 179ms/step - loss: 0.7459 - acc: 0.7524 - val_loss: 1.3058 - val_acc: 0.6203\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.61900 to 0.62033, saving model to model_han_.hdf5\n",
            "Epoch 6/10\n",
            "4000/4000 [==============================] - 721s 180ms/step - loss: 0.6381 - acc: 0.7974 - val_loss: 1.4957 - val_acc: 0.5977\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.62033\n",
            "Epoch 7/10\n",
            "4000/4000 [==============================] - 711s 178ms/step - loss: 0.4833 - acc: 0.8475 - val_loss: 1.8904 - val_acc: 0.6030\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.62033\n",
            "Epoch 8/10\n",
            "4000/4000 [==============================] - 714s 179ms/step - loss: 0.3666 - acc: 0.8861 - val_loss: 2.0437 - val_acc: 0.5950\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.62033\n",
            "Epoch 9/10\n",
            "4000/4000 [==============================] - 720s 180ms/step - loss: 0.2433 - acc: 0.9266 - val_loss: 2.4539 - val_acc: 0.5833\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.62033\n",
            "Epoch 10/10\n",
            "4000/4000 [==============================] - 713s 178ms/step - loss: 0.1628 - acc: 0.9519 - val_loss: 2.8979 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.62033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBcfeUoABsUe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}